{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "973e19df",
   "metadata": {},
   "source": [
    "# 1、ConversationTokenBufferMemory的使用\n",
    "\n",
    "举例1："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f61c6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "# 创建大模型实例\n",
    "llm = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17b61a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始内存 (共 4 条消息) ---\n",
      "[HumanMessage(content='你好吗？', additional_kwargs={}, response_metadata={}), AIMessage(content='我很好，谢谢！', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='今天天气如何？', additional_kwargs={}, response_metadata={}), AIMessage(content='晴天，25度', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n",
      "\n",
      "--- 优化后：修剪结果 (Max=10) ---\n",
      "[AIMessage(content='晴天，25度', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.messages import trim_messages\n",
    "\n",
    "# ====================================================\n",
    "# 1. 定义离线计数器 (防止网络卡顿的关键)\n",
    "# ====================================================\n",
    "def offline_counter(messages) -> int:\n",
    "    \"\"\"用字数模拟 Token 数，每 1 个字算 1 个 Token (粗略估算)\"\"\"\n",
    "    total = 0\n",
    "    for msg in messages:\n",
    "        total += len(msg.content)\n",
    "    return total\n",
    "\n",
    "# ====================================================\n",
    "# 2. 定义修剪器 (替代 ConversationTokenBufferMemory)\n",
    "# ====================================================\n",
    "# 对应旧版的 max_token_limit=10\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=10,          # 限制大小\n",
    "    strategy=\"last\",        # 保留最新的\n",
    "    token_counter=offline_counter, # 使用离线计数，秒运行\n",
    "    include_system=True,\n",
    "    allow_partial=False,    # 不切断单句话\n",
    ")\n",
    "\n",
    "# ====================================================\n",
    "# 3. 操作流程\n",
    "# ====================================================\n",
    "\n",
    "# A. 存储消息 (使用 InMemoryChatMessageHistory)\n",
    "history = InMemoryChatMessageHistory()\n",
    "history.add_user_message(\"你好吗？\")       # 4个字\n",
    "history.add_ai_message(\"我很好，谢谢！\")   # 6个字 (累计10)\n",
    "history.add_user_message(\"今天天气如何？\") # 6个字 (累计16)\n",
    "history.add_ai_message(\"晴天，25度\")       # 5个字 (累计21)\n",
    "\n",
    "print(f\"--- 原始内存 (共 {len(history.messages)} 条消息) ---\")\n",
    "print(history.messages)\n",
    "\n",
    "# B. 获取修剪后的结果\n",
    "# 这步操作通常在 Chain 内部自动做，这里手动演示效果\n",
    "pruned_messages = trimmer.invoke(history.messages)\n",
    "\n",
    "print(f\"\\n--- 优化后：修剪结果 (Max=10) ---\")\n",
    "# 因为最后一条 \"晴天，25度\" 占5个token，上一条 \"今天天气...\" 占6个\n",
    "# 5+6=11 > 10，所以只能保留最后一条\n",
    "print(pruned_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43820c85",
   "metadata": {},
   "source": [
    "举例2："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3929e71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始全量记忆 (共 4 条) ---\n",
      "[HumanMessage(content='你好吗？', additional_kwargs={}, response_metadata={}), AIMessage(content='我很好，谢谢！', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='今天天气如何？', additional_kwargs={}, response_metadata={}), AIMessage(content='晴天，25度', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n",
      "\n",
      "--- 优化后：修剪结果 (Max=20) ---\n",
      "[AIMessage(content='我很好，谢谢！', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='今天天气如何？', additional_kwargs={}, response_metadata={}), AIMessage(content='晴天，25度', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.messages import trim_messages\n",
    "\n",
    "# ====================================================\n",
    "# 1. 定义离线计数器 (关键优化)\n",
    "# ====================================================\n",
    "# 为了防止 tiktoken 下载卡死，用“字数”粗略模拟 Token 数\n",
    "# 在中文语境下，1个汉字通常对应 0.7~2 个 Token，这里简单按 1:1 计算用于演示\n",
    "def offline_token_counter(messages) -> int:\n",
    "    total = 0\n",
    "    for msg in messages:\n",
    "        total += len(msg.content)\n",
    "    return total\n",
    "\n",
    "# ====================================================\n",
    "# 2. 定义修剪器 (替代 ConversationTokenBufferMemory)\n",
    "# ====================================================\n",
    "# 对应你原来的 max_token_limit=20\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=20,          # 设置上限 (这里按字数算)\n",
    "    strategy=\"last\",        # 保留最新的消息\n",
    "    token_counter=offline_token_counter, # 使用离线计数\n",
    "    include_system=True,\n",
    "    allow_partial=False,    # 不截断单条消息\n",
    ")\n",
    "\n",
    "# ====================================================\n",
    "# 3. 操作流程\n",
    "# ====================================================\n",
    "\n",
    "# A. 存储消息 (使用 InMemoryChatMessageHistory)\n",
    "# 这是一个全量的笔记本，记录所有历史，不会自动删除\n",
    "history = InMemoryChatMessageHistory()\n",
    "\n",
    "# Round 1\n",
    "history.add_user_message(\"你好吗？\")       # 4 字\n",
    "history.add_ai_message(\"我很好，谢谢！\")   # 6 字\n",
    "\n",
    "# Round 2\n",
    "history.add_user_message(\"今天天气如何？\") # 6 字\n",
    "history.add_ai_message(\"晴天，25度\")       # 5 字\n",
    "\n",
    "# B. 查看原始记忆\n",
    "print(f\"--- 原始全量记忆 (共 {len(history.messages)} 条) ---\")\n",
    "print(history.messages)\n",
    "\n",
    "# C. 执行修剪 (模拟 load_memory_variables)\n",
    "# 这一步通常在 Chain 内部做，这里手动展示效果\n",
    "# 计算逻辑：\n",
    "# 最后一条(5) + 倒数第二条(6) + 倒数第三条(6) = 17 < 20\n",
    "# 如果再加倒数第四条(4) = 21 > 20，超标了！\n",
    "# 所以预期结果：丢弃最早的 \"你好吗？\"，保留后三条 (或者根据 trim 策略保留成对)\n",
    "pruned_messages = trimmer.invoke(history.messages)\n",
    "\n",
    "print(f\"\\n--- 优化后：修剪结果 (Max=20) ---\")\n",
    "print(pruned_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66cb58b",
   "metadata": {},
   "source": [
    "# 2、SummaryMemory的使用\n",
    "\n",
    "举例1：\n",
    "\n",
    "如果实例化SummaryMemory前，没有历史消息，可以使用构造方法实例化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7515d271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始对话条数: 6 ---\n",
      "\n",
      "--- 优化后：生成的摘要 ---\n",
      "人类询问AI的身份，AI介绍自己为无所不能的AI助手小智。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 创建大模型\n",
    "llm = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "# ==========================================================\n",
    "# 2. 准备历史数据\n",
    "# ==========================================================\n",
    "# 先创建一个历史记录对象，把对话存进去\n",
    "history = InMemoryChatMessageHistory()\n",
    "history.add_user_message(\"你好\")\n",
    "history.add_ai_message(\"怎么了\")\n",
    "history.add_user_message(\"你是谁\")\n",
    "history.add_ai_message(\"我是AI助手小智\")\n",
    "history.add_user_message(\"初次对话，你能介绍一下你自己吗？\")\n",
    "history.add_ai_message(\"当然可以了。我是一个无所不能的小智。\")\n",
    "\n",
    "print(f\"--- 原始对话条数: {len(history.messages)} ---\")\n",
    "\n",
    "# ==========================================================\n",
    "# 3. 定义总结链 (替代 ConversationSummaryMemory 的黑盒逻辑)\n",
    "# ==========================================================\n",
    "# 这是一个专门用来做“阅读理解”的 Prompt\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    请将以下的对话内容总结为一个简短的摘要（Summary）。\n",
    "    摘要应包含关键信息，去除冗余的寒暄。\n",
    "    \n",
    "    对话内容：\n",
    "    {chat_history}\n",
    "    \n",
    "    摘要：\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 格式化Prompt -> 调用LLM -> 解析成字符串\n",
    "summarize_chain = summary_prompt | llm | StrOutputParser()\n",
    "\n",
    "# ==========================================================\n",
    "# 4. 执行总结\n",
    "# ==========================================================\n",
    "# history.messages 转换成字符串传给 chain\n",
    "# (注：如果模型支持直接读 Message 对象，也可以用 MessagesPlaceholder)\n",
    "chat_history_str = \"\\n\".join([f\"{msg.type}: {msg.content}\" for msg in history.messages])\n",
    "\n",
    "summary = summarize_chain.invoke({\"chat_history\": chat_history_str})\n",
    "\n",
    "print(\"\\n--- 优化后：生成的摘要 ---\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd91808",
   "metadata": {},
   "source": [
    "举例2：如果SummaryMemory前，已经有历史消息，可以调用from_messages()实例化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ed8dbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 初始历史消息数: 2 ---\n",
      "\n",
      "[操作 1] 生成初始摘要...\n",
      "摘要内容: 用户询问AI的身份，AI回应称自己是AI助手小智。\n",
      "\n",
      "[操作 2] 添加新对话...\n",
      "\n",
      "[操作 3] 生成更新后的摘要...\n",
      "摘要内容: 用户小明向AI助手小智问好并介绍自己，小智回应并表达欢迎。对话中包含用户身份为小明，AI身份为小智。\n",
      "\n",
      "[操作 4] 查看完整历史记录...\n",
      "[HumanMessage(content='你好，你是谁？', additional_kwargs={}, response_metadata={}), AIMessage(content='我是AI助手小智', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='我的名字叫小明', additional_kwargs={}, response_metadata={}), AIMessage(content='很高兴认识你', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "# 1. 创建大模型\n",
    "llm = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "# =========================================================\n",
    "# 2. 准备历史消息 (替代 ChatMessageHistory)\n",
    "# =========================================================\n",
    "# 使用 Core 组件 InMemoryChatMessageHistory\n",
    "history = InMemoryChatMessageHistory()\n",
    "\n",
    "# 假设的原始消息\n",
    "history.add_user_message(\"你好，你是谁？\")\n",
    "history.add_ai_message(\"我是AI助手小智\")\n",
    "\n",
    "print(f\"--- 初始历史消息数: {len(history.messages)} ---\")\n",
    "\n",
    "# =========================================================\n",
    "# 3. 定义总结链\n",
    "# =========================================================\n",
    "# 可以清楚地定义如何做总结，而不是依赖内部写死的英文 Prompt\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    请阅读以下的对话历史，并将其压缩为一个简练的摘要（Summary）。\n",
    "    摘要应包含关键信息，如用户身份、AI身份等。\n",
    "\n",
    "    对话历史：\n",
    "    {history_str}\n",
    "\n",
    "    摘要：\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 构建 LCEL 链：格式化 -> LLM -> 解析字符串\n",
    "summarizer_chain = summary_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 辅助函数：将消息对象转为字符串，并生成摘要\n",
    "def get_current_summary(chat_history):\n",
    "    # 将 Message 对象列表转换为文本字符串\n",
    "    history_str = \"\\n\".join([f\"{msg.type}: {msg.content}\" for msg in chat_history.messages])\n",
    "    # 调用链生成摘要\n",
    "    return summarizer_chain.invoke({\"history_str\": history_str})\n",
    "\n",
    "# =========================================================\n",
    "# 4. 操作流程演示\n",
    "# =========================================================\n",
    "\n",
    "# A. 打印初始摘要\n",
    "print(\"\\n[操作 1] 生成初始摘要...\")\n",
    "summary_v1 = get_current_summary(history)\n",
    "print(f\"摘要内容: {summary_v1}\")\n",
    "\n",
    "# B. 添加新对话\n",
    "print(\"\\n[操作 2] 添加新对话...\")\n",
    "history.add_user_message(\"我的名字叫小明\")\n",
    "history.add_ai_message(\"很高兴认识你\")\n",
    "\n",
    "# C. 再次生成摘要\n",
    "print(\"\\n[操作 3] 生成更新后的摘要...\")\n",
    "summary_v2 = get_current_summary(history)\n",
    "print(f\"摘要内容: {summary_v2}\")\n",
    "\n",
    "# D. 查看原始消息\n",
    "print(\"\\n[操作 4] 查看完整历史记录...\")\n",
    "print(history.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8c2e6f",
   "metadata": {},
   "source": [
    "# 3、ConversationSummaryBufferMemory的使用\n",
    "\n",
    "举例1："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8765b0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Round 1 ---\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "我是小明\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "你好，小明！很高兴见到你。有什么我可以帮你的吗？是想聊聊天，还是有具体的问题需要解答？😊\n",
      "\n",
      "--- Round 2 ---\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "我叫什么？\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "你叫小明！😊 是的，我之前已经知道你的名字了。有什么我可以帮你的吗？\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "# 1. 定义模型\n",
    "llm = ChatOpenAI(\n",
    "    model=os.getenv(\"LLM_MODEL_ID\")\n",
    ")\n",
    "\n",
    "# 2. 定义图 (WorkFlow)\n",
    "# MessagesState 内置了 message 列表，会自动 append 新消息\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# 定义一个节点：直接调用模型\n",
    "def call_model(state: MessagesState):\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# 3. 核心：加上 MemorySaver (Checkpointer)\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 4. 编译成应用\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# 5. 调用 (自动管理历史)\n",
    "config = {\"configurable\": {\"thread_id\": \"user_1\"}} # thread_id 相当于 session_id\n",
    "\n",
    "# 第一轮\n",
    "print(\"--- Round 1 ---\")\n",
    "for chunk in app.stream({\"messages\": [HumanMessage(content=\"我是小明\")]}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# 第二轮 \n",
    "print(\"\\n--- Round 2 ---\")\n",
    "for chunk in app.stream({\"messages\": [HumanMessage(content=\"我叫什么？\")]}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45acd6a4",
   "metadata": {},
   "source": [
    "对比组：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c081b631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Round 1: 自我介绍 ---\n",
      "AI: 你好，小明！很高兴认识你。你是控制工程的研究生，这说明你正在学习一个非常有趣且应用广泛的领域。控制工程涉及系统的设计、分析和优化，广泛应用于工业自动化、机器人技术、航空航天、汽车工程等多个领域。\n",
      "\n",
      "你目前的研究方向是？是控制系统设计、建模与仿真，还是控制算法开发，或者是某个具体应用方向，比如智能控制、鲁棒控制、自适应控制、或者控制理论在新兴技术中的应用？如果你愿意分享，我很乐意和你一起讨论相关课题，或者帮你解答一些技术问题。😊\n",
      "\n",
      "--- Round 2: 聊聊研究方向 ---\n",
      "AI: 你好，小明！很高兴得知你研究的是**多模态水下声学目标识别**这个方向，这是一个非常前沿且具有挑战性的领域。水下声学目标识别在海洋探测、水下机器人、声呐系统、军事水下监控等应用中都非常重要。而“多模态”意味着你可能同时融合了**声学数据**（比如声呐回波）和其他类型的传感器数据（如光学、惯性导航、压力传感器等），这大大增强了目标识别的准确性和鲁棒性。\n",
      "\n",
      "在你研究过程中，可能涉及以下几个方面：\n",
      "\n",
      "---\n",
      "\n",
      "### 📘 1. **多模态数据融合方法**\n",
      "- 你可能会用到**多传感器数据融合技术**（Multiple Sensor Data Fusion），例如贝叶斯网络、卡尔曼滤波、深度学习的多模态融合方法（如CNN+RNN、Transformer、Cross-Attention等）。\n",
      "- 是否考虑了**时空对齐问题**？比如在水下环境中，不同传感器的时间和空间同步是一个关键挑战。\n",
      "\n",
      "---\n",
      "\n",
      "### 🧠 2. **数据预处理与特征提取**\n",
      "- 在水下声学信号处理中，可能会有**噪声干扰**（如海洋环境噪声、多路径效应等），你可能需要做一些**降噪、滤波、去噪**的预处理。\n",
      "- 特征提取方面，常用的方法包括：\n",
      "  - **时频分析**（如STFT、小波变换、CWT）\n",
      "  - **深度学习中的自动特征提取**（如使用CNN、Transformer来提取声学信号或图像的高级特征）\n",
      "  - 对于多模态数据，你可能需要设计融合不同模态的特征表示方式。\n",
      "\n",
      "---\n",
      "\n",
      "### 🤖 3. **深度学习与目标识别模型**\n",
      "- 在当前研究中，**卷积神经网络（CNN）**、**循环神经网络（RNN）**、**Transformer**、**自注意力机制**、以及**多模态融合模型**（如Multimodal Fusion Networks）可能是你用到的工具。\n",
      "- 你是否尝试过使用**迁移学习**，或者从公开的水下声学数据集中进行训练？像**Kaggle**、**NOAA**、**MUlti-Sensor Integrated Sonar Dataset**（MUSIC）等可能有相关数据。\n",
      "\n",
      "---\n",
      "\n",
      "### 🌊 4. **水下环境的特殊性**\n",
      "- 水下环境噪声复杂，信号传播特性与陆地不同（如多途延迟、衰减、非线性传播等），这些都会影响目标识别的性能。\n",
      "- 你是否面临**模型泛化能力不足**、**数据标注困难**、**模型在真实水下环境中的效果受限**等实际问题？\n",
      "\n",
      "---\n",
      "\n",
      "### 📚 5. **常用算法和工具**\n",
      "- **信号处理工具**：MATLAB、Python（NumPy, SciPy）、Simulink、LabVIEW等。\n",
      "- **深度学习框架**：TensorFlow、PyTorch、Keras。\n",
      "- **水下数据集**：你是否使用过如**Underwater Acoustic Target Classification Dataset**（UATCD）、**Swin Transformer-based UAT Dataset**等？\n",
      "- **性能评估指标**：识别准确率、召回率、F1-score、误识别率等。\n",
      "\n",
      "---\n",
      "\n",
      "### 🧩 6. **研究挑战与创新点**\n",
      "- 水下目标识别通常面临**小样本问题**、**数据稀疏性**、**背景噪声复杂性**、**目标运动状态变化**等难点。\n",
      "- 你可能在追求某种**鲁棒性更强的识别方法**，或者开发了新的**特征提取与融合策略**，比如结合声学和视觉信息进行**联合建模**。\n",
      "\n",
      "---\n",
      "\n",
      "如果你愿意，可以和我分享一下你的研究项目、主要技术路线或遇到的挑战，我会尽力提供帮助和建议！你想更深入讨论哪个方面呢？比如模型设计、数据处理，或者仿真验证？😊\n",
      "\n",
      "--- Round 3: 触发总结 (Buffer Overflow) ---\n",
      "AI: 你好，小明！在**多模态水下声学目标识别**领域，**Transformer** 模型近年来确实展现了巨大的潜力，尤其是在处理**长距离依赖**、**时序信息**和**多模态数据融合**方面。它已经被广泛应用于视觉、语音、自然语言处理等领域，而在水下目标识别中也逐渐被探索和应用。\n",
      "\n",
      "---\n",
      "\n",
      "### 🌊 一、Transformer 在水下声学目标识别中的主要应用场景\n",
      "\n",
      "#### 1. **声学信号的特征提取与建模**\n",
      "- Transformer 能够很好地捕捉**声学信号中的长程相关性**，在水下声呐信号处理中尤其有用。\n",
      "- 例如，使用**1D Transformer**来处理**水下声学回波信号**，可以提取出信号中包含的**潜在模式**和**目标特征**，这对识别不同类型的水下目标很有帮助。\n",
      "- **自注意力机制**（Self-Attention）可以动态地关注信号中重要的时序特征，并对噪声或干扰进行某种“滤波”。\n",
      "\n",
      "#### 2. **多模态数据融合**\n",
      "- Transformer 可以用来进行**跨模态对齐和融合**（如声学与光学、雷达、惯性导航等数据的融合）。\n",
      "- 比如，将声学信号和图像（或雷达点云）作为输入，设计**多模态 Transformer**模型（如**Multimodal Transformer Network**），通过**跨模态注意力**机制（Cross-Attention）逐层融合信息，提高最终识别的性能。\n",
      "- 这种方法在**水下机器人系统**和**水下监测系统**（如AUV、UUV）中非常有用。\n",
      "\n",
      "#### 3. **时序建模与目标识别**\n",
      "- 水下目标的声学信号通常具有较强的**时序特性**，比如机动目标的回波信号可能随时间变化。\n",
      "- 使用 Transformer 来处理**连续的声学数据序列**或**传感器数据序列**，可以更好地建模目标的运动状态和声学特征。\n",
      "\n",
      "#### 4. **端到端语音与声呐信号识别**\n",
      "- 在某些研究中，Transformer 被用来构建端到端的识别模型，输入是原始的声学信号，输出是目标类别。\n",
      "- 这种方式简化了传统信号处理流程（如频谱分析、手工特征设计），直接通过深度学习自动学习目标的表征和分类特征。\n",
      "\n",
      "---\n",
      "\n",
      "### 📈 二、Transformer 在水下目标识别中的优势\n",
      "\n",
      "| 优势 | 描述 |\n",
      "|------|------|\n",
      "| **长程依赖建模** | Transformer 可以捕捉很长的信号片段中的依赖关系，有助于识别复杂目标的特征 |\n",
      "| **端到端处理能力** | 可以直接输入原始信号，避免复杂的手工特征设计，简化流程 |\n",
      "| **灵活性与可扩展性** | 可以轻松集成多模态信息，适用于多种传感器数据的融合 |\n",
      "| **鲁棒性增强** | 在噪声环境下，通过注意力机制可以自动聚焦于关键特征 |\n",
      "\n",
      "---\n",
      "\n",
      "### ⚙️ 三、Transformer 在水下目标识别中的一些典型工作/研究方向\n",
      "\n",
      "1. **用于水下声呐信号分类的Transformer模型**\n",
      "   - 研究者使用1D Transformer对**回波信号进行分类**。\n",
      "   - 例如，CSDN、IEEE、Springer等平台有相关论文（如“Transformer for Underwater Acoustic Signal Classification”）。\n",
      "   - 这些模型通常在**水下目标分类数据集**如**Passive Sonar Data (PSD)、Swin Transformer-based UAT Dataset**上进行训练和测试。\n",
      "\n",
      "2. **多模态融合Transformer模型**\n",
      "   - 将声学数据（频域表示）与图像数据（如从水下摄像机、激光雷达等获取）进行融合。\n",
      "   - 使用**Cross-Attention**机制，实现声学与视觉信息的交互建模。\n",
      "   - 比如在水下目标识别任务中，声学数据可以提供目标的整体轮廓或材质信息，视觉数据可以提供目标的表面细节或形状。\n",
      "\n",
      "3. **Transformer 与传统信号处理结合**\n",
      "   - 有时研究者会将**时频变换**（如STFT）与 Transformer 结合使用，认为Transformer更适合建模**变换后的频谱特征**。\n",
      "   - 这种结构非常适合处理水下声学信号的**非平稳性和多路径效应**。\n",
      "\n",
      "4. **Transformer 用于目标检测与追踪**\n",
      "   - 在水下检测系统中，Transformer 可以用于**目标检测与追踪算法**（如YOLO、DETR与Transformer的结合），特别是在**多目标跟踪与行为识别**等任务上。\n",
      "\n",
      "---\n",
      "\n",
      "### 🤯 四、潜在的挑战与问题\n",
      "\n",
      "虽然 Transformer 在水下目标识别中有很多优势，但也面临一些挑战：\n",
      "\n",
      "- **数据稀缺**：水下数据采集成本高，标注困难。\n",
      "- **计算资源需求高**：Transformer 的自注意力机制计算复杂度较高，可能不适用于嵌入式设备或实时系统。\n",
      "- **噪声环境下的鲁棒性**：水下环境噪声复杂，Transformer 对噪声比较敏感，可能需要**噪声鲁棒性增强策略**（如对抗训练、加噪训练等）。\n",
      "- **多模态对齐问题**：不同模态数据在时间或空间上的同步问题需要精心处理。\n",
      "\n",
      "---\n",
      "\n",
      "### 🧬 五、相关研究参考（部分）\n",
      "\n",
      "如果你感兴趣，可以参考以下方向的论文或资料（部分中文资料可能存在，但英文研究论文更为丰富）：\n",
      "\n",
      "- **Transformer for Underwater Acoustic Signal Classification**: 该领域的一些研究使用了Transformer进行回波信号的分类，效果优于传统卷积网络。\n",
      "- **Multi-modal Transformer Network for Underwater Target Recognition**: 使用多模态Transformer进行水下目标识别，常见的数据包括声学与视觉。\n",
      "- **Deep Learning in Underwater Acoustic Target Recognition**: 一些综述文献介绍了深度学习在水下目标识别中的应用，包括Transformer、CNN、RNN等。\n",
      "\n",
      "---\n",
      "\n",
      "### 📌 六、你可以尝试的方向\n",
      "\n",
      "如果想进一步使用Transformer进行水下目标识别，可以考虑：\n",
      "\n",
      "1. **融合多模态数据**（声学 + 光学 + RGB + 激光雷达等）\n",
      "2. **改进Transformer结构**：例如加入**Transformer+CNN混合模型**、**稀疏注意力机制**（如Longformer、BigBird）等，以适应水下数据的特殊性。\n",
      "3. **使用领域适应技术**：处理不同水下环境下的数据差异。\n",
      "4. **探讨模型轻量化与部署优化**：如使用**知识蒸馏**、**剪枝**、**量化**等技术，让Transformer能在嵌入式系统上运行。\n",
      "\n",
      "---\n",
      "\n",
      "如果你正在构建一个基于Transformer的多模态水下目标识别系统，或者遇到了一些技术难题，欢迎随时告诉我！我可以帮你分析模型结构、优化策略、数据处理方法等。🎉\n",
      "\n",
      "========== 状态透视 ==========\n",
      "【长期记忆 (Summary)】: \n",
      "更新后的长期记忆摘要如下：\n",
      "\n",
      "---\n",
      "\n",
      "**长期记忆摘要：**\n",
      "\n",
      "当前对话中，用户小明是一名控制工程的研究生，研究方向为**多模态水下声学目标识别**。该方向结合了**声学数据**与其它传感器数据（如光学、惯性导航、压力传感器等），提升目标识别的准确性与鲁棒性。研究中可能涉及以下关键内容：\n",
      "\n",
      "- **多模态数据融合方法**：如贝叶斯网络、卡尔曼滤波、深度学习中的多模态融合策略（CNN+RNN、Transformer、Cross-Attention等）。\n",
      "- **数据分析与预处理**：面对水下噪声和信号衰减等环境因素，需进行降噪、滤波等处理，并提取有效的特征。\n",
      "- **深度学习模型应用**：可能使用CNN、Transformer、自注意力机制等技术进行目标识别，关注模型在复杂环境下的表现。\n",
      "- **水下环境特殊性**：如多路径效应、信号衰减、噪声干扰、目标运动变化等对识别的影响。\n",
      "- **研究挑战与创新**：如小样本问题、数据标注困难、模型泛化能力不足等，同时可能在特征提取、融合策略或算法优化方面有所创新。\n",
      "\n",
      "小明希望深入探讨该研究中的模型设计、数据处理或仿真验证等方面，对方表现出对该领域的浓厚兴趣和一定的技术积累。后续交流可围绕技术实现、数据来源、模型优化等展开。\n",
      "\n",
      "--- \n",
      "\n",
      "这段摘要覆盖了用户的研究方向、研究内容、方法、挑战及未来可能的讨论方向，便于后续对话的延续与深入。\n",
      "【短期显存 (Buffer)】: ['在这个领域，Transformer模型有什么应用？', '你好，小明！在**多模态水下声学目标识别**领域，**Transformer** 模型近年来确实展现了巨大的潜力，尤其是在处理**长距离依赖**、**时序信息**和**多模态数据融合**方面。它已经被广泛应用于视觉、语音、自然语言处理等领域，而在水下目标识别中也逐渐被探索和应用。\\n\\n---\\n\\n### 🌊 一、Transformer 在水下声学目标识别中的主要应用场景\\n\\n#### 1. **声学信号的特征提取与建模**\\n- Transformer 能够很好地捕捉**声学信号中的长程相关性**，在水下声呐信号处理中尤其有用。\\n- 例如，使用**1D Transformer**来处理**水下声学回波信号**，可以提取出信号中包含的**潜在模式**和**目标特征**，这对识别不同类型的水下目标很有帮助。\\n- **自注意力机制**（Self-Attention）可以动态地关注信号中重要的时序特征，并对噪声或干扰进行某种“滤波”。\\n\\n#### 2. **多模态数据融合**\\n- Transformer 可以用来进行**跨模态对齐和融合**（如声学与光学、雷达、惯性导航等数据的融合）。\\n- 比如，将声学信号和图像（或雷达点云）作为输入，设计**多模态 Transformer**模型（如**Multimodal Transformer Network**），通过**跨模态注意力**机制（Cross-Attention）逐层融合信息，提高最终识别的性能。\\n- 这种方法在**水下机器人系统**和**水下监测系统**（如AUV、UUV）中非常有用。\\n\\n#### 3. **时序建模与目标识别**\\n- 水下目标的声学信号通常具有较强的**时序特性**，比如机动目标的回波信号可能随时间变化。\\n- 使用 Transformer 来处理**连续的声学数据序列**或**传感器数据序列**，可以更好地建模目标的运动状态和声学特征。\\n\\n#### 4. **端到端语音与声呐信号识别**\\n- 在某些研究中，Transformer 被用来构建端到端的识别模型，输入是原始的声学信号，输出是目标类别。\\n- 这种方式简化了传统信号处理流程（如频谱分析、手工特征设计），直接通过深度学习自动学习目标的表征和分类特征。\\n\\n---\\n\\n### 📈 二、Transformer 在水下目标识别中的优势\\n\\n| 优势 | 描述 |\\n|------|------|\\n| **长程依赖建模** | Transformer 可以捕捉很长的信号片段中的依赖关系，有助于识别复杂目标的特征 |\\n| **端到端处理能力** | 可以直接输入原始信号，避免复杂的手工特征设计，简化流程 |\\n| **灵活性与可扩展性** | 可以轻松集成多模态信息，适用于多种传感器数据的融合 |\\n| **鲁棒性增强** | 在噪声环境下，通过注意力机制可以自动聚焦于关键特征 |\\n\\n---\\n\\n### ⚙️ 三、Transformer 在水下目标识别中的一些典型工作/研究方向\\n\\n1. **用于水下声呐信号分类的Transformer模型**\\n   - 研究者使用1D Transformer对**回波信号进行分类**。\\n   - 例如，CSDN、IEEE、Springer等平台有相关论文（如“Transformer for Underwater Acoustic Signal Classification”）。\\n   - 这些模型通常在**水下目标分类数据集**如**Passive Sonar Data (PSD)、Swin Transformer-based UAT Dataset**上进行训练和测试。\\n\\n2. **多模态融合Transformer模型**\\n   - 将声学数据（频域表示）与图像数据（如从水下摄像机、激光雷达等获取）进行融合。\\n   - 使用**Cross-Attention**机制，实现声学与视觉信息的交互建模。\\n   - 比如在水下目标识别任务中，声学数据可以提供目标的整体轮廓或材质信息，视觉数据可以提供目标的表面细节或形状。\\n\\n3. **Transformer 与传统信号处理结合**\\n   - 有时研究者会将**时频变换**（如STFT）与 Transformer 结合使用，认为Transformer更适合建模**变换后的频谱特征**。\\n   - 这种结构非常适合处理水下声学信号的**非平稳性和多路径效应**。\\n\\n4. **Transformer 用于目标检测与追踪**\\n   - 在水下检测系统中，Transformer 可以用于**目标检测与追踪算法**（如YOLO、DETR与Transformer的结合），特别是在**多目标跟踪与行为识别**等任务上。\\n\\n---\\n\\n### 🤯 四、潜在的挑战与问题\\n\\n虽然 Transformer 在水下目标识别中有很多优势，但也面临一些挑战：\\n\\n- **数据稀缺**：水下数据采集成本高，标注困难。\\n- **计算资源需求高**：Transformer 的自注意力机制计算复杂度较高，可能不适用于嵌入式设备或实时系统。\\n- **噪声环境下的鲁棒性**：水下环境噪声复杂，Transformer 对噪声比较敏感，可能需要**噪声鲁棒性增强策略**（如对抗训练、加噪训练等）。\\n- **多模态对齐问题**：不同模态数据在时间或空间上的同步问题需要精心处理。\\n\\n---\\n\\n### 🧬 五、相关研究参考（部分）\\n\\n如果你感兴趣，可以参考以下方向的论文或资料（部分中文资料可能存在，但英文研究论文更为丰富）：\\n\\n- **Transformer for Underwater Acoustic Signal Classification**: 该领域的一些研究使用了Transformer进行回波信号的分类，效果优于传统卷积网络。\\n- **Multi-modal Transformer Network for Underwater Target Recognition**: 使用多模态Transformer进行水下目标识别，常见的数据包括声学与视觉。\\n- **Deep Learning in Underwater Acoustic Target Recognition**: 一些综述文献介绍了深度学习在水下目标识别中的应用，包括Transformer、CNN、RNN等。\\n\\n---\\n\\n### 📌 六、你可以尝试的方向\\n\\n如果想进一步使用Transformer进行水下目标识别，可以考虑：\\n\\n1. **融合多模态数据**（声学 + 光学 + RGB + 激光雷达等）\\n2. **改进Transformer结构**：例如加入**Transformer+CNN混合模型**、**稀疏注意力机制**（如Longformer、BigBird）等，以适应水下数据的特殊性。\\n3. **使用领域适应技术**：处理不同水下环境下的数据差异。\\n4. **探讨模型轻量化与部署优化**：如使用**知识蒸馏**、**剪枝**、**量化**等技术，让Transformer能在嵌入式系统上运行。\\n\\n---\\n\\n如果你正在构建一个基于Transformer的多模态水下目标识别系统，或者遇到了一些技术难题，欢迎随时告诉我！我可以帮你分析模型结构、优化策略、数据处理方法等。🎉']\n",
      "【验证】: 原始的小明身份信息是否已从 Buffer 中删除？ -> True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from typing import Literal\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 1. 定义模型\n",
    "llm = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "# =================================================================\n",
    "# 2. 定义状态 (State Schema)\n",
    "# =================================================================\n",
    "class AgentState(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# =================================================================\n",
    "# 3. 定义逻辑节点 (Nodes)\n",
    "# =================================================================\n",
    "def call_model(state: AgentState):\n",
    "    \"\"\"主对话节点：负责调用大模型\"\"\"\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # --- 逻辑 A: 注入长期记忆 ---\n",
    "    # 如果有摘要，将其作为 SystemMessage 插入上下文的最前端\n",
    "    if summary:\n",
    "        system_message = SystemMessage(content=f\"【长期记忆摘要】\\n{summary}\")\n",
    "        # 注意：这里我们构造一个临时的消息列表传给 LLM，不修改 state 里的实际存储\n",
    "        messages = [system_message] + messages\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def summarize_conversation(state: AgentState):\n",
    "    \"\"\"记忆整理节点：负责将旧对话压缩为摘要 (Buffer -> Summary)\"\"\"\n",
    "    \n",
    "    # --- 逻辑 B: 缓冲区控制 (Buffer Logic) ---\n",
    "    stored_messages = state[\"messages\"]\n",
    "    \n",
    "    if len(stored_messages) <= 2:\n",
    "        return {} # 没达到阈值，跳过\n",
    "    \n",
    "    # 1. 切分：找出需要被“压缩”的旧消息\n",
    "    to_summarize = stored_messages[:-2]\n",
    "    \n",
    "    # 2. 生成摘要：基于“旧摘要” + “待压缩消息”生成“新摘要”\n",
    "    current_summary = state.get(\"summary\", \"\")\n",
    "    summary_prompt = ChatPromptTemplate.from_template(\n",
    "        \"当前长期记忆：{summary}\\n\\n新增对话片段：\\n{new_lines}\\n\\n请将新增对话合并入长期记忆，生成一段更新后的精炼摘要：\"\n",
    "    )\n",
    "    chain = summary_prompt | llm | StrOutputParser()\n",
    "    \n",
    "    conversation_str = \"\\n\".join([f\"{m.type}: {m.content}\" for m in to_summarize])\n",
    "    new_summary = chain.invoke({\"summary\": current_summary, \"new_lines\": conversation_str})\n",
    "    \n",
    "    # 3. 物理删除：关键步骤\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in to_summarize]\n",
    "    \n",
    "    return {\"summary\": new_summary, \"messages\": delete_messages}\n",
    "\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"边逻辑：决定是否触发记忆整理\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # 阈值判断：如果原文超过 4 条，就触发总结\n",
    "    if len(messages) > 4:\n",
    "        return \"summarize_conversation\"\n",
    "    return END\n",
    "\n",
    "# =================================================================\n",
    "# 4. 构建图 (Graph Construction)\n",
    "# =================================================================\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 添加节点\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(\"summarize_conversation\", summarize_conversation)\n",
    "\n",
    "# 定义流向\n",
    "# 开始 -> 对话 -> 判断(是否太长?) -> 总结 -> 结束\n",
    "#                   |\n",
    "#                   V\n",
    "#                  结束\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# 编译应用\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# =================================================================\n",
    "# 5. 运行演示\n",
    "# =================================================================\n",
    "# 只要 thread_id 不变，记忆就会一直存在（并自动被压缩）\n",
    "config = {\"configurable\": {\"thread_id\": \"v1_user_test\"}}\n",
    "\n",
    "print(\"--- Round 1: 自我介绍 ---\")\n",
    "# 此时 buffer 为空，直接回复\n",
    "input1 = \"你好，我是小明。我是一名控制工程的研究生。\"\n",
    "resp1 = app.invoke({\"messages\": [HumanMessage(content=input1)]}, config)\n",
    "print(f\"AI: {resp1['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n--- Round 2: 聊聊研究方向 ---\")\n",
    "# 此时 buffer 有 2 条，未触发总结\n",
    "input2 = \"我主要研究多模态水下声学目标识别。\"\n",
    "resp2 = app.invoke({\"messages\": [HumanMessage(content=input2)]}, config)\n",
    "print(f\"AI: {resp2['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n--- Round 3: 触发总结 (Buffer Overflow) ---\")\n",
    "# 此时 buffer 将达到 6 条 > 阈值 4。\n",
    "# 系统将自动执行 summarize_conversation：\n",
    "# 1. 把 Round 1 (身份) 和 Round 2 (研究方向) 压缩进 summary\n",
    "# 2. 删除 Round 1 和 Round 2 的原始消息\n",
    "# 3. 只保留 Round 3 的原文\n",
    "input3 = \"在这个领域，Transformer模型有什么应用？\"\n",
    "resp3 = app.invoke({\"messages\": [HumanMessage(content=input3)]}, config)\n",
    "print(f\"AI: {resp3['messages'][-1].content}\")\n",
    "\n",
    "# =================================================================\n",
    "# 6. 验证状态\n",
    "# =================================================================\n",
    "print(\"\\n========== 状态透视 ==========\")\n",
    "snapshot = app.get_state(config)\n",
    "current_summary = snapshot.values.get(\"summary\")\n",
    "current_messages = snapshot.values.get(\"messages\")\n",
    "\n",
    "print(f\"【长期记忆 (Summary)】: \\n{current_summary}\")\n",
    "print(f\"【短期显存 (Buffer)】: {[m.content for m in current_messages]}\")\n",
    "print(f\"【验证】: 原始的小明身份信息是否已从 Buffer 中删除？ -> {'我是小明' not in str(current_messages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23a0464",
   "metadata": {},
   "source": [
    "举例2：模拟客服交互"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3506e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 开始对话 (Thread ID: customer_123) ===\n",
      "\n",
      "--- Round 1 ---\n",
      "用户: 你好，我想查询订单12345的状态\n",
      "客服: 您好！很高兴为您服务。请问订单号12345的订单是通过哪个平台或店铺下单的呢？这样我可以更准确地帮您查询订单状态。\n",
      "\n",
      "--- Round 2 ---\n",
      "用户: 这个订单是上周五下的\n",
      "客服: 您好，感谢您的补充！订单12345是上周五下的，我这就为您查询最新的订单状态。请您稍等片刻，我尽快为您反馈相关信息。如果需要其他帮助，也欢迎随时告诉我！\n",
      "\n",
      "--- Round 3 ---\n",
      "用户: 我现在急着用，能加急处理吗\n",
      "客服: 您好，理解您的急迫心情！我们非常重视您的需求，订单12345已经为您标记为加急处理，会优先安排物流和配送。请您保持电话畅通或关注短信通知，以便我们及时与您联系。如果还有其他问题，欢迎随时告知！祝您一切顺利！\n",
      "\n",
      "--- Round 4 ---\n",
      "用户: 等等，我可能记错订单号了，应该是12346\n",
      "客服: 您好，感谢您的提醒！您可能记错了订单号，我们刚刚收到新的订单号12346的信息。为了确保准确无误，请您确认一下订单号是否正确，或者提供一些订单的其他信息（如购买时间、商品名称等），我们可以帮您进一步核实。再次感谢您的理解与配合！\n",
      "\n",
      "--- Round 5 ---\n",
      "用户: 对了，你们退货政策是怎样的\n",
      "客服: 您好，感谢您的提问！我们的退货政策如下：\n",
      "\n",
      "如果您对商品不满意，可以在签收后 **7天内** 申请无理由退货（部分特殊商品除外，如定制类、易损耗品等，具体以商品页面说明为准）。退货时请保留商品的原始包装和发票，确保商品完好无损。\n",
      "\n",
      "申请退货的流程是：  \n",
      "1. 登录您的账户，进入“我的订单”页面；  \n",
      "2. 找到对应订单，点击“申请退货”；  \n",
      "3. 填写退货原因并提交；  \n",
      "4. 我们会在**24小时内**审核并通知您退货结果。\n",
      "\n",
      "如果需要帮助，我们也可以协助您完成退货操作哦！祝您购物愉快！\n",
      "\n",
      "\n",
      "=== 最终记忆透视 ===\n",
      "【长期摘要 (Summary)】:\n",
      "当前摘要：  \n",
      "用户询问订单状态，最初提到订单号12345，AI确认该订单的下单时间为上周五，并正在查询其最新状态，请求用户稍等。随后用户表示可能记错了订单号，应为12346，AI确认已收到新订单号12346的信息，并建议用户确认订单号是否正确或提供其他相关信息（如购买时间、商品名称等）以便进一步核实。同时，AI保持开放态度，表示如需其他帮助，随时可以告知。\n",
      "\n",
      "【短期原文 (Buffer)】 (2条):\n",
      "  [human]: 对了，你们退货政策是怎样的\n",
      "  [ai]: 您好，感谢您的提问！我们的退货政策如下：\n",
      "\n",
      "如果您对商品不满意，可以在签收后 **7天内** 申请无理由退货（部分特殊商品除外，如定制类、易损耗品等，具体以商品页面说明为准）。退货时请保留商品的原始包装和发票，确保商品完好无损。\n",
      "\n",
      "申请退货的流程是：  \n",
      "1. 登录您的账户，进入“我的订单”页面；  \n",
      "2. 找到对应订单，点击“申请退货”；  \n",
      "3. 填写退货原因并提交；  \n",
      "4. 我们会在**24小时内**审核并通知您退货结果。\n",
      "\n",
      "如果需要帮助，我们也可以协助您完成退货操作哦！祝您购物愉快！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from typing import Literal\n",
    "\n",
    "# 1. 导入核心组件\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 2. 导入 LangGraph 组件 (必须安装 langgraph)\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 加载环境变量\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# =========================================================\n",
    "# 3. 配置模型与状态\n",
    "# =========================================================\n",
    "llm = ChatOpenAI(\n",
    "    model=os.getenv(\"LLM_MODEL_ID\"), \n",
    ")\n",
    "\n",
    "# 定义状态：继承默认的 MessagesState，并额外增加 summary 字段\n",
    "class AgentState(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# =========================================================\n",
    "# 4. 定义逻辑节点 (Nodes)\n",
    "# =========================================================\n",
    "\n",
    "def call_model(state: AgentState):\n",
    "    \"\"\"主对话节点：负责生成回复\"\"\"\n",
    "    \n",
    "    # A. 获取状态\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # B. 构造 System Prompt (包含人设 + 长期记忆摘要)\n",
    "    # 这是电商客服的人设\n",
    "    persona = \"你是电商客服助手，用中文友好回复用户问题。保持专业但亲切的语气。\"\n",
    "    \n",
    "    if summary:\n",
    "        system_msg_content = f\"{persona}\\n\\n【之前的对话摘要】: {summary}\"\n",
    "    else:\n",
    "        system_msg_content = persona\n",
    "        \n",
    "    # C. 构造临时消息列表传给 LLM (System + History)\n",
    "    # 注意：不修改 state[\"messages\"]，只是临时组合发给模型\n",
    "    messages_for_llm = [SystemMessage(content=system_msg_content)] + messages\n",
    "    \n",
    "    response = llm.invoke(messages_for_llm)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def summarize_conversation(state: AgentState):\n",
    "    \"\"\"记忆整理节点：核心优化点 (Buffer -> Summary)\"\"\"\n",
    "    \n",
    "    stored_messages = state[\"messages\"]\n",
    "    \n",
    "    # 阈值控制：如果消息少于等于 4 条 (2轮)，就不总结\n",
    "    if len(stored_messages) <= 4:\n",
    "        return {}\n",
    "    \n",
    "    # 1. 切分：保留最后 2 条原文，前面的全部去总结\n",
    "    to_summarize = stored_messages[:-2]\n",
    "    \n",
    "    # 2. 生成摘要\n",
    "    current_summary = state.get(\"summary\", \"\")\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"当前摘要: {summary}\\n\\n新增对话:\\n{new_lines}\\n\\n请将新增对话合并到摘要中，保留关键信息(如订单号、意图):\"\n",
    "    )\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    \n",
    "    conversation_str = \"\\n\".join([f\"{m.type}: {m.content}\" for m in to_summarize])\n",
    "    new_summary = chain.invoke({\"summary\": current_summary, \"new_lines\": conversation_str})\n",
    "    \n",
    "    # 3. 物理删除：从状态中移除旧消息，释放 Context Window\n",
    "    delete_ops = [RemoveMessage(id=m.id) for m in to_summarize]\n",
    "    \n",
    "    return {\"summary\": new_summary, \"messages\": delete_ops}\n",
    "\n",
    "\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"边逻辑：决定是否触发总结\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    # 如果消息超过 4 条，就去总结\n",
    "    if len(messages) > 4:\n",
    "        return \"summarize_conversation\"\n",
    "    return END\n",
    "\n",
    "# =========================================================\n",
    "# 5. 构建图 (Graph)\n",
    "# =========================================================\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(\"summarize_conversation\", summarize_conversation)\n",
    "\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# 启用持久化记忆\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# =========================================================\n",
    "# 6. 执行对话 (模拟用户输入)\n",
    "# =========================================================\n",
    "dialogue_inputs = [\n",
    "    \"你好，我想查询订单12345的状态\",\n",
    "    \"这个订单是上周五下的\",\n",
    "    \"我现在急着用，能加急处理吗\",\n",
    "    \"等等，我可能记错订单号了，应该是12346\",\n",
    "    \"对了，你们退货政策是怎样的\"\n",
    "]\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"customer_123\"}}\n",
    "\n",
    "print(f\"=== 开始对话 (Thread ID: {config['configurable']['thread_id']}) ===\\n\")\n",
    "\n",
    "for i, user_input in enumerate(dialogue_inputs):\n",
    "    print(f\"--- Round {i+1} ---\")\n",
    "    print(f\"用户: {user_input}\")\n",
    "    \n",
    "    # 调用图\n",
    "    events = app.stream(\n",
    "        {\"messages\": [HumanMessage(content=user_input)]}, \n",
    "        config, \n",
    "        stream_mode=\"values\"\n",
    "    )\n",
    "    \n",
    "    # 获取最后一次输出\n",
    "    last_response = None\n",
    "    for event in events:\n",
    "        if \"messages\" in event:\n",
    "            last_response = event[\"messages\"][-1]\n",
    "            \n",
    "    print(f\"客服: {last_response.content}\\n\")\n",
    "\n",
    "# =========================================================\n",
    "# 7. 查看当前记忆状态\n",
    "# =========================================================\n",
    "print(\"\\n=== 最终记忆透视 ===\")\n",
    "snapshot = app.get_state(config)\n",
    "summary = snapshot.values.get(\"summary\")\n",
    "buffer_msgs = snapshot.values.get(\"messages\")\n",
    "\n",
    "print(f\"【长期摘要 (Summary)】:\\n{summary}\")\n",
    "print(f\"\\n【短期原文 (Buffer)】 ({len(buffer_msgs)}条):\")\n",
    "for m in buffer_msgs:\n",
    "    print(f\"  [{m.type}]: {m.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870bcdd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
