{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af748e8f",
   "metadata": {},
   "source": [
    "# 1、字符串输出解析器 StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8368c44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "大语言模型是指一种能够生成自然语言文本的机器学习模型，这些模型通常基于深层神经网络结构，如变换器（Transformer）架构，具有大量的参数（通常超过百万级甚至亿级参数）。大语言模型通过对大量文本数据进行训练，可以理解和生成与人类相似的自然语言文本，具备强大的语言理解和生成能力。\n",
      "\n",
      "大语言模型能够完成的任务范围广泛，包括但不限于文本补全、机器翻译、情感分析、问答系统、文本分类、摘要生成等。在近年来自然语言处理领域取得了重要进展，成为诸多文本生成任务的有力工具。代表性的大语言模型包括但不限于：阿里云的通义千问、谷歌的LaMDA、百度的文心一言、阿里云的通义万相、百度ERNIE等。\n"
     ]
    }
   ],
   "source": [
    "# 1、获取大模型\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser, XMLOutputParser\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_core.utils import pre_init\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "chat_model = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "# 2、调用大模型\n",
    "response = chat_model.invoke(\"什么是大语言模型？\")\n",
    "# print(type(response))   # AIMessage\n",
    "\n",
    "# 3、如何获取一个字符串的输出结果呢？\n",
    "# # 方式1：自己调用输出结果的content\n",
    "# print(response.content)\n",
    "\n",
    "# 方式2：使用StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "str_response = parser.invoke(response)\n",
    "print(type(str_response))  # <class 'str'>\n",
    "print(str_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd2e113",
   "metadata": {},
   "source": [
    "# 2、JsonOutputParser : Json输出解析器\n",
    "\n",
    "方式1："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3986bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q': '人工智能用英文怎么说？', 'a': '人工智能用英文说为Artificial Intelligence (AI)'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_model = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个靠谱的{role}\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# 正确的：\n",
    "prompt = chat_prompt_template.invoke(\n",
    "    input={\"role\": \"人工智能专家\", \"question\": \"人工智能用英文怎么说？问题用q表示，答案用a表示，返回一个JSON格式的数据\"})\n",
    "\n",
    "# 错误的：\n",
    "# prompt = chat_prompt_template.invoke(input={\"role\":\"人工智能专家\",\"question\":\"人工智能用英文怎么说？\"})\n",
    "\n",
    "response = chat_model.invoke(prompt)\n",
    "# print(response.content)\n",
    "\n",
    "# 获取一个JsonOutputParser的实例\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "json_result = parser.invoke(response)\n",
    "print(json_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebf04f0",
   "metadata": {},
   "source": [
    "方式2：\n",
    "\n",
    "举例1："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b48e38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return a JSON object.\n"
     ]
    }
   ],
   "source": [
    "parser = JsonOutputParser()\n",
    "\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcce78c6",
   "metadata": {},
   "source": [
    "举例2："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30e24802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```json\\n{\\n  \"joke\": \"为什么电脑经常生病？因为窗户（Windows）总是开着！\"\\n}\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 52, 'total_tokens': 78, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'Qwen/Qwen2.5-7B-Instruct', 'system_fingerprint': '', 'id': '019bf9036ae9f033638cd9c64685e96b', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019bf903-6d88-71c3-8ff1-7690fd2a1514-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 52, 'output_tokens': 26, 'total_tokens': 78, 'input_token_details': {}, 'output_token_details': {}}\n",
      "{'joke': '为什么电脑经常生病？因为窗户（Windows）总是开着！'}\n"
     ]
    }
   ],
   "source": [
    "# 引入依赖包\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 初始化语言模型\n",
    "chat_model = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "joke_query = \"告诉我一个笑话。\"\n",
    "\n",
    "# 定义Json解析器\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# 以PromptTemplate为例\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"回答用户的查询\\n 满足的格式为{format_instructions}\\n 问题为{question}\\n\",\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke(input={\"question\": joke_query})\n",
    "response = chat_model.invoke(prompt)\n",
    "print(response)\n",
    "\n",
    "json_result = parser.invoke(response)\n",
    "print(json_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671cb5aa",
   "metadata": {},
   "source": [
    "知识的拓展： |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "665f97f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q': '人工智能用英文怎么说？', 'a': 'Artificial Intelligence (AI)'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_model = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个靠谱的{role}\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# 获取一个JsonOutputParser的实例\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# 写法1：\n",
    "# prompt = chat_prompt_template.invoke(input={\"role\":\"人工智能专家\",\"question\":\"人工智能用英文怎么说？问题用q表示，答案用a表示，返回一个JSON格式的数据\"})\n",
    "#\n",
    "# response = chat_model.invoke(prompt)\n",
    "#\n",
    "# json_result = parser.invoke(response)\n",
    "# print(json_result)\n",
    "\n",
    "# 写法2：\n",
    "chain = chat_prompt_template | chat_model | parser\n",
    "json_result1 = chain.invoke(\n",
    "    input={\"role\": \"人工智能专家\", \"question\": \"人工智能用英文怎么说？问题用q表示，答案用a表示，返回一个JSON格式的数据\"}\n",
    "    )\n",
    "print(json_result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7743d2e3",
   "metadata": {},
   "source": [
    "针对于举例2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a4a6112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': '为什么电脑经常生病？因为窗户（windings）总是开着！'}\n"
     ]
    }
   ],
   "source": [
    "# 引入依赖包\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 初始化语言模型\n",
    "chat_model = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "joke_query = \"告诉我一个笑话。\"\n",
    "\n",
    "# 定义Json解析器\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# 以PromptTemplate为例\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"回答用户的查询\\n 满足的格式为{format_instructions}\\n 问题为{question}\\n\",\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "# 写法1：\n",
    "# prompt = prompt_template.invoke(input={\"question\":joke_query})\n",
    "# response = chat_model.invoke(prompt)\n",
    "# json_result = parser.invoke(response)\n",
    "\n",
    "chain = prompt_template | chat_model | parser\n",
    "json_result = chain.invoke(input={\"question\": joke_query})\n",
    "print(json_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a29f3c2",
   "metadata": {},
   "source": [
    "# 3、XMLOutputParser XML输出解析器的使用\n",
    "\n",
    "举例1：自己在提示词模板中写明使用XML格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1671c5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "当然可以。这里有一个简短的周星驰电影记录供您参考：\n",
      "\n",
      "```html\n",
      "<movie>\n",
      "    <title>大话西游之月光宝盒</title>\n",
      "    <year>1995</year>\n",
      "    <director>周星驰</director>\n",
      "    <actor>\n",
      "        <name>周星驰</name>\n",
      "        <name>朱茵</name>\n",
      "    </actor>\n",
      "    <genre>奇幻、喜剧</genre>\n",
      "    <description>这部影片讲述了迟来的唐僧从月宫盗取月光宝盒，由此引发了蛛丝马迹的爱情、误会交织的故事。</description>\n",
      "</movie>\n",
      "```\n",
      "\n",
      "这个示例呈现了《大话西游之月光宝盒》的部分基本信息，包括电影名称、主演和简要描述等。如果有更多电影需要记录，可以按照这样的结构进行添加。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "chat_model = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "actor_query = \"周星驰的简短电影记录\"\n",
    "response = chat_model.invoke(f\"请生成{actor_query}，将影片附在<movie></movie>标签中\")\n",
    "\n",
    "print(type(response))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68492ce",
   "metadata": {},
   "source": [
    "举例2："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876274c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a XML file.\n",
      "1. Output should conform to the tags below.\n",
      "2. If tags are not given, make them on your own.\n",
      "3. Remember to always open and close all the tags.\n",
      "\n",
      "As an example, for the tags [\"foo\", \"bar\", \"baz\"]:\n",
      "1. String \"<foo>\n",
      "   <bar>\n",
      "      <baz></baz>\n",
      "   </bar>\n",
      "</foo>\" is a well-formatted instance of the schema.\n",
      "2. String \"<foo>\n",
      "   <bar>\n",
      "   </foo>\" is a badly-formatted instance.\n",
      "3. String \"<foo>\n",
      "   <tag>\n",
      "   </tag>\n",
      "</foo>\" is a badly-formatted instance.\n",
      "\n",
      "Here are the output tags:\n",
      "```\n",
      "None\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers.xml import XMLOutputParser\n",
    "\n",
    "parser = XMLOutputParser()\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466a0902",
   "metadata": {},
   "source": [
    "使用parser.get_format_instructions()结构实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f748102d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TomHanks>\n",
      "   <影片记录>\n",
      "      <电影名称>阿甘正传</电影名称>\n",
      "      <上映年份>1994</上映年份>\n",
      "      <电影名称>拯救大兵瑞恩</电影名称>\n",
      "      <上映年份>1998</上映年份>\n",
      "      <电影名称>欲望城市</电影名称>\n",
      "      <上映年份>2008</上映年份>\n",
      "   </影片记录>\n",
      "</TomHanks>\n"
     ]
    }
   ],
   "source": [
    "# 1.导入相关包\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 2. 初始化语言模型\n",
    "chat_model = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "# 3.测试模型的xml解析效果\n",
    "actor_query = \"生成汤姆·汉克斯的简短电影记录,使用中文回复\"\n",
    "\n",
    "# 4.定义XMLOutputParser对象\n",
    "parser = XMLOutputParser()\n",
    "\n",
    "# 5. 生成提示词模板\n",
    "prompt_template1 = PromptTemplate.from_template(\n",
    "    template=\"用户的问题：{query}\\n使用的格式：{format_instructions}\"\n",
    ")\n",
    "\n",
    "prompt_template2 = prompt_template1.partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "\n",
    "response = chat_model.invoke(prompt_template2.invoke(input={\"query\": actor_query}))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af173ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TomHanks': [{'影片记录': [{'电影名称': '阿甘正传'}, {'上映年份': '1994'}, {'电影名称': '拯救大兵瑞恩'}, {'上映年份': '1998'}, {'电影名称': '欲望城市'}, {'上映年份': '2008'}]}]}\n"
     ]
    }
   ],
   "source": [
    "xml_result = parser.invoke(response)\n",
    "print(xml_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad067920",
   "metadata": {},
   "source": [
    "# 4、列表解析器 CommaSeparatedListOutputParser\n",
    "\n",
    "举例1："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d398d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n",
      "['大象', '猩猩', '狮子']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# 返回一些指令或模板，这些指令告诉系统如何解析或格式化输出数据\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)\n",
    "\n",
    "messages = \"大象,猩猩,狮子\"\n",
    "result = output_parser.parse(messages)\n",
    "print(result)\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4bb613",
   "metadata": {},
   "source": [
    "举例2："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce2682b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['科幻电影', '爱情电影', '动作电影', '喜剧电影', '悬疑电影']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "# 初始化语言模型\n",
    "chat_model = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "# 创建解析器\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# 创建LangChain提示模板\n",
    "chat_prompt = PromptTemplate.from_template(\n",
    "    \"生成5个关于{text}的列表.\\n\\n{format_instructions}\",\n",
    "    partial_variables={\n",
    "    \"format_instructions\": output_parser.get_format_instructions()\n",
    "    })\n",
    "\n",
    "# 提示模板与输出解析器传递输出\n",
    "# chat_prompt = chat_prompt.partial(format_instructions=output_parser.get_format_instructions())\n",
    "\n",
    "# 将提示和模型合并以进行调用\n",
    "chain = chat_prompt | chat_model | output_parser\n",
    "res = chain.invoke({\"text\": \"电影\"})\n",
    "print(res)\n",
    "print(type(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2023bcf",
   "metadata": {},
   "source": [
    "# 5、日期解析器 DatetimeOutputParser（太老了，已经被移除）\n",
    "\n",
    "举例1："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b376ae62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 指令内容 ===\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"date_value\": {\"description\": \"事件发生的日期，必须严格使用 YYYY-MM-DD 格式 (ISO 8601)\", \"format\": \"date-time\", \"title\": \"Date Value\", \"type\": \"string\"}}, \"required\": [\"date_value\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. 定义一个只包含日期的结构\n",
    "class DateResponse(BaseModel):\n",
    "    date_value: datetime = Field(description=\"事件发生的日期，必须严格使用 YYYY-MM-DD 格式 (ISO 8601)\")\n",
    "\n",
    "# 2. 使用 PydanticOutputParser\n",
    "output_parser = PydanticOutputParser(pydantic_object=DateResponse)\n",
    "\n",
    "# 3. 获取格式指令\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "print(\"=== 指令内容 ===\")\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6074cc7a",
   "metadata": {},
   "source": [
    "举例2：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "970fdf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日期: 1949-10-01 00:00:00+00:00\n",
      "格式化: 1949-10-01\n",
      "类型: <class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1. 定义你想要的数据结构\n",
    "class TimeResponse(BaseModel):\n",
    "    date_value: datetime = Field(description=\"The date of the event\")\n",
    "\n",
    "# 2. 初始化模型\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "llm = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "# 3. 使用 v1.x 的核心方法 .with_structured_output()\n",
    "structured_llm = llm.with_structured_output(TimeResponse)\n",
    "\n",
    "# 4. 直接调用\n",
    "try:\n",
    "    response = structured_llm.invoke(\"中华人民共和国是什么时候成立的？\")\n",
    "    print(f\"日期: {response.date_value}\") # 直接拿到 datetime 对象\n",
    "    print(f\"格式化: {response.date_value.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"类型: {type(response.date_value)}\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
