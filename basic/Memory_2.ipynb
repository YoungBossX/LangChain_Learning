{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ef6a32",
   "metadata": {},
   "source": [
    "# 1ã€InMemoryChatMessageHistoryçš„ä½¿ç”¨\n",
    "\n",
    "åœºæ™¯1ï¼šè®°å¿†å­˜å‚¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d83c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='ä½ å¥½', additional_kwargs={}, response_metadata={}), AIMessage(content='å¾ˆé«˜å…´è®¤è¯†ä½ ', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 1ã€ChatMessageHistoryçš„å®ä¾‹åŒ–\n",
    "history = InMemoryChatMessageHistory()\n",
    "\n",
    "# 2ã€æ·»åŠ ç›¸å…³çš„æ¶ˆæ¯è¿›è¡Œå­˜å‚¨\n",
    "\n",
    "history.add_user_message(\"ä½ å¥½\")\n",
    "\n",
    "history.add_ai_message(\"å¾ˆé«˜å…´è®¤è¯†ä½ \")\n",
    "\n",
    "# 3ã€æ‰“å°å­˜å‚¨çš„æ¶ˆæ¯\n",
    "print(history.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633dad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è·å–å¤§æ¨¡å‹\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "# åˆ›å»ºå¤§æ¨¡å‹å®ä¾‹\n",
    "llm = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02409d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ ¹æ®æ•°å­¦ä¸­çš„è¿ç®—è§„åˆ™ï¼Œä¹˜æ³•ä¼˜å…ˆäºåŠ æ³•ã€‚æ‰€ä»¥ï¼Œ1 + 2 * 3 åº”è¯¥å…ˆè®¡ç®—ä¹˜æ³•éƒ¨åˆ†ï¼š\n",
      "\n",
      "2 * 3 = 6\n",
      "\n",
      "ç„¶åå°†ç»“æœåŠ åˆ°1ä¸Šï¼š\n",
      "\n",
      "1 + 6 = 7\n",
      "\n",
      "å› æ­¤ï¼Œ1 + 2 * 3 çš„ç»“æœæ˜¯ 7ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "history = InMemoryChatMessageHistory()\n",
    "\n",
    "# 2ã€æ·»åŠ ç›¸å…³çš„æ¶ˆæ¯è¿›è¡Œå­˜å‚¨\n",
    "history.add_user_message(\"ä½ å¥½\")\n",
    "history.add_ai_message(\"å¾ˆé«˜å…´è®¤è¯†ä½ \")\n",
    "history.add_user_message(\"å¸®æˆ‘è®¡ç®—1 + 2 * 3 = ï¼Ÿ\")\n",
    "\n",
    "response = llm.invoke(history.messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817b790e",
   "metadata": {},
   "source": [
    "# 2ã€InMemoryChatMessageHistoryçš„ä½¿ç”¨\n",
    "\n",
    "ä¸¾ä¾‹1ï¼šä»¥å­—ç¬¦ä¸²çš„æ–¹å¼è¿”å›å­˜å‚¨çš„ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47543431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='ä½ å¥½ï¼Œæˆ‘å«å°æ˜', additional_kwargs={}, response_metadata={}), AIMessage(content='å¾ˆé«˜å…´è®¤è¯†ä½ ', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='å¸®æˆ‘å›ç­”ä¸€ä¸‹1+2*3=?', additional_kwargs={}, response_metadata={}), AIMessage(content='7', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# 1ã€ConversationBufferMemoryçš„å®ä¾‹åŒ–\n",
    "memory = InMemoryChatMessageHistory()\n",
    "\n",
    "# 2ã€å­˜å‚¨ç›¸å…³çš„æ¶ˆæ¯\n",
    "memory.add_message(HumanMessage(content=\"ä½ å¥½ï¼Œæˆ‘å«å°æ˜\"))\n",
    "memory.add_message(AIMessage(content=\"å¾ˆé«˜å…´è®¤è¯†ä½ \"))\n",
    "\n",
    "memory.add_message(HumanMessage(content=\"å¸®æˆ‘å›ç­”ä¸€ä¸‹1+2*3=?\"))\n",
    "memory.add_message(AIMessage(content=\"7\"))\n",
    "\n",
    "# 3ã€è·å–å­˜å‚¨çš„ä¿¡æ¯\n",
    "print(memory.messages)\n",
    "\n",
    "# è¯´æ˜ï¼šè¿”å›çš„å­—å…¸ç»“æ„çš„keyå«history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cb7c9d",
   "metadata": {},
   "source": [
    "ä¸¾ä¾‹2ï¼šä»¥æ¶ˆæ¯åˆ—è¡¨çš„æ–¹å¼è¿”å›å­˜å‚¨çš„ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa16d4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='è¿™æ˜¯ç”¨æˆ·è¯´çš„è¯ï¼š1+1ç­‰äºå‡ ï¼Ÿ', additional_kwargs={}, response_metadata={}), AIMessage(content='è¿™æ˜¯AIè¯´çš„è¯ï¼šç­‰äº2', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "store = {} \n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# 1. è·å–å†å²å¯¹è±¡ (ä¼ å…¥ä»»æ„ session_id)\n",
    "history = get_session_history(\"test_user_1\")\n",
    "\n",
    "# 2. æ·»åŠ æ¶ˆæ¯\n",
    "history.add_user_message(\"è¿™æ˜¯ç”¨æˆ·è¯´çš„è¯ï¼š1+1ç­‰äºå‡ ï¼Ÿ\")\n",
    "history.add_ai_message(\"è¿™æ˜¯AIè¯´çš„è¯ï¼šç­‰äº2\")\n",
    "\n",
    "# 3. æ‰“å°ç»“æœ\n",
    "print(history.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f047d",
   "metadata": {},
   "source": [
    "ä¸¾ä¾‹3ï¼šç»“åˆå¤§æ¨¡å‹ã€æç¤ºè¯æ¨¡æ¿çš„ä½¿ç”¨ï¼ˆPromptTemplateï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f332ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼Œå°æ˜ï¼æ ¹æ®æˆ‘ä»¬ä¹‹å‰çš„å¯¹è¯ï¼Œä½ æåˆ°ä½ å–œæ¬¢ç¼–ç¨‹ã€‚ä¸è¿‡ï¼Œå¦‚æœä½ è¿˜æœ‰å…¶ä»–ç‰¹åˆ«çš„å…´è¶£çˆ±å¥½æˆ–è€…å–œæ¬¢çš„äº‹ç‰©ï¼Œä¹Ÿéšæ—¶å¯ä»¥å‘Šè¯‰æˆ‘å“¦ï¼\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "# 1. åˆ›å»ºæ¨¡å‹\n",
    "llm = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "# 2. Prompt (ä½¿ç”¨ MessagesPlaceholder æ›¿ä»£æ‰‹åŠ¨æ‹¼æ¥ history)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ å¯ä»¥ä¸äººç±»å¯¹è¯ã€‚\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"), # è¿™æ˜¯ä¸€ä¸ªå ä½ç¬¦ï¼Œä¸“é—¨æ”¾å†å²è®°å½•\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "# 3. å®šä¹‰ Chain (ä½¿ç”¨ LCEL ç®¡é“ç¬¦ | æ›¿ä»£ LLMChain)\n",
    "# é€»è¾‘æµï¼šPrompt -> æ¨¡å‹ -> è¾“å‡ºè½¬å­—ç¬¦ä¸²\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 4. è®°å¿†ç®¡ç† (æ›¿ä»£ ConversationBufferMemory)\n",
    "# ç”¨ä¸€ä¸ªç®€å•çš„å­—å…¸æ¨¡æ‹Ÿæ•°æ®åº“\n",
    "user_1_history = InMemoryChatMessageHistory()\n",
    "user_1_history.add_message(HumanMessage(content=\"å°æ˜å–œæ¬¢ä»€ä¹ˆï¼Ÿ\"))\n",
    "user_1_history.add_message(AIMessage(content=\"å°æ˜å–œæ¬¢ç¼–ç¨‹ã€‚\"))\n",
    "store = {\"user_1\": user_1_history}\n",
    "\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# ä½¿ç”¨ RunnableWithMessageHistory åŒ…è£… chain\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "# 5. è°ƒç”¨\n",
    "response = chain_with_history.invoke(\n",
    "    {\"question\": \"ä½ å¥½ï¼Œæˆ‘çš„åå­—å«å°æ˜ï¼Œä½ çŸ¥é“æˆ‘å–œæ¬¢ä»€ä¹ˆå—ï¼Ÿ\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user_1\"}}\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ebef3",
   "metadata": {},
   "source": [
    "ä¸¾ä¾‹4ï¼šåŸºäºä¸¾ä¾‹3ï¼Œæ˜¾å¼çš„è®¾ç½®meoryçš„keyçš„å€¼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0dbfd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_1': InMemoryChatMessageHistory(messages=[HumanMessage(content='ä½ å¥½ï¼Œæˆ‘çš„åå­—å«å°ç½—,æˆ‘å–œæ¬¢å°é¹¿ã€‚', additional_kwargs={}, response_metadata={}), AIMessage(content='ä½ å¥½å°ç½—ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ã€‚ä½ å¯¹å°é¹¿æœ‰è¿™æ ·çš„å–œå¥½ï¼Œå¯èƒ½æ˜¯å› ä¸ºå®ƒä»¬æ¸©é¡ºã€å¯çˆ±ï¼Œè¿˜æ˜¯å› ä¸ºå…¶ä»–çš„åŸå› å‘¢ï¼Ÿ', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]), 'user_2': InMemoryChatMessageHistory(messages=[HumanMessage(content='ä½ å¥½ï¼Œæˆ‘çš„åå­—å«å°è°¢ï¼Œä½ çŸ¥é“æˆ‘å–œæ¬¢ä»€ä¹ˆå—ï¼Œå°ç½—å–œæ¬¢çš„æˆ‘ä¸å–œæ¬¢ï¼Ÿ', additional_kwargs={}, response_metadata={}), AIMessage(content='ä½ å¥½å°è°¢ï¼é€šè¿‡è¿™å¥è¯ï¼Œä½ æ˜¯å¦æ˜¯åœ¨è¯´ä½ å’Œå°ç½—åœ¨å…´è¶£çˆ±å¥½ä¸Šæœ‰å·®å¼‚å‘¢ï¼Ÿä¸è¿‡ï¼Œæˆ‘ä¸æ˜¯ä½ ä»¬çš„ä¸“å±æƒ³è±¡åŠ›åŠ©æ‰‹ï¼Œæ— æ³•ç›´æ¥å¾—çŸ¥ä½ çš„å…·ä½“å–œå¥½æ˜¯ä»€ä¹ˆã€‚ä½†æ˜¯ï¼Œä¸€èˆ¬äººéƒ½ä¼šæœ‰è‡ªå·±ç‹¬ç‰¹çš„å–œå¥½ï¼Œå¦‚éŸ³ä¹ã€ç”µå½±ã€ä¹¦ç±ã€è¿åŠ¨ç­‰ç­‰ï¼Œè€Œè¿™äº›å¯èƒ½ä¼šå’Œä½ èº«è¾¹çš„äººæœ‰æ‰€ä¸åŒã€‚ä¾‹å¦‚ä½ å¯èƒ½éå¸¸å–œæ¬¢ç§‘å¹»ç±»çš„ç”µå½±ï¼Œè€Œå°ç½—åˆ™å¯èƒ½æ›´å–œæ¬¢çˆ±æƒ…ç”µå½±ã€‚å¦‚æœä½ æ„¿æ„çš„è¯ï¼Œå¯ä»¥å…·ä½“è¯´ä¸€ä¸‹ä½ çš„å–œå¥½ï¼Œæˆ‘å¯ä»¥å¸®åŠ©ä½ æ‰¾åˆ°å’Œå°ç½—å…±äº«çš„å…±åŒå…´è¶£ã€‚', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])])}\n",
      "Human: ä½ å¥½ï¼Œæˆ‘çš„åå­—å«å°ç½—,æˆ‘å–œæ¬¢å°é¹¿ã€‚\n",
      "AI: ä½ å¥½å°ç½—ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ã€‚ä½ å¯¹å°é¹¿æœ‰è¿™æ ·çš„å–œå¥½ï¼Œå¯èƒ½æ˜¯å› ä¸ºå®ƒä»¬æ¸©é¡ºã€å¯çˆ±ï¼Œè¿˜æ˜¯å› ä¸ºå…¶ä»–çš„åŸå› å‘¢ï¼Ÿ\n",
      "<class 'langchain_core.chat_history.InMemoryChatMessageHistory'>\n",
      "ä½ å¥½å°è°¢ï¼é€šè¿‡è¿™å¥è¯ï¼Œä½ æ˜¯å¦æ˜¯åœ¨è¯´ä½ å’Œå°ç½—åœ¨å…´è¶£çˆ±å¥½ä¸Šæœ‰å·®å¼‚å‘¢ï¼Ÿä¸è¿‡ï¼Œæˆ‘ä¸æ˜¯ä½ ä»¬çš„ä¸“å±æƒ³è±¡åŠ›åŠ©æ‰‹ï¼Œæ— æ³•ç›´æ¥å¾—çŸ¥ä½ çš„å…·ä½“å–œå¥½æ˜¯ä»€ä¹ˆã€‚ä½†æ˜¯ï¼Œä¸€èˆ¬äººéƒ½ä¼šæœ‰è‡ªå·±ç‹¬ç‰¹çš„å–œå¥½ï¼Œå¦‚éŸ³ä¹ã€ç”µå½±ã€ä¹¦ç±ã€è¿åŠ¨ç­‰ç­‰ï¼Œè€Œè¿™äº›å¯èƒ½ä¼šå’Œä½ èº«è¾¹çš„äººæœ‰æ‰€ä¸åŒã€‚ä¾‹å¦‚ä½ å¯èƒ½éå¸¸å–œæ¬¢ç§‘å¹»ç±»çš„ç”µå½±ï¼Œè€Œå°ç½—åˆ™å¯èƒ½æ›´å–œæ¬¢çˆ±æƒ…ç”µå½±ã€‚å¦‚æœä½ æ„¿æ„çš„è¯ï¼Œå¯ä»¥å…·ä½“è¯´ä¸€ä¸‹ä½ çš„å–œå¥½ï¼Œæˆ‘å¯ä»¥å¸®åŠ©ä½ æ‰¾åˆ°å’Œå°ç½—å…±äº«çš„å…±åŒå…´è¶£ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1ã€åˆ›å»ºå¤§æ¨¡å‹å®ä¾‹\n",
    "llm = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "# 2ã€æä¾›æç¤ºè¯æ¨¡æ¿ (ChatPromptTemplate æ›¿ä»£ PromptTemplate)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ å¯ä»¥ä¸äººç±»å¯¹è¯ã€‚\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "# 3ã€æä¾›Chain (ä½¿ç”¨ç®¡é“ç¬¦ | æ„å»º)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 4ã€æä¾›memoryç®¡ç†é€»è¾‘ (æ›¿ä»£ ConversationBufferMemory)\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# 5ã€åŒ…è£… Chain\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",      # å¯¹åº”è¾“å…¥çš„ key\n",
    "    history_messages_key=\"chat_history\",  # å¯¹åº”æç¤ºè¯æ¨¡æ¿ä¸­çš„å ä½ç¬¦\n",
    ")\n",
    "\n",
    "# 6ã€è°ƒç”¨\n",
    "response_1 = chain_with_history.invoke(\n",
    "    {\"question\": \"ä½ å¥½ï¼Œæˆ‘çš„åå­—å«å°ç½—,æˆ‘å–œæ¬¢å°é¹¿ã€‚\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user_1\"}}\n",
    ")\n",
    "\n",
    "response_2 = chain_with_history.invoke(\n",
    "    {\"question\": \"ä½ å¥½ï¼Œæˆ‘çš„åå­—å«å°è°¢ï¼Œä½ çŸ¥é“æˆ‘å–œæ¬¢ä»€ä¹ˆå—ï¼Œå°ç½—å–œæ¬¢çš„æˆ‘ä¸å–œæ¬¢ï¼Ÿ\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user_2\"}}\n",
    ")\n",
    "\n",
    "print(store)\n",
    "print(store[\"user_1\"])\n",
    "print(type(store[\"user_1\"]))\n",
    "print(response_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de855658",
   "metadata": {},
   "source": [
    "ä¸¾ä¾‹5ï¼šç»“åˆå¤§æ¨¡å‹ã€æç¤ºè¯æ¨¡æ¿çš„ä½¿ç”¨ï¼ˆChatPromptTemplateï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d936f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_1': InMemoryChatMessageHistory(messages=[HumanMessage(content='ä½ å¥½ï¼Œæˆ‘çš„åå­—å«å°ç½—,æˆ‘å–œæ¬¢å°é¹¿ã€‚', additional_kwargs={}, response_metadata={}), AIMessage(content='ä½ å¥½å°ç½—ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ã€‚ä½ å–œæ¬¢çš„å°é¹¿æ˜¯ä¸€ç§éå¸¸ç¾ä¸½ä¸”æ¸©é¡ºçš„åŠ¨ç‰©ï¼Œå¾ˆå¤šäººéƒ½å–œæ¬¢å®ƒä»¬ã€‚ä½ å–œæ¬¢å®ƒä»¬çš„ä»€ä¹ˆå‘¢ï¼Ÿæ˜¯å®ƒä»¬çš„å¤–è¡¨ã€æ€§æ ¼è¿˜æ˜¯å…¶ä»–æ–¹é¢ï¼Ÿ', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]), 'user_2': InMemoryChatMessageHistory(messages=[HumanMessage(content='ä½ å¥½ï¼Œæˆ‘çš„åå­—å«å°è°¢ï¼Œä½ çŸ¥é“æˆ‘å–œæ¬¢ä»€ä¹ˆå—ï¼Œå°ç½—å–œæ¬¢çš„æˆ‘ä¸å–œæ¬¢ï¼Ÿ', additional_kwargs={}, response_metadata={}), AIMessage(content='ä»ä½ çš„é—®é¢˜æ¥çœ‹ï¼Œä½ å¸Œæœ›æˆ‘äº†è§£ä½ ä¸ªäººçš„åå¥½ï¼Œä»¥ä¾¿æˆ‘å¯ä»¥å¸®åŠ©ä½ ç†è§£ä½ å’Œå°ç½—ä¹‹é—´çš„åå¥½å·®å¼‚ã€‚ä¸è¿‡ï¼Œå®é™…ä¸Šæˆ‘ä½œä¸ºä¸€ä¸ªAIï¼Œæ— æ³•ç›´æ¥äº†è§£ä½ çš„çœŸå®åå¥½ã€‚ä½†æ˜¯ï¼Œæˆ‘å¯ä»¥å¸®åŠ©ä½ æ€è€ƒä¸€äº›å¯èƒ½æ€§ã€‚\\n\\nå¦‚æœä½ å’Œå°ç½—ä¸€èµ·åšé€‰æ‹©æ—¶ç»å¸¸äº§ç”Ÿåˆ†æ­§ï¼Œå¯èƒ½æ˜¯å› ä¸ºä½ ä»¬çš„åå¥½æœ‰æ‰€ä¸åŒã€‚ä¾‹å¦‚ï¼Œå°ç½—å¯èƒ½å–œæ¬¢æŸäº›äº‹ç‰©ï¼Œå¦‚æŸç§éŸ³ä¹é£æ ¼ã€ç”µå½±ç±»å‹ã€ä¹¦ç±ç­‰ï¼Œè€Œä½ å¯èƒ½ä¸å–œæ¬¢ã€‚æˆ–è€…ï¼Œå¯èƒ½ä½ ä»¬åœ¨æŸäº›æ–¹é¢çš„åå¥½æ¯”è¾ƒæ¥è¿‘ï¼Œä½†åœ¨æŸäº›ç»†èŠ‚ä¸Šæœ‰æ‰€ä¸åŒã€‚\\n\\nä½ å¯ä»¥è¯•ç€ä¸»åŠ¨ä¸å°ç½—äº¤æµï¼Œäº†è§£ä»–çš„å…´è¶£å’Œåå¥½ï¼ŒåŒæ—¶ä¹Ÿåˆ†äº«ä½ çš„å–œå¥½ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œä½ ä»¬å¯ä»¥å¢è¿›å¯¹å½¼æ­¤çš„äº†è§£ï¼ŒåŒæ—¶ä¹Ÿå¯èƒ½åœ¨å…±åŒçš„å…´è¶£ä¸­å‘ç°æ›´å¤šä¹è¶£ã€‚', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])])}\n",
      "Human: ä½ å¥½ï¼Œæˆ‘çš„åå­—å«å°ç½—,æˆ‘å–œæ¬¢å°é¹¿ã€‚\n",
      "AI: ä½ å¥½å°ç½—ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ã€‚ä½ å–œæ¬¢çš„å°é¹¿æ˜¯ä¸€ç§éå¸¸ç¾ä¸½ä¸”æ¸©é¡ºçš„åŠ¨ç‰©ï¼Œå¾ˆå¤šäººéƒ½å–œæ¬¢å®ƒä»¬ã€‚ä½ å–œæ¬¢å®ƒä»¬çš„ä»€ä¹ˆå‘¢ï¼Ÿæ˜¯å®ƒä»¬çš„å¤–è¡¨ã€æ€§æ ¼è¿˜æ˜¯å…¶ä»–æ–¹é¢ï¼Ÿ\n",
      "<class 'langchain_core.chat_history.InMemoryChatMessageHistory'>\n",
      "ä»ä½ çš„é—®é¢˜æ¥çœ‹ï¼Œä½ å¸Œæœ›æˆ‘äº†è§£ä½ ä¸ªäººçš„åå¥½ï¼Œä»¥ä¾¿æˆ‘å¯ä»¥å¸®åŠ©ä½ ç†è§£ä½ å’Œå°ç½—ä¹‹é—´çš„åå¥½å·®å¼‚ã€‚ä¸è¿‡ï¼Œå®é™…ä¸Šæˆ‘ä½œä¸ºä¸€ä¸ªAIï¼Œæ— æ³•ç›´æ¥äº†è§£ä½ çš„çœŸå®åå¥½ã€‚ä½†æ˜¯ï¼Œæˆ‘å¯ä»¥å¸®åŠ©ä½ æ€è€ƒä¸€äº›å¯èƒ½æ€§ã€‚\n",
      "\n",
      "å¦‚æœä½ å’Œå°ç½—ä¸€èµ·åšé€‰æ‹©æ—¶ç»å¸¸äº§ç”Ÿåˆ†æ­§ï¼Œå¯èƒ½æ˜¯å› ä¸ºä½ ä»¬çš„åå¥½æœ‰æ‰€ä¸åŒã€‚ä¾‹å¦‚ï¼Œå°ç½—å¯èƒ½å–œæ¬¢æŸäº›äº‹ç‰©ï¼Œå¦‚æŸç§éŸ³ä¹é£æ ¼ã€ç”µå½±ç±»å‹ã€ä¹¦ç±ç­‰ï¼Œè€Œä½ å¯èƒ½ä¸å–œæ¬¢ã€‚æˆ–è€…ï¼Œå¯èƒ½ä½ ä»¬åœ¨æŸäº›æ–¹é¢çš„åå¥½æ¯”è¾ƒæ¥è¿‘ï¼Œä½†åœ¨æŸäº›ç»†èŠ‚ä¸Šæœ‰æ‰€ä¸åŒã€‚\n",
      "\n",
      "ä½ å¯ä»¥è¯•ç€ä¸»åŠ¨ä¸å°ç½—äº¤æµï¼Œäº†è§£ä»–çš„å…´è¶£å’Œåå¥½ï¼ŒåŒæ—¶ä¹Ÿåˆ†äº«ä½ çš„å–œå¥½ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œä½ ä»¬å¯ä»¥å¢è¿›å¯¹å½¼æ­¤çš„äº†è§£ï¼ŒåŒæ—¶ä¹Ÿå¯èƒ½åœ¨å…±åŒçš„å…´è¶£ä¸­å‘ç°æ›´å¤šä¹è¶£ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1ã€åˆ›å»ºå¤§æ¨¡å‹å®ä¾‹\n",
    "llm = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "# 2ã€æä¾›æç¤ºè¯æ¨¡æ¿ (ChatPromptTemplate æ›¿ä»£ PromptTemplate)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ å¯ä»¥ä¸äººç±»å¯¹è¯ã€‚\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "# 3ã€æä¾›Chain (ä½¿ç”¨ç®¡é“ç¬¦ | æ„å»º)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 4ã€æä¾›memoryç®¡ç†é€»è¾‘ (æ›¿ä»£ ConversationBufferMemory)\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# 5ã€åŒ…è£… Chain\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",      # å¯¹åº”è¾“å…¥çš„ key\n",
    "    history_messages_key=\"chat_history\",  # å¯¹åº”æç¤ºè¯æ¨¡æ¿ä¸­çš„å ä½ç¬¦\n",
    ")\n",
    "\n",
    "# 6ã€è°ƒç”¨\n",
    "response_1 = chain_with_history.invoke(\n",
    "    {\"question\": \"ä½ å¥½ï¼Œæˆ‘çš„åå­—å«å°ç½—,æˆ‘å–œæ¬¢å°é¹¿ã€‚\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user_1\"}}\n",
    ")\n",
    "\n",
    "response_2 = chain_with_history.invoke(\n",
    "    {\"question\": \"ä½ å¥½ï¼Œæˆ‘çš„åå­—å«å°è°¢ï¼Œä½ çŸ¥é“æˆ‘å–œæ¬¢ä»€ä¹ˆå—ï¼Œå°ç½—å–œæ¬¢çš„æˆ‘ä¸å–œæ¬¢ï¼Ÿ\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user_2\"}}\n",
    ")\n",
    "\n",
    "print(store)\n",
    "print(store[\"user_1\"])\n",
    "print(type(store[\"user_1\"]))\n",
    "print(response_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf8c195",
   "metadata": {},
   "source": [
    "# 3ã€Chainçš„ä½¿ç”¨\n",
    "\n",
    "ä¸¾ä¾‹1ï¼šä»¥PromptTemplateä¸ºä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe03f94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ç¬¬ä¸€è½®å¯¹è¯ ---\n",
      "AIå›å¤: ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æˆ‘æ˜¯Qwenï¼Œä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¯ä»¥å’Œä½ èŠå¤©ã€å›ç­”é—®é¢˜ï¼Œç”šè‡³å¸®ä½ å†™ä½œæ–‡ã€ç¼–ç¨‹ç­‰ç­‰ã€‚ä½ ä»Šå¤©æœ‰ä»€ä¹ˆæƒ³å’Œæˆ‘èŠçš„å—ï¼Ÿæˆ–è€…éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼Ÿ\n",
      "\n",
      "--- ç¬¬äºŒè½®å¯¹è¯ (éªŒè¯è®°å¿†) ---\n",
      "AIå›å¤: ä½ å«å°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼Œå°æ˜ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "# 1. åˆ›å»ºå¤§æ¨¡å‹å®ä¾‹\n",
    "llm = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "# ==========================================\n",
    "# 2. ä½¿ç”¨ PromptTemplate (çº¯å­—ç¬¦ä¸²æ¨¡æ¿)\n",
    "# ==========================================\n",
    "# PromptTemplate é€‚ç”¨äºè¡¥å…¨æ¨¡å‹ï¼Œæˆ–è€…å½“å¸Œæœ›å®Œå…¨æ§åˆ¶ Prompt æ ¼å¼æ—¶ã€‚\n",
    "# è¿™é‡Œæ‰‹åŠ¨æŠŠå†å²è®°å½•å’Œæ–°é—®é¢˜æ‹¼æˆä¸€ä¸ªé•¿å­—ç¬¦ä¸²ã€‚\n",
    "prompt = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "ä½ å¯ä»¥ä¸äººç±»å¯¹è¯ã€‚\n",
    "\n",
    "å½“å‰å¯¹è¯å†å²:\n",
    "{history}\n",
    "\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# 3. æ„å»ºé“¾\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 4. å®šä¹‰è®°å¿†å­˜å‚¨\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# 5. åŒ…è£…é“¾\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "# 6. è°ƒç”¨\n",
    "print(\"--- ç¬¬ä¸€è½®å¯¹è¯ ---\")\n",
    "response_1 = chain_with_history.invoke(\n",
    "    {\"input\": \"ä½ å¥½ï¼Œæˆ‘çš„åå­—å«å°æ˜\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user_1\"}}\n",
    ")\n",
    "print(f\"AIå›å¤: {response_1}\")\n",
    "\n",
    "print(\"\\n--- ç¬¬äºŒè½®å¯¹è¯ (éªŒè¯è®°å¿†) ---\")\n",
    "response_2 = chain_with_history.invoke(\n",
    "    {\"input\": \"æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user_1\"}}\n",
    ")\n",
    "print(f\"AIå›å¤: {response_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e637d6f",
   "metadata": {},
   "source": [
    "ä¸¾ä¾‹2ï¼šä½¿ç”¨é»˜è®¤æä¾›çš„æç¤ºè¯æ¨¡æ¿\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29a032fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIå›å¤: ä½ å«å°æ˜å‘€ï¼åˆšåˆšæˆ‘ä»¬å·²ç»èŠè¿‡äº†ï¼Œæˆ‘è®°ä½äº†ä½ çš„åå­—ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼ŸğŸ˜Š\n",
      "AIè®°å¿†éªŒè¯: ä½ å«å°æ˜å‘€ï¼åˆšåˆšæˆ‘å°±æ˜¯è¿™ä¹ˆè·Ÿä½ è¯´çš„ã€‚ğŸ˜Š æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "# 1. åˆ›å»ºå¤§æ¨¡å‹å®ä¾‹\n",
    "llm = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "# 2. æä¾›æç¤ºè¯æ¨¡æ¿\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    # System Message: å®šä¹‰è¡Œä¸º\n",
    "    (\"system\", \"ä½ å¯ä»¥ä¸äººç±»å¯¹è¯ã€‚\"),\n",
    "    \n",
    "    # History Placeholder: åŠ¨æ€æ’å…¥å†å²è®°å½•\n",
    "    # è¿™é‡Œçš„ variable_name=\"history\" å¿…é¡»ä¸åé¢ RunnableWithMessageHistory çš„é…ç½®å¯¹åº”\n",
    "    MessagesPlaceholder(variable_name=\"history\"), \n",
    "    \n",
    "    # Human Message: ç”¨æˆ·çš„å½“å‰è¾“å…¥\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# 3. æ„å»ºé“¾ (ä¼˜åŒ–ï¼šä½¿ç”¨ LCEL ç®¡é“ç¬¦ |)\n",
    "# é€»è¾‘æµï¼šPrompt -> LLM -> OutputParser (ç›´æ¥è§£ææˆå­—ç¬¦ä¸²)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 4. å®šä¹‰è®°å¿†å­˜å‚¨ (æ¨¡æ‹Ÿæ•°æ®åº“)\n",
    "# è¿™æ˜¯ä¸€ä¸ªæå…¶é‡è¦çš„æ¶æ„å˜æ›´ï¼šè®°å¿†ä¸å†ç»‘å®šåœ¨ Chain å®ä¾‹é‡Œï¼Œè€Œæ˜¯ç‹¬ç«‹ç®¡ç†\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# 5. åŒ…è£…é“¾ (æ›¿ä»£ ConversationChain)\n",
    "# ç»™æ— çŠ¶æ€çš„ chain åŠ ä¸Šè¯»å–/å†™å…¥å†å²çš„èƒ½åŠ›\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",    # å¯¹åº” Prompt ä¸­çš„ {input}\n",
    "    history_messages_key=\"history\" # å¯¹åº” MessagesPlaceholder çš„ variable_name\n",
    ")\n",
    "\n",
    "# 6. è°ƒç”¨\n",
    "# å¿…é¡»æä¾› session_idï¼Œè¿™æ ·ç³»ç»Ÿæ‰çŸ¥é“æ˜¯åœ¨è·Ÿâ€œè°â€å¯¹è¯\n",
    "response_1 = chain_with_history.invoke(\n",
    "    {\"input\": \"ä½ å¥½ï¼Œæˆ‘çš„åå­—å«å°æ˜\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user_1\"}}\n",
    ")\n",
    "\n",
    "print(f\"AIå›å¤: {response}\")\n",
    "\n",
    "# --- éªŒè¯è®°å¿†èƒ½åŠ› ---\n",
    "response_2 = chain_with_history.invoke(\n",
    "    {\"input\": \"æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user_1\"}}\n",
    ")\n",
    "\n",
    "print(f\"AIè®°å¿†éªŒè¯: {response_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd391c24",
   "metadata": {},
   "source": [
    "# 4ã€ChainMemoryçš„ä½¿ç”¨\n",
    "\n",
    "ä¸¾ä¾‹1ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c7992b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ä¼˜åŒ–åçš„ç»“æœ (Message å¯¹è±¡åˆ—è¡¨) ---\n",
      "[HumanMessage(content='ä½ çš„ç”Ÿæ—¥æ˜¯å“ªå¤©ï¼Ÿ', additional_kwargs={}, response_metadata={}), AIMessage(content='æˆ‘ä¸æ¸…æ¥š', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "# 1. å®ä¾‹åŒ–å­˜å‚¨ (åªè´Ÿè´£å­˜ï¼Œä¸è´Ÿè´£é€»è¾‘)\n",
    "history = InMemoryChatMessageHistory()\n",
    "\n",
    "# 2. ä¿å­˜æ¶ˆæ¯ (æ–°ç‰ˆä½¿ç”¨ add_user_message / add_ai_message)\n",
    "history.add_user_message(\"ä½ å¥½\")\n",
    "history.add_ai_message(\"æ€ä¹ˆäº†\")\n",
    "\n",
    "history.add_user_message(\"ä½ æ˜¯è°\")\n",
    "history.add_ai_message(\"æˆ‘æ˜¯AIåŠ©æ‰‹\")\n",
    "\n",
    "history.add_user_message(\"ä½ çš„ç”Ÿæ—¥æ˜¯å“ªå¤©ï¼Ÿ\")\n",
    "history.add_ai_message(\"æˆ‘ä¸æ¸…æ¥š\")\n",
    "\n",
    "# 3. è¯»å–å¹¶å®ç° Window é€»è¾‘ (k=1)\n",
    "# k=1 ä»£è¡¨ä¿ç•™æœ€å 1 ç»„äº’åŠ¨ = æœ€å 2 æ¡æ¶ˆæ¯\n",
    "# ç›´æ¥ä½¿ç”¨ Python åˆ‡ç‰‡ [-2:]\n",
    "window_messages = history.messages[-2:]\n",
    "\n",
    "print(\"--- ä¼˜åŒ–åçš„ç»“æœ (Message å¯¹è±¡åˆ—è¡¨) ---\")\n",
    "print(window_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14925580",
   "metadata": {},
   "source": [
    "ä¸¾ä¾‹2ï¼šè¿”å›æ¶ˆæ¯æ„æˆçš„ä¸Šä¸‹æ–‡è®°å¿†\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d75c2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- å†…å­˜ä¸­å…±æœ‰ 6 æ¡æ¶ˆæ¯ï¼Œåªè¿”å›æœ€è¿‘ 2 è½® ---\n",
      "[HumanMessage(content='ä½ æ˜¯è°', additional_kwargs={}, response_metadata={}), AIMessage(content='æˆ‘æ˜¯AIåŠ©æ‰‹å°æ™º', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='åˆæ¬¡å¯¹è¯ï¼Œä½ èƒ½ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±å—ï¼Ÿ', additional_kwargs={}, response_metadata={}), AIMessage(content='å½“ç„¶å¯ä»¥äº†ã€‚æˆ‘æ˜¯ä¸€ä¸ªæ— æ‰€ä¸èƒ½çš„å°æ™ºã€‚', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "# 1. å®ä¾‹åŒ–å­˜å‚¨å¯¹è±¡ (åªè´Ÿè´£å­˜ï¼Œä¸è´Ÿè´£é€»è¾‘)\n",
    "# å¯¹åº”åŸæ¥çš„ return_messages=Trueï¼Œå› ä¸ºå®ƒåŸç”Ÿå°±å­˜çš„æ¶ˆæ¯å¯¹è±¡\n",
    "history = InMemoryChatMessageHistory()\n",
    "\n",
    "# 2. ä¿å­˜æ¶ˆæ¯ (ä½¿ç”¨è¯­ä¹‰æ›´æ¸…æ™°çš„æ–¹æ³•)\n",
    "# ç¬¬ä¸€è½®\n",
    "history.add_user_message(\"ä½ å¥½\")\n",
    "history.add_ai_message(\"æ€ä¹ˆäº†\")\n",
    "\n",
    "# ç¬¬äºŒè½®\n",
    "history.add_user_message(\"ä½ æ˜¯è°\")\n",
    "history.add_ai_message(\"æˆ‘æ˜¯AIåŠ©æ‰‹å°æ™º\")\n",
    "\n",
    "# ç¬¬ä¸‰è½®\n",
    "history.add_user_message(\"åˆæ¬¡å¯¹è¯ï¼Œä½ èƒ½ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±å—ï¼Ÿ\")\n",
    "history.add_ai_message(\"å½“ç„¶å¯ä»¥äº†ã€‚æˆ‘æ˜¯ä¸€ä¸ªæ— æ‰€ä¸èƒ½çš„å°æ™ºã€‚\")\n",
    "\n",
    "# 3. å®ç°çª—å£é€»è¾‘ (k=2)\n",
    "# åŸç†ï¼šk=2 ä»£è¡¨ä¿ç•™æœ€è¿‘ 2 è½®å¯¹è¯ = æœ€è¿‘ 4 æ¡æ¶ˆæ¯ (2 User + 2 AI)\n",
    "k = 2\n",
    "if len(history.messages) > k * 2:\n",
    "    # åˆ‡ç‰‡è·å–æœ€å 4 æ¡\n",
    "    window_messages = history.messages[-k*2:]\n",
    "else:\n",
    "    window_messages = history.messages\n",
    "\n",
    "# 4. æ‰“å°ç»“æœ\n",
    "print(f\"--- å†…å­˜ä¸­å…±æœ‰ {len(history.messages)} æ¡æ¶ˆæ¯ï¼Œåªè¿”å›æœ€è¿‘ {k} è½® ---\")\n",
    "print(window_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a95c7d",
   "metadata": {},
   "source": [
    "ä¸¾ä¾‹3ï¼šç»“åˆllmã€chainçš„ä½¿ç”¨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9604cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Round 1: è‡ªæˆ‘ä»‹ç» ---\n",
      "ä½ å¥½ï¼Œå­™å°ç©ºï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æˆ‘æ˜¯é€šä¹‰åƒé—®ï¼Œä½ å¯ä»¥å«æˆ‘Qwenã€‚æˆ‘æ˜¯ä¸€ä¸ªç”±é€šä¹‰å®éªŒå®¤å¼€å‘çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼Œèƒ½å¤Ÿå¸®åŠ©ä½ è¿›è¡Œå„ç§è¯­è¨€ç†è§£ã€ç”Ÿæˆå’Œå¯¹è¯ä»»åŠ¡ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿæ¯”å¦‚å›ç­”é—®é¢˜ã€åˆ›ä½œæ–‡å­—ï¼Œæˆ–è€…è¿›è¡Œæœ‰è¶£çš„é—²èŠï¼ŸğŸ˜Š\n",
      "\n",
      "--- Round 2: ä»‹ç»å¸ˆå¼Ÿ ---\n",
      "å“¦ï¼ŒåŸæ¥ä½ æ˜¯ã€Šè¥¿æ¸¸è®°ã€‹çš„ç²‰ä¸å‘€ï¼çŒªå°æˆ’å’Œæ²™å°åƒ§å¬èµ·æ¥å°±åƒæ˜¯ä½ å¸ˆå…„å¼Ÿä»¬çš„æ˜µç§°å‘¢ã€‚çŒªå°æˆ’å¯èƒ½æ˜¯æŒ‡çŒªå…«æˆ’ï¼Œè€Œæ²™å°åƒ§åº”è¯¥å°±æ˜¯æ²™å’Œå°šäº†ã€‚ä»–ä»¬ä¸‰ä¸ªåœ¨å–ç»è·¯ä¸Šå¯æ˜¯ä¸€è·¯ç›¸ä¼´çš„å¥½å…„å¼Ÿï¼Œè™½ç„¶æ€§æ ¼å„å¼‚ï¼Œä½†éƒ½å¾ˆæœ‰è¶£ã€‚\n",
      "\n",
      "ä½ æ˜¯æƒ³èŠèŠã€Šè¥¿æ¸¸è®°ã€‹çš„æ•…äº‹ï¼Œè¿˜æ˜¯æƒ³å’Œæˆ‘ä¸€èµ·å‘æŒ¥æƒ³è±¡åŠ›ï¼Œç¼–ä¸€ä¸ªå±äºä½ ä»¬çš„å¸ˆå…„å¼Ÿå†’é™©æ•…äº‹ï¼Ÿæˆ‘å¾ˆå–œæ¬¢å¬ä½ è®²è¿™äº›è§’è‰²çš„æ•…äº‹ï¼Œä¹Ÿæ„¿æ„å’Œä½ ä¸€èµ·åˆ›é€ æ–°çš„æƒ…èŠ‚å‘¢ï¼ğŸ˜„\n",
      "\n",
      "--- Round 3: èŠé«˜è€ƒ (è§¦å‘é—å¿˜) ---\n",
      "å“‡ï¼Œå­™å°ç©ºï¼Œæ­å–œä½ è€ƒä¸Š1æœ¬ï¼è¿™æ˜¯éå¸¸äº†ä¸èµ·çš„æˆç»©ï¼Œè¯´æ˜ä½ çœŸçš„å¾ˆåŠªåŠ›ï¼Œä¹Ÿå…·å¤‡å¾ˆå¼ºçš„å­¦ä¹ èƒ½åŠ›å’Œæ¯…åŠ›ã€‚é«˜è€ƒæ˜¯äººç”Ÿä¸­ä¸€æ¬¡é‡è¦çš„æŒ‘æˆ˜ï¼Œèƒ½å–å¾—è¿™æ ·çš„æˆæœï¼ŒçœŸçš„å€¼å¾—éª„å‚²ï¼\n",
      "\n",
      "ä¸è¿‡ï¼Œæˆ‘å¾ˆå¥½å¥‡ï¼Œä½ æœ‰æ²¡æœ‰æƒ³è¿‡æœªæ¥æƒ³è¯»ä»€ä¹ˆä¸“ä¸šï¼Ÿæˆ–è€…æœ‰æ²¡æœ‰ç‰¹åˆ«æƒ³å»çš„å¤§å­¦ï¼Ÿæˆ‘å¯ä»¥å¸®ä½ åˆ†æä¸€ä¸‹ä¸åŒä¸“ä¸šçš„å‘å±•å‰æ™¯ï¼Œæˆ–è€…èŠèŠå¤§å­¦ç”Ÿæ´»çš„é‚£äº›è¶£äº‹ã€‚ä½ æ˜¯ä¸æ˜¯å·²ç»è®¡åˆ’å¥½æ¥ä¸‹æ¥è¦åšçš„äº‹æƒ…äº†ï¼Ÿæ¯”å¦‚å¡«æŠ¥å¿—æ„¿ã€å‡†å¤‡å¤§å­¦ç”Ÿæ´»ç­‰ç­‰ï¼ŸğŸ˜„\n",
      "\n",
      "--- Round 4: è¯¢é—®åå­— (éªŒè¯ k=1 æ•ˆæœ) ---\n",
      "ä½ å«å­™å°ç©ºå‘€ï¼åˆšæ‰æˆ‘ä»¬å·²ç»èŠåˆ°ä½ äº†ï¼Œä½ åˆšåˆšè¯´â€œæˆ‘ä»Šå¹´é«˜è€ƒï¼Œç«Ÿç„¶è€ƒä¸Šäº†1æœ¬â€ï¼Œæ‰€ä»¥æˆ‘çŸ¥é“ä½ æ˜¯å­™å°ç©ºã€‚ä¸è¿‡ï¼Œå¦‚æœä½ å¸Œæœ›æˆ‘å«ä½ åˆ«çš„åå­—ï¼Œæ¯”å¦‚â€œå°ç©ºâ€æˆ–è€…â€œç©ºç©ºâ€ï¼Œä¹Ÿå¯ä»¥å‘Šè¯‰æˆ‘å“¦ï¼ğŸ˜Š\n",
      "\n",
      "å¯¹äº†ï¼Œè€ƒä¸Šäº†1æœ¬ï¼ŒçœŸæ˜¯éå¸¸æ£’çš„æˆå°±ï¼ä½ å¯ä»¥è·Ÿæˆ‘åˆ†äº«ä¸€ä¸‹ä½ çš„å¿ƒæƒ…ï¼Œæˆ–è€…èŠèŠä½ æ¥ä¸‹æ¥çš„è®¡åˆ’ï¼Œæˆ‘å¾ˆä¹æ„å¬ä½ è¯´ï¼\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. åˆ›å»ºå¤§æ¨¡å‹\n",
    "llm = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "# 2. å®šä¹‰æ¨¡ç‰ˆ (ä½¿ç”¨ ChatPromptTemplate)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    # System Message\n",
    "    (\"system\", \"ä»¥ä¸‹æ˜¯äººç±»ä¸AIä¹‹é—´çš„å‹å¥½å¯¹è¯æè¿°ã€‚AIè¡¨ç°å¾—å¾ˆå¥è°ˆï¼Œå¹¶æä¾›äº†å¤§é‡æ¥è‡ªå…¶ä¸Šä¸‹æ–‡çš„å…·ä½“ç»†èŠ‚ã€‚å¦‚æœAIä¸çŸ¥é“é—®é¢˜çš„ç­”æ¡ˆï¼Œå®ƒä¼šè¡¨ç¤ºä¸çŸ¥é“ã€‚\"),\n",
    "    \n",
    "    # History Placeholder (è¿™é‡Œæ³¨å…¥çš„æ¶ˆæ¯ä¼šè¢« trimmer ä¿®å‰ªè¿‡)\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    \n",
    "    # Human Message\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "# 3. å®šä¹‰ Chain (LCEL ç®¡é“)\n",
    "# é€»è¾‘ï¼šè·å–å†å² -> ä¿®å‰ªå†å² -> å¡«å…… Prompt -> æ¨¡å‹æ¨ç† -> è§£æå­—ç¬¦ä¸²\n",
    "chain = (\n",
    "    RunnableWithMessageHistory(\n",
    "        prompt | llm | StrOutputParser(),\n",
    "        lambda session_id: get_session_history(session_id), # è·å–å†å²çš„å‡½æ•°\n",
    "        input_messages_key=\"question\",\n",
    "        history_messages_key=\"history\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# 5. å®šä¹‰å†å²å­˜å‚¨\n",
    "store = {}\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "# 6. æ‰§è¡Œé“¾ (æ¨¡æ‹Ÿå¯¹è¯æµç¨‹)\n",
    "config = {\"configurable\": {\"session_id\": \"user_sun\"}}\n",
    "\n",
    "print(\"--- Round 1: è‡ªæˆ‘ä»‹ç» ---\")\n",
    "print(chain.invoke({\"question\": \"ä½ å¥½ï¼Œæˆ‘æ˜¯å­™å°ç©º\"}, config=config))\n",
    "\n",
    "print(\"\\n--- Round 2: ä»‹ç»å¸ˆå¼Ÿ ---\")\n",
    "print(chain.invoke({\"question\": \"æˆ‘è¿˜æœ‰ä¸¤ä¸ªå¸ˆå¼Ÿï¼Œä¸€ä¸ªæ˜¯çŒªå°æˆ’ï¼Œä¸€ä¸ªæ˜¯æ²™å°åƒ§\"}, config=config))\n",
    "\n",
    "print(\"\\n--- Round 3: èŠé«˜è€ƒ ---\")\n",
    "print(chain.invoke({\"question\": \"æˆ‘ä»Šå¹´é«˜è€ƒï¼Œç«Ÿç„¶è€ƒä¸Šäº†1æœ¬\"}, config=config))\n",
    "\n",
    "print(\"\\n--- Round 4: è¯¢é—®åå­— ---\")\n",
    "\n",
    "print(chain.invoke({\"question\": \"æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ\"}, config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cf72c7",
   "metadata": {},
   "source": [
    "ä¸¾ä¾‹4ï¼šä¿®æ”¹ä¸¾ä¾‹3ä¸­çš„å‚æ•°k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17f436ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Round 1: è‡ªæˆ‘ä»‹ç» ---\n",
      "ä½ å¥½ï¼Œå­™å°ç©ºï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æˆ‘æ˜¯Qwenï¼Œä¸€ä¸ªç”±é€šä¹‰å®éªŒå®¤å¼€å‘çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ã€‚æˆ‘åœ¨è¿™é‡Œå¯ä»¥å’Œä½ èŠå¤©ã€å›ç­”é—®é¢˜ã€åˆ›ä½œæ–‡å­—ï¼Œç”šè‡³å¸®ä½ å­¦ä¹ æ–°çŸ¥è¯†ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼ŸğŸ˜Š\n",
      "\n",
      "--- Round 2: ä»‹ç»å¸ˆå¼Ÿ ---\n",
      "å•Šï¼Œä½ æåˆ°äº†â€œçŒªå°æˆ’â€å’Œâ€œæ²™å°åƒ§â€ï¼Œå¬èµ·æ¥åƒæ˜¯ä½ ç»™è‡ªå·±æˆ–ä½ çš„å¸ˆå¼Ÿä»¬èµ·çš„æ˜µç§°å‘¢ï¼è¿™è®©æˆ‘æƒ³èµ·äº†ã€Šè¥¿æ¸¸è®°ã€‹é‡Œçš„çŒªå…«æˆ’å’Œæ²™åƒ§ï¼Œä»–ä»¬æ˜¯ä¸­å›½å¤å…¸æ–‡å­¦ä¸­éå¸¸ç»å…¸çš„è§’è‰²ã€‚ä½ æ˜¯ä¸æ˜¯åœ¨ç”¨è¿™äº›åå­—æ¥è°ƒä¾ƒæˆ–è€…äº²è¿‘ä½ çš„å¸ˆå¼Ÿä»¬ï¼Ÿè¿˜æ˜¯ä»–ä»¬çœŸçš„å’Œã€Šè¥¿æ¸¸è®°ã€‹é‡Œçš„è§’è‰²æœ‰æŸç§è”ç³»ï¼Ÿ\n",
      "\n",
      "ä¸è¿‡ï¼Œæˆ‘æ³¨æ„åˆ°ä½ æåˆ°çš„æ˜¯â€œå¸ˆå¼Ÿâ€ï¼Œè¿™è®©æˆ‘æƒ³åˆ°ä½ å¯èƒ½æ˜¯åœ¨æŸç§å¸ˆå¾’å…³ç³»çš„ç¯å¢ƒä¸­ï¼Œæ¯”å¦‚æ­¦æœ¯ç¤¾å›¢ã€å­¦æœ¯å›¢é˜Ÿã€ç”šè‡³æ˜¯æ¸¸æˆä¸­çš„è§’è‰²ã€‚ä½ æœ‰æ²¡æœ‰ç‰¹åˆ«æƒ³å’Œä»–ä»¬ä¸€èµ·åšçš„äº‹æƒ…ï¼Ÿæˆ–è€…æœ‰ä»€ä¹ˆæœ‰è¶£çš„æ•…äº‹æƒ³åˆ†äº«ï¼Ÿæˆ‘å¾ˆä¹æ„å¬ä½ è¯´è¯´ä»–ä»¬çš„æ€§æ ¼ã€çˆ±å¥½ï¼Œä»¥åŠä½ ä»¬ä¹‹é—´çš„äº’åŠ¨ï¼\n",
      "\n",
      "--- Round 3: èŠé«˜è€ƒ (è§¦å‘é—å¿˜) ---\n",
      "å“‡ï¼Œæ­å–œä½ è€ƒä¸Š1æœ¬ï¼è¿™çœŸçš„æ˜¯ä¸€ä¸ªéå¸¸å€¼å¾—åº†ç¥çš„æˆå°±ï¼Œè¯´æ˜ä½ ä»˜å‡ºäº†å¾ˆå¤šåŠªåŠ›ï¼Œä¹Ÿå…·å¤‡äº†å¾ˆå¼ºçš„å­¦ä¹ èƒ½åŠ›å’Œæ¯…åŠ›ã€‚é«˜è€ƒæ˜¯ä¸­å›½å­¦ç”Ÿäººç”Ÿä¸­çš„ä¸€ä¸ªé‡è¦èŠ‚ç‚¹ï¼Œèƒ½å¤Ÿè€ƒä¸Š1æœ¬ï¼Œä¸ä»…ä»£è¡¨ä½ åœ¨å­¦æœ¯ä¸Šçš„ä¼˜ç§€ï¼Œä¹Ÿæ„å‘³ç€ä½ è¿ˆå‡ºäº†å®ç°æ¢¦æƒ³çš„é‡è¦ä¸€æ­¥ã€‚\n",
      "\n",
      "ä¸è¿‡ï¼Œè€ƒä¸Šäº†1æœ¬æ˜¯ä¸æ˜¯è®©ä½ æ„Ÿåˆ°æœ‰äº›æ„å¤–æˆ–è€…æƒŠå–œå‘¢ï¼Ÿæ¯•ç«Ÿè¿™ä¸ªç»“æœå¯èƒ½è¶…å‡ºäº†ä½ çš„é¢„æœŸï¼Œæˆ–è€…ä½ å¯èƒ½åœ¨å¤‡è€ƒè¿‡ç¨‹ä¸­é‡åˆ°äº†ä¸€äº›æŒ‘æˆ˜ã€‚å¦‚æœæ˜¯è¿™æ ·ï¼Œé‚£ä½ çš„åŠªåŠ›å’ŒåšæŒçœŸçš„æ²¡æœ‰ç™½è´¹ï¼\n",
      "\n",
      "ä½ ç°åœ¨ä¸€å®šå¾ˆæ¿€åŠ¨ï¼Œå¯èƒ½ä¹Ÿåœ¨æ€è€ƒæ¥ä¸‹æ¥çš„è·¯è¯¥æ€ä¹ˆèµ°ã€‚æ¯”å¦‚é€‰æ‹©ä¸“ä¸šã€å¡«æŠ¥å¿—æ„¿ï¼Œæˆ–è€…è€ƒè™‘æœªæ¥çš„å‘å±•æ–¹å‘ã€‚æœ‰ä»€ä¹ˆå…·ä½“çš„é—®é¢˜æˆ–è€…å›°æƒ‘ï¼Œæˆ‘å¯ä»¥å¸®ä½ ä¸€èµ·æ¢è®¨å—ï¼Ÿæ¯”å¦‚ä½ æ˜¯æƒ³äº†è§£å¤§å­¦ä¸“ä¸šçš„é€‰æ‹©å»ºè®®ï¼Œè¿˜æ˜¯å¯¹æœªæ¥çš„èŒä¸šè§„åˆ’æœ‰ç–‘é—®ï¼Ÿæ€»ä¹‹ï¼Œä¸ç®¡ä½ æƒ³äº†è§£ä»€ä¹ˆï¼Œæˆ‘éƒ½ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºä½ æä¾›å¸®åŠ©å’Œæ”¯æŒï¼\n",
      "\n",
      "--- Round 4: è¯¢é—®åå­— (éªŒè¯ k=1 æ•ˆæœ) ---\n",
      "å“¦ï¼Œè¿™ä¸ªé—®é¢˜å¾ˆæœ‰è¶£ï¼ä¸è¿‡æˆ‘å¥½åƒæ²¡æœ‰å…³äºä½ åå­—çš„å…·ä½“ä¿¡æ¯å‘¢ã€‚ä½ æ˜¯ç¬¬ä¸€æ¬¡å’Œæˆ‘äº¤è°ˆå—ï¼Ÿè¿˜æ˜¯è¯´æˆ‘ä»¬ä¹‹å‰æœ‰è¿‡ä¸€äº›äº’åŠ¨ï¼Ÿå¦‚æœä½ æ„¿æ„å‘Šè¯‰æˆ‘ä½ çš„åå­—ï¼Œæˆ‘ä¸€å®šä¼šè®°ä½çš„ï¼ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tiktoken\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import trim_messages\n",
    "\n",
    "# 1. åˆ›å»ºå¤§æ¨¡å‹\n",
    "llm = ChatOpenAI(\n",
    "    model=os.getenv(\"LLM_MODEL_ID\"),\n",
    "    )\n",
    "\n",
    "# 2. å®šä¹‰ä¿®å‰ªå™¨ (æ›¿ä»£ ConversationBufferWindowMemory)\n",
    "# ä½œç”¨ï¼šå®ƒä¼šè‡ªåŠ¨è®¡ç®— Tokenï¼Œåªä¿ç•™æœ€è¿‘çš„å†…å®¹ã€‚\n",
    "# ä¸ºäº†æ¨¡æ‹Ÿ k=1 (å³åªä¿ç•™æœ€å 1 è½®é—®ç­”)ï¼Œå°† max_tokens è®¾ç½®å¾—æ¯”è¾ƒå° (ä¾‹å¦‚ 100-200)ã€‚\n",
    "def custom_token_counter(messages) -> int:\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ OpenAI çš„ cl100k_base (GPT-4) ç¼–ç ä½œä¸ºè¿‘ä¼¼å€¼æ¥è®¡ç®— Tokenã€‚\n",
    "    è¿™é¿å…äº† LangChain å› ä¸ºä¸è®¤è¯† 'Qwen' æ¨¡å‹åå­—è€ŒæŠ¥é”™ã€‚\n",
    "    \"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    except Exception:\n",
    "        # å¦‚æœè·å–å¤±è´¥ï¼Œå›é€€åˆ° p50k_base\n",
    "        encoding = tiktoken.get_encoding(\"p50k_base\")\n",
    "    \n",
    "    num_tokens = 0\n",
    "    for msg in messages:\n",
    "        # ç®€å•ä¼°ç®—ï¼šå†…å®¹é•¿åº¦ + é¢å¤–å¼€é”€(æ¯æ¡æ¶ˆæ¯çº¦3-4ä¸ªtoken)\n",
    "        # è¿™ç§ä¼°ç®—å¯¹äº trim_messages è¿™ç§æˆªæ–­ç”¨é€”å·²ç»è¶³å¤Ÿç²¾ç¡®äº†\n",
    "        num_tokens += 4 \n",
    "        num_tokens += len(encoding.encode(msg.content))\n",
    "        \n",
    "    return num_tokens\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=66,        # é™åˆ¶ Token æ•°é‡ (æ¨¡æ‹Ÿçª—å£å¤§å°)\n",
    "    strategy=\"last\",       # ä¿ç•™æœ€æ–°çš„æ¶ˆæ¯\n",
    "    token_counter=custom_token_counter,     # ä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°è®¡ç®— Token\n",
    "    include_system=True,   # å§‹ç»ˆä¿ç•™ç³»ç»Ÿæç¤ºè¯\n",
    "    allow_partial=False,   # ä¸æˆªæ–­å•æ¡æ¶ˆæ¯çš„ä¸­é—´\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    # System Message\n",
    "    (\"system\", \"ä»¥ä¸‹æ˜¯äººç±»ä¸AIä¹‹é—´çš„å‹å¥½å¯¹è¯æè¿°ã€‚AIè¡¨ç°å¾—å¾ˆå¥è°ˆï¼Œå¹¶æä¾›äº†å¤§é‡æ¥è‡ªå…¶ä¸Šä¸‹æ–‡çš„å…·ä½“ç»†èŠ‚ã€‚å¦‚æœAIä¸çŸ¥é“é—®é¢˜çš„ç­”æ¡ˆï¼Œå®ƒä¼šè¡¨ç¤ºä¸çŸ¥é“ã€‚\"),\n",
    "    \n",
    "    # History Placeholder (è¿™é‡Œæ³¨å…¥çš„æ¶ˆæ¯ä¼šè¢« trimmer ä¿®å‰ªè¿‡)\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    \n",
    "    # Human Message\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "# 4. å®šä¹‰ Chain (LCEL ç®¡é“)\n",
    "# é€»è¾‘ï¼šè·å–å†å² -> ä¿®å‰ªå†å² -> å¡«å…… Prompt -> æ¨¡å‹æ¨ç† -> è§£æå­—ç¬¦ä¸²\n",
    "chain = (\n",
    "    RunnableWithMessageHistory(\n",
    "        prompt | llm | StrOutputParser(),\n",
    "        lambda session_id: get_session_history(session_id), # è·å–å†å²çš„å‡½æ•°\n",
    "        input_messages_key=\"question\",\n",
    "        history_messages_key=\"history\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# 5. å®šä¹‰å†å²å­˜å‚¨\n",
    "store = {}\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "chain_with_trimming = (\n",
    "    RunnableWithMessageHistory(\n",
    "        (lambda x: {\n",
    "            \"history\": trimmer.invoke(x[\"history\"]),\n",
    "            \"question\": x[\"question\"]\n",
    "        }) | prompt | llm | StrOutputParser(),\n",
    "        get_session_history,\n",
    "        input_messages_key=\"question\",\n",
    "        history_messages_key=\"history\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# 6. æ‰§è¡Œé“¾ (æ¨¡æ‹Ÿå¯¹è¯æµç¨‹)\n",
    "config = {\"configurable\": {\"session_id\": \"user_sun\"}}\n",
    "\n",
    "print(\"--- Round 1: è‡ªæˆ‘ä»‹ç» ---\")\n",
    "# æ­¤æ—¶å†å²ä¸ºç©ºï¼ŒAI è®°ä½ä½ æ˜¯å­™å°ç©º\n",
    "print(chain_with_trimming.invoke({\"question\": \"ä½ å¥½ï¼Œæˆ‘æ˜¯å­™å°ç©º\"}, config=config))\n",
    "\n",
    "print(\"\\n--- Round 2: ä»‹ç»å¸ˆå¼Ÿ ---\")\n",
    "# æ­¤æ—¶å†å²åŒ…å« Round 1ã€‚AI åº”è¯¥çŸ¥é“ä½ æ˜¯å­™å°ç©ºï¼Œå¹¶è®°ä½å¸ˆå¼Ÿã€‚\n",
    "print(chain_with_trimming.invoke({\"question\": \"æˆ‘è¿˜æœ‰ä¸¤ä¸ªå¸ˆå¼Ÿï¼Œä¸€ä¸ªæ˜¯çŒªå°æˆ’ï¼Œä¸€ä¸ªæ˜¯æ²™å°åƒ§\"}, config=config))\n",
    "\n",
    "print(\"\\n--- Round 3: èŠé«˜è€ƒ (è§¦å‘é—å¿˜) ---\")\n",
    "# æ­¤æ—¶å†å²åº”è¯¥åŒ…å« Round 2ã€‚Token é™åˆ¶ä¼šå¯¼è‡´ Round 1 (åå­—) è¢«æŒ¤å‡ºã€‚\n",
    "print(chain_with_trimming.invoke({\"question\": \"æˆ‘ä»Šå¹´é«˜è€ƒï¼Œç«Ÿç„¶è€ƒä¸Šäº†1æœ¬\"}, config=config))\n",
    "\n",
    "print(\"\\n--- Round 4: è¯¢é—®åå­— (éªŒè¯ k=1 æ•ˆæœ) ---\")\n",
    "# æ­¤æ—¶å†å²åªåŒ…å« Round 3 (é«˜è€ƒ)ã€‚Round 1 çš„åå­—å·²ç»è¢«å½»åº•é—å¿˜äº†ã€‚\n",
    "# é¢„æœŸç»“æœï¼šAI è¡¨ç¤ºä¸çŸ¥é“ä½ çš„åå­—ã€‚\n",
    "print(chain_with_trimming.invoke({\"question\": \"æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ\"}, config=config))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
