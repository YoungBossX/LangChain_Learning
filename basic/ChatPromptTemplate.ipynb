{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30ed80bd",
   "metadata": {},
   "source": [
    "# 提示词模板之ChatPromptTemplate的使用\n",
    "\n",
    "1、实例化的方式（两种方式：使用构造方法、from_messages()）\n",
    "\n",
    "2、调用提示词模板的几种方法：invoke() \\ format() \\ format_messages() \\ format_prompt()\n",
    "\n",
    "3、更丰富的实例化参数类型\n",
    "\n",
    "4、结合LLM\n",
    "\n",
    "5、插入消息列表：MessagePlaceholder\n",
    "\n",
    "## 1、实例化的方式\n",
    "\n",
    "方式1：使用构造方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47fc834a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个AI助手，你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是1 + 2 * 3 = ？', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.prompt_values.ChatPromptValue'>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# 创建实例\n",
    "chat_prompt_template = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        (\"system\", \"你是一个AI助手，你的名字叫{name}\"),\n",
    "        (\"human\", \"我的问题是{question}\")\n",
    "    ],\n",
    "    input_variables=[\"name\", \"question\"],\n",
    ")\n",
    "\n",
    "response = chat_prompt_template.invoke(input={\"name\": \"小智\", \"question\": \"1 + 2 * 3 = ？\"})\n",
    "print(response)\n",
    "print(type(response))  # <class 'langchain_core.prompt_values.ChatPromptValue'>\n",
    "print(len(response.messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72f6e63",
   "metadata": {},
   "source": [
    "更简洁的方式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f74753c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个AI助手，你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是1 + 2 * 3 = ？', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.prompt_values.ChatPromptValue'>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建实例\n",
    "chat_prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"你是一个AI助手，你的名字叫{name}\"),\n",
    "    (\"human\", \"我的问题是{question}\")\n",
    "])\n",
    "\n",
    "response = chat_prompt_template.invoke({\"name\": \"小智\", \"question\": \"1 + 2 * 3 = ？\"})\n",
    "print(response)\n",
    "print(type(response))  # <class 'langchain_core.prompt_values.ChatPromptValue'>\n",
    "print(len(response.messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dea8af",
   "metadata": {},
   "source": [
    "方式2：调用from_message()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd4375e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个AI助手，你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是1 + 2 * 3 = ？', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.prompt_values.ChatPromptValue'>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建实例\n",
    "# chat_prompt_template = ChatPromptTemplate([\n",
    "#         (\"system\",\"你是一个AI助手，你的名字叫{name}\"),\n",
    "#         (\"human\",\"我的问题是{question}\")\n",
    "# ])\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个AI助手，你的名字叫{name}\"),\n",
    "    (\"human\", \"我的问题是{question}\")\n",
    "])\n",
    "\n",
    "response = chat_prompt_template.invoke({\"name\": \"小智\", \"question\": \"1 + 2 * 3 = ？\"})\n",
    "print(response)\n",
    "print(type(response))  # <class 'langchain_core.prompt_values.ChatPromptValue'>\n",
    "print(len(response.messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e79c42",
   "metadata": {},
   "source": [
    "## 2、调用提示词模板的几种方法\n",
    "\n",
    "invoke() \\ format() \\ format_messages() \\ format_prompt()\n",
    "\n",
    "invoke()：传入的是字典，返回ChatPromptValue\n",
    "\n",
    "format():传入变量的值，返回str\n",
    "\n",
    "format_messages(): 传入变量的值，返回消息构成的list\n",
    "\n",
    "format_prompt(): 传入变量的值，返回ChatPromptValue\n",
    "\n",
    "#举例1：invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "431d1140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个AI助手，你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是1 + 2 * 3 = ？', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.prompt_values.ChatPromptValue'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建实例\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个AI助手，你的名字叫{name}\"),\n",
    "    (\"human\", \"我的问题是{question}\")\n",
    "])\n",
    "\n",
    "response = chat_prompt_template.invoke({\"name\": \"小智\", \"question\": \"1 + 2 * 3 = ？\"})\n",
    "print(response)\n",
    "print(type(response))  # <class 'langchain_core.prompt_values.ChatPromptValue'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e8fca5",
   "metadata": {},
   "source": [
    "举例2：format()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03731a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: 你是一个AI助手，你的名字叫小智\n",
      "Human: 我的问题是1 + 2 * 3 = ？\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建实例\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个AI助手，你的名字叫{name}\"),\n",
    "    (\"human\", \"我的问题是{question}\")\n",
    "])\n",
    "\n",
    "response = chat_prompt_template.format(name=\"小智\", question=\"1 + 2 * 3 = ？\")\n",
    "print(response)\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d08d91",
   "metadata": {},
   "source": [
    "举例3：format_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ae2f735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个AI助手，你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是1 + 2 * 3 = ？', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.prompt_values.ChatPromptValue'>\n",
      "[SystemMessage(content='你是一个AI助手，你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是1 + 2 * 3 = ？', additional_kwargs={}, response_metadata={})]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建实例\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个AI助手，你的名字叫{name}\"),\n",
    "    (\"human\", \"我的问题是{question}\")\n",
    "])\n",
    "\n",
    "response = chat_prompt_template.invoke({\"name\": \"小智\", \"question\": \"1 + 2 * 3 = ？\"})\n",
    "print(response)\n",
    "print(type(response))  # from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建实例\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个AI助手，你的名字叫{name}\"),\n",
    "    (\"human\", \"我的问题是{question}\")\n",
    "])\n",
    "\n",
    "response = chat_prompt_template.format_messages(name=\"小智\", question=\"1 + 2 * 3 = ？\")\n",
    "print(response)\n",
    "print(type(response))  # <class 'list'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceff69e",
   "metadata": {},
   "source": [
    "举例4：format_prompt()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e8ba3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个AI助手，你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是1 + 2 * 3 = ？', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.prompt_values.ChatPromptValue'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建实例\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个AI助手，你的名字叫{name}\"),\n",
    "    (\"human\", \"我的问题是{question}\")\n",
    "])\n",
    "\n",
    "response = chat_prompt_template.format_prompt(name=\"小智\", question=\"1 + 2 * 3 = ？\")\n",
    "print(response)\n",
    "print(type(response))  # <class 'langchain_core.prompt_values.ChatPromptValue'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60e09c7",
   "metadata": {},
   "source": [
    "如何实现ChatPromptValue与list[messages]、字符串之间的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a59378c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: 你是一个AI助手，你的名字叫小智\n",
      "Human: 我的问题是1 + 2 * 3 = ？\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建实例\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个AI助手，你的名字叫{name}\"),\n",
    "    (\"human\", \"我的问题是{question}\")\n",
    "])\n",
    "\n",
    "# response = chat_prompt_template.format_prompt(name=\"小智\", question=\"1 + 2 * 3 = ？\")\n",
    "response = chat_prompt_template.invoke({\"name\": \"小智\", \"question\": \"1 + 2 * 3 = ？\"})\n",
    "\n",
    "# 将ChatPromptValue类型转换为消息构成的list\n",
    "response_messages = response.to_messages()\n",
    "# print(response_messages)\n",
    "# print(type(response_messages))\n",
    "\n",
    "# 将ChatPromptValue类型转换为字符串类型\n",
    "response_to_string = response.to_string()\n",
    "print(response_to_string)\n",
    "print(type(response_to_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3e8d38",
   "metadata": {},
   "source": [
    "## 3、更丰富的实例化参数类型\n",
    "\n",
    "本质：不管使用构造方法、还是使用from_message()来创建ChatPromptTemplate的实例，本质上来讲，传入的都是消息构成的列表。\n",
    "\n",
    "从调用上来讲，我们看到，不管使用构造方法，还是使用from_message()，messages参数的类型都是列表，但是列表的元素的类型是多样的。元素可以是：\n",
    "\n",
    "字符串类型、字典类型、消息类型、元组构成的列表（最常用、最基础、最简单）、Chat提示词模板类型、消息提示词模板类型\n",
    "\n",
    "举例1：元组构成的列表（最常用、最基础、最简单）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18028b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建实例\n",
    "# 第1种方式\n",
    "chat_prompt_template1 = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        (\"system\", \"你是一个AI助手，你的名字叫{name}\"),\n",
    "        (\"human\", \"我的问题是{question}\")\n",
    "    ]\n",
    ")\n",
    "# 第2种方式\n",
    "chat_prompt_template2 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个AI助手，你的名字叫{name}\"),\n",
    "    (\"human\", \"我的问题是{question}\")\n",
    "])\n",
    "\n",
    "response = chat_prompt_template1.invoke({\"name\": \"小智\", \"question\": \"1 + 2 * 3 = ？\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceef450",
   "metadata": {},
   "source": [
    "举例2：字符串\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4067ddc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='我的问题是1 + 2 * 3 = ？', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建实例\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    \"我的问题是{question}\"  # 默认的角色是：human\n",
    "])\n",
    "\n",
    "response = chat_prompt_template.invoke({\"question\": \"1 + 2 * 3 = ？\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc36abd",
   "metadata": {},
   "source": [
    "举例3：字典类型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f323c8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='我是一个人工智能助手，我的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是1 + 2 * 3 = ？', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建实例\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    {\"role\": \"system\", \"content\": \"我是一个人工智能助手，我的名字叫{name}\"},\n",
    "    {\"role\": \"human\", \"content\": \"我的问题是{question}\"},\n",
    "])\n",
    "\n",
    "response = chat_prompt_template.invoke({\"name\": \"小智\", \"question\": \"1 + 2 * 3 = ？\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937d4033",
   "metadata": {},
   "source": [
    "举例4：消息类型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fbf94b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='我是一个人工智能助手，我的名字叫{name}', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是{question}', additional_kwargs={}, response_metadata={})]\n",
      "我是一个人工智能助手，我的名字叫{name}\n",
      "我的问题是{question}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建实例\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(\"我是一个人工智能助手，我的名字叫{name}\"),\n",
    "    HumanMessage(\"我的问题是{question}\")\n",
    "])\n",
    "\n",
    "response = chat_prompt_template.invoke({\"name\":\"小智\", \"question\":\"1 + 2 * 3 = ？\"})\n",
    "# response = chat_prompt_template.invoke({})\n",
    "print(response)\n",
    "print(response.messages[0].content) \n",
    "print(response.messages[1].content) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b2b94",
   "metadata": {},
   "source": [
    "举例5：Chat提示词模板类型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c53cc0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='我是一个人工智能助手，我的名字叫小智', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='很高兴认识你,我的问题是你为什么这么帅？', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 使用 BaseChatPromptTemplate（嵌套的 ChatPromptTemplate）\n",
    "nested_prompt_template1 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"我是一个人工智能助手，我的名字叫{name}\")\n",
    "])\n",
    "nested_prompt_template2 = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"很高兴认识你,我的问题是{question}\")\n",
    "])\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    nested_prompt_template1,\n",
    "    nested_prompt_template2\n",
    "])\n",
    "\n",
    "prompt_template.format_messages(name=\"小智\", question=\"你为什么这么帅？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28de9b3",
   "metadata": {},
   "source": [
    "举例6：消息提示词模板类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93350921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是一个专家模型', additional_kwargs={}, response_metadata={}), HumanMessage(content='给我解释原理，用浅显易懂的语言', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# 导入聊天消息类模板\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "# 创建消息模板\n",
    "system_template = \"你是一个专家{role}\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "human_template = \"给我解释{concept}，用浅显易懂的语言\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# 组合成聊天提示模板\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message_prompt, human_message_prompt\n",
    "])\n",
    "\n",
    "# 格式化提示\n",
    "formatted_messages = chat_prompt.format_messages(\n",
    "    role=\"模型\",\n",
    "    concept=\"原理\"\n",
    ")\n",
    "print(formatted_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01e103d",
   "metadata": {},
   "source": [
    "## 4、结合LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6da12078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='根据数学中的运算法则，乘法优先于加法。所以，我们先计算2 * 3，然后将结果加到1上。计算过程如下：\\n\\n1 + 2 * 3 = 1 + 6 = 7\\n\\n答案是7。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 35, 'total_tokens': 92, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'Qwen/Qwen2.5-7B-Instruct', 'system_fingerprint': '', 'id': '019bf3eca8b21b7cef736bb5605913dc', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019bf3ec-b512-7bf3-bc7a-689b0f70c24d-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 35, 'output_tokens': 57, 'total_tokens': 92, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "# 1、提供大模型\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "#加载配置文件\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"LLM_BASE_URL\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"LLM_API_KEY\")\n",
    "\n",
    "# 获取对话模型：\n",
    "chat_model = ChatOpenAI(\n",
    "    model=os.getenv(\"LLM_MODEL_ID\")\n",
    ")\n",
    "\n",
    "# 2、通过Chat提示词模板，创建提示词\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建实例\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个AI助手，你的名字叫{name}\"),\n",
    "    (\"human\", \"我的问题是{question}\")\n",
    "])\n",
    "\n",
    "prompt_response = chat_prompt_template.invoke({\"name\": \"小智\", \"question\": \"1 + 2 * 3 = ？\"})\n",
    "\n",
    "# 3、通过大模型调用提示词，得到响应数据\n",
    "response = chat_model.invoke(prompt_response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732806d2",
   "metadata": {},
   "source": [
    "## 5、插入消息列表：MessagePlaceholder\n",
    "\n",
    "使用场景：当ChatPromptTemplate模板中的消息类型和个数不确定的时候，我们就可以使用MessagePlaceholder。\n",
    "\n",
    "举例1：\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1960d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='你是一个AI助手，你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是：1 + 2 * 3 = ?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.chat import MessagesPlaceholder\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个AI助手，你的名字叫{name}\"),\n",
    "    MessagesPlaceholder(variable_name=\"1\")\n",
    "])\n",
    "\n",
    "chat_prompt_template.invoke({\n",
    "    \"name\": \"小智\",\n",
    "    \"1\": [HumanMessage(content=\"我的问题是：1 + 2 * 3 = ?\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcb7e58",
   "metadata": {},
   "source": [
    "举例2："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f206e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='你是一个AI助手，你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是：1 + 2 * 3 = ?', additional_kwargs={}, response_metadata={}), AIMessage(content='1 + 2 * 3 = 7', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.chat import MessagesPlaceholder\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个AI助手，你的名字叫{name}\"),\n",
    "    MessagesPlaceholder(variable_name=\"1\")\n",
    "])\n",
    "\n",
    "chat_prompt_template.invoke({\n",
    "    \"name\": \"小智\",\n",
    "    \"1\": [HumanMessage(content=\"我的问题是：1 + 2 * 3 = ?\"), AIMessage(content=\"1 + 2 * 3 = 7\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946e7d76",
   "metadata": {},
   "source": [
    "举例3：存储对话历史记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35b378bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        MessagesPlaceholder(\"history\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# prompt_value = prompt.format_messages(\n",
    "#     history=[HumanMessage(content=\"1+2*3 = ?\"), AIMessage(content=\"1+2*3=7\")],\n",
    "#     question=\"我刚才问题是什么？\"\n",
    "#     )\n",
    "\n",
    "# print(prompt_value)\n",
    "\n",
    "prompt_value = prompt.invoke(\n",
    "    {\n",
    "        \"history\": [(\"human\", \"what's 5 + 2\"), (\"ai\", \"5 + 2 is 7\")],\n",
    "        \"question\": \"now multiply that by 4\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcd0e997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure! \\n\\n\\\\( (5 + 2) \\\\times 4 = 7 \\\\times 4 = 28 \\\\)', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 49, 'total_tokens': 76, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'Qwen/Qwen2.5-7B-Instruct', 'system_fingerprint': '', 'id': '019bf3f8a770510632b92138b89f5598', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bf3f8-b3fb-7b01-be56-1819f98afd52-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 49, 'output_tokens': 27, 'total_tokens': 76, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "# 加载配置文件\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"LLM_BASE_URL\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"LLM_API_KEY\")\n",
    "\n",
    "# 获取对话模型：\n",
    "chat_model = ChatOpenAI(\n",
    "    model=os.getenv(\"LLM_MODEL_ID\")\n",
    ")\n",
    "\n",
    "chat_model.invoke(prompt_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
