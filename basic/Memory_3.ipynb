{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "973e19df",
   "metadata": {},
   "source": [
    "# 1、ConversationTokenBufferMemory的使用\n",
    "\n",
    "举例1："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f61c6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "# 创建大模型实例\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17b61a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始内存 (共 4 条消息) ---\n",
      "[HumanMessage(content='你好吗？', additional_kwargs={}, response_metadata={}), AIMessage(content='我很好，谢谢！', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='今天天气如何？', additional_kwargs={}, response_metadata={}), AIMessage(content='晴天，25度', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n",
      "\n",
      "--- 优化后：修剪结果 (Max=10) ---\n",
      "[AIMessage(content='晴天，25度', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.messages import trim_messages\n",
    "\n",
    "# ====================================================\n",
    "# 1. 定义离线计数器 (防止网络卡顿的关键)\n",
    "# ====================================================\n",
    "def offline_counter(messages) -> int:\n",
    "    \"\"\"用字数模拟 Token 数，每 1 个字算 1 个 Token (粗略估算)\"\"\"\n",
    "    total = 0\n",
    "    for msg in messages:\n",
    "        total += len(msg.content)\n",
    "    return total\n",
    "\n",
    "# ====================================================\n",
    "# 2. 定义修剪器 (替代 ConversationTokenBufferMemory)\n",
    "# ====================================================\n",
    "# 对应旧版的 max_token_limit=10\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=10,          # 限制大小\n",
    "    strategy=\"last\",        # 保留最新的\n",
    "    token_counter=offline_counter, # 使用离线计数，秒运行\n",
    "    include_system=True,\n",
    "    allow_partial=False,    # 不切断单句话\n",
    ")\n",
    "\n",
    "# ====================================================\n",
    "# 3. 操作流程\n",
    "# ====================================================\n",
    "\n",
    "# A. 存储消息 (使用 InMemoryChatMessageHistory)\n",
    "history = InMemoryChatMessageHistory()\n",
    "history.add_user_message(\"你好吗？\")       # 4个字\n",
    "history.add_ai_message(\"我很好，谢谢！\")   # 6个字 (累计10)\n",
    "history.add_user_message(\"今天天气如何？\") # 6个字 (累计16)\n",
    "history.add_ai_message(\"晴天，25度\")       # 5个字 (累计21)\n",
    "\n",
    "print(f\"--- 原始内存 (共 {len(history.messages)} 条消息) ---\")\n",
    "print(history.messages)\n",
    "\n",
    "# B. 获取修剪后的结果\n",
    "# 这步操作通常在 Chain 内部自动做，这里手动演示效果\n",
    "pruned_messages = trimmer.invoke(history.messages)\n",
    "\n",
    "print(f\"\\n--- 优化后：修剪结果 (Max=10) ---\")\n",
    "# 因为最后一条 \"晴天，25度\" 占5个token，上一条 \"今天天气...\" 占6个\n",
    "# 5+6=11 > 10，所以只能保留最后一条\n",
    "print(pruned_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43820c85",
   "metadata": {},
   "source": [
    "举例2："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3929e71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始全量记忆 (共 4 条) ---\n",
      "[HumanMessage(content='你好吗？', additional_kwargs={}, response_metadata={}), AIMessage(content='我很好，谢谢！', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='今天天气如何？', additional_kwargs={}, response_metadata={}), AIMessage(content='晴天，25度', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n",
      "\n",
      "--- 优化后：修剪结果 (Max=20) ---\n",
      "[AIMessage(content='我很好，谢谢！', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='今天天气如何？', additional_kwargs={}, response_metadata={}), AIMessage(content='晴天，25度', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.messages import trim_messages\n",
    "\n",
    "# ====================================================\n",
    "# 1. 定义离线计数器 (关键优化)\n",
    "# ====================================================\n",
    "# 为了防止 tiktoken 下载卡死，用“字数”粗略模拟 Token 数\n",
    "# 在中文语境下，1个汉字通常对应 0.7~2 个 Token，这里简单按 1:1 计算用于演示\n",
    "def offline_token_counter(messages) -> int:\n",
    "    total = 0\n",
    "    for msg in messages:\n",
    "        total += len(msg.content)\n",
    "    return total\n",
    "\n",
    "# ====================================================\n",
    "# 2. 定义修剪器 (替代 ConversationTokenBufferMemory)\n",
    "# ====================================================\n",
    "# 对应你原来的 max_token_limit=20\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=20,          # 设置上限 (这里按字数算)\n",
    "    strategy=\"last\",        # 保留最新的消息\n",
    "    token_counter=offline_token_counter, # 使用离线计数\n",
    "    include_system=True,\n",
    "    allow_partial=False,    # 不截断单条消息\n",
    ")\n",
    "\n",
    "# ====================================================\n",
    "# 3. 操作流程\n",
    "# ====================================================\n",
    "\n",
    "# A. 存储消息 (使用 InMemoryChatMessageHistory)\n",
    "# 这是一个全量的笔记本，记录所有历史，不会自动删除\n",
    "history = InMemoryChatMessageHistory()\n",
    "\n",
    "# Round 1\n",
    "history.add_user_message(\"你好吗？\")       # 4 字\n",
    "history.add_ai_message(\"我很好，谢谢！\")   # 6 字\n",
    "\n",
    "# Round 2\n",
    "history.add_user_message(\"今天天气如何？\") # 6 字\n",
    "history.add_ai_message(\"晴天，25度\")       # 5 字\n",
    "\n",
    "# B. 查看原始记忆\n",
    "print(f\"--- 原始全量记忆 (共 {len(history.messages)} 条) ---\")\n",
    "print(history.messages)\n",
    "\n",
    "# C. 执行修剪 (模拟 load_memory_variables)\n",
    "# 这一步通常在 Chain 内部做，这里手动展示效果\n",
    "# 计算逻辑：\n",
    "# 最后一条(5) + 倒数第二条(6) + 倒数第三条(6) = 17 < 20\n",
    "# 如果再加倒数第四条(4) = 21 > 20，超标了！\n",
    "# 所以预期结果：丢弃最早的 \"你好吗？\"，保留后三条 (或者根据 trim 策略保留成对)\n",
    "pruned_messages = trimmer.invoke(history.messages)\n",
    "\n",
    "print(f\"\\n--- 优化后：修剪结果 (Max=20) ---\")\n",
    "print(pruned_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66cb58b",
   "metadata": {},
   "source": [
    "# 2、SummaryMemory的使用\n",
    "\n",
    "举例1：\n",
    "\n",
    "如果实例化SummaryMemory前，没有历史消息，可以使用构造方法实例化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7515d271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始对话条数: 6 ---\n",
      "\n",
      "--- 优化后：生成的摘要 ---\n",
      "人类询问AI的身份，AI介绍自己为无所不能的AI助手小智。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 创建大模型\n",
    "llm = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "# ==========================================================\n",
    "# 2. 准备历史数据\n",
    "# ==========================================================\n",
    "# 先创建一个历史记录对象，把对话存进去\n",
    "history = InMemoryChatMessageHistory()\n",
    "history.add_user_message(\"你好\")\n",
    "history.add_ai_message(\"怎么了\")\n",
    "history.add_user_message(\"你是谁\")\n",
    "history.add_ai_message(\"我是AI助手小智\")\n",
    "history.add_user_message(\"初次对话，你能介绍一下你自己吗？\")\n",
    "history.add_ai_message(\"当然可以了。我是一个无所不能的小智。\")\n",
    "\n",
    "print(f\"--- 原始对话条数: {len(history.messages)} ---\")\n",
    "\n",
    "# ==========================================================\n",
    "# 3. 定义总结链 (替代 ConversationSummaryMemory 的黑盒逻辑)\n",
    "# ==========================================================\n",
    "# 这是一个专门用来做“阅读理解”的 Prompt\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    请将以下的对话内容总结为一个简短的摘要（Summary）。\n",
    "    摘要应包含关键信息，去除冗余的寒暄。\n",
    "    \n",
    "    对话内容：\n",
    "    {chat_history}\n",
    "    \n",
    "    摘要：\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 格式化Prompt -> 调用LLM -> 解析成字符串\n",
    "summarize_chain = summary_prompt | llm | StrOutputParser()\n",
    "\n",
    "# ==========================================================\n",
    "# 4. 执行总结\n",
    "# ==========================================================\n",
    "# history.messages 转换成字符串传给 chain\n",
    "# (注：如果模型支持直接读 Message 对象，也可以用 MessagesPlaceholder)\n",
    "chat_history_str = \"\\n\".join([f\"{msg.type}: {msg.content}\" for msg in history.messages])\n",
    "\n",
    "summary = summarize_chain.invoke({\"chat_history\": chat_history_str})\n",
    "\n",
    "print(\"\\n--- 优化后：生成的摘要 ---\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd91808",
   "metadata": {},
   "source": [
    "举例2：如果SummaryMemory前，已经有历史消息，可以调用from_messages()实例化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ed8dbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 初始历史消息数: 2 ---\n",
      "\n",
      "[操作 1] 生成初始摘要...\n",
      "摘要内容: 用户询问AI的身份，AI回应称自己是AI助手小智。\n",
      "\n",
      "[操作 2] 添加新对话...\n",
      "\n",
      "[操作 3] 生成更新后的摘要...\n",
      "摘要内容: 用户小明向AI助手小智问好并介绍自己，小智回应并表达欢迎。对话中包含用户身份为小明，AI身份为小智。\n",
      "\n",
      "[操作 4] 查看完整历史记录...\n",
      "[HumanMessage(content='你好，你是谁？', additional_kwargs={}, response_metadata={}), AIMessage(content='我是AI助手小智', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='我的名字叫小明', additional_kwargs={}, response_metadata={}), AIMessage(content='很高兴认识你', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "# 1. 创建大模型\n",
    "llm = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "# =========================================================\n",
    "# 2. 准备历史消息 (替代 ChatMessageHistory)\n",
    "# =========================================================\n",
    "# 使用 Core 组件 InMemoryChatMessageHistory\n",
    "history = InMemoryChatMessageHistory()\n",
    "\n",
    "# 假设的原始消息\n",
    "history.add_user_message(\"你好，你是谁？\")\n",
    "history.add_ai_message(\"我是AI助手小智\")\n",
    "\n",
    "print(f\"--- 初始历史消息数: {len(history.messages)} ---\")\n",
    "\n",
    "# =========================================================\n",
    "# 3. 定义总结链\n",
    "# =========================================================\n",
    "# 可以清楚地定义如何做总结，而不是依赖内部写死的英文 Prompt\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    请阅读以下的对话历史，并将其压缩为一个简练的摘要（Summary）。\n",
    "    摘要应包含关键信息，如用户身份、AI身份等。\n",
    "\n",
    "    对话历史：\n",
    "    {history_str}\n",
    "\n",
    "    摘要：\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 构建 LCEL 链：格式化 -> LLM -> 解析字符串\n",
    "summarizer_chain = summary_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 辅助函数：将消息对象转为字符串，并生成摘要\n",
    "def get_current_summary(chat_history):\n",
    "    # 将 Message 对象列表转换为文本字符串\n",
    "    history_str = \"\\n\".join([f\"{msg.type}: {msg.content}\" for msg in chat_history.messages])\n",
    "    # 调用链生成摘要\n",
    "    return summarizer_chain.invoke({\"history_str\": history_str})\n",
    "\n",
    "# =========================================================\n",
    "# 4. 操作流程演示\n",
    "# =========================================================\n",
    "\n",
    "# A. 打印初始摘要\n",
    "print(\"\\n[操作 1] 生成初始摘要...\")\n",
    "summary_v1 = get_current_summary(history)\n",
    "print(f\"摘要内容: {summary_v1}\")\n",
    "\n",
    "# B. 添加新对话\n",
    "print(\"\\n[操作 2] 添加新对话...\")\n",
    "history.add_user_message(\"我的名字叫小明\")\n",
    "history.add_ai_message(\"很高兴认识你\")\n",
    "\n",
    "# C. 再次生成摘要\n",
    "print(\"\\n[操作 3] 生成更新后的摘要...\")\n",
    "summary_v2 = get_current_summary(history)\n",
    "print(f\"摘要内容: {summary_v2}\")\n",
    "\n",
    "# D. 查看原始消息\n",
    "print(\"\\n[操作 4] 查看完整历史记录...\")\n",
    "print(history.messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
