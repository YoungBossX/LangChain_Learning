{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead4cc7d",
   "metadata": {},
   "source": [
    "# å°‘é‡ç¤ºä¾‹çš„æç¤ºè¯æ¨¡æ¿çš„ä½¿ç”¨\n",
    "\n",
    "FewShotPromptTemplate: ä¸PromptTemplateä¸€èµ·ä½¿ç”¨\n",
    "\n",
    "FewShotChatMessagePromptTemplateï¼šä¸ChatPromptTemplateä¸€èµ·ä½¿ç”¨\n",
    "\n",
    "Example selectors(ç¤ºä¾‹é€‰æ‹©å™¨):\n",
    "\n",
    "## 1ã€FewShotPromptTemplateçš„ä½¿ç”¨\n",
    "\n",
    "\n",
    "ä¸¾ä¾‹1ï¼šæœªæä¾›ç¤ºä¾‹çš„æƒ…å†µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8e971a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‚¨çš„è¡¨è¾¾å¯èƒ½éœ€è¦ä¸€äº›æ¾„æ¸…ã€‚å¦‚æœæ‚¨æ˜¯æƒ³è¦è¿›è¡Œæ•°å­¦è¿ç®—ï¼Œé‚£ä¹ˆ2åŠ ä¸Š9ç­‰äº11ã€‚å¦‚æœæ‚¨æ˜¯æŒ‡å…¶ä»–å«ä¹‰ï¼Œè¯·æä¾›æ›´å¤šä¿¡æ¯ï¼Œæˆ‘å°†å¾ˆä¹æ„å¸®åŠ©æ‚¨ã€‚\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_core.prompts import FewShotPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "chat_model = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"),\n",
    "                        temperature=0.7)\n",
    "\n",
    "res = chat_model.invoke(\"2 ğŸ¦œ 9æ˜¯å¤šå°‘?\")\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e774b66",
   "metadata": {},
   "source": [
    "ä¸¾ä¾‹2ï¼šä½¿ç”¨FewShotPromptTemplate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb575432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='input:é•¿æ²™å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\\noutput:é•¿æ²™å¸‚\\n\\ninput:å—äº¬ä¸‹é›¨å—ï¼Ÿ\\noutput:å—äº¬å¸‚\\n\\ninput:æ­¦æ±‰çƒ­å—ï¼Ÿ\\noutput:æ­¦æ±‰å¸‚\\n\\ninput:æ­å·ä¼šä¸‹é›¨å—ï¼Ÿ\\noutput:')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# åˆ›å»ºPromptTemplateçš„å®ä¾‹\n",
    "example_prompt = PromptTemplate.from_template(\n",
    "    template=\"input:{input}\\noutput:{output}\",\n",
    ")\n",
    "\n",
    "# æä¾›ä¸€äº›ç¤ºä¾‹\n",
    "examples = [\n",
    "    {\"input\": \"é•¿æ²™å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\", \"output\": \"é•¿æ²™å¸‚\"},\n",
    "    {\"input\": \"å—äº¬ä¸‹é›¨å—ï¼Ÿ\", \"output\": \"å—äº¬å¸‚\"},\n",
    "    {\"input\": \"æ­¦æ±‰çƒ­å—ï¼Ÿ\", \"output\": \"æ­¦æ±‰å¸‚\"}\n",
    "]\n",
    "\n",
    "# åˆ›å»ºFewShotPromptTemplateçš„å®ä¾‹\n",
    "few_shot_template = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples = examples,\n",
    "    suffix=\"input:{input}\\noutput:\", # å£°æ˜åœ¨ç¤ºä¾‹åé¢çš„æç¤ºè¯æ¨¡æ¿\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "few_shot_template.invoke({\"input\":\"æ­å·ä¼šä¸‹é›¨å—ï¼Ÿ\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db4aa1",
   "metadata": {},
   "source": [
    "è°ƒç”¨å¤§æ¨¡å‹ä»¥åï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99b3f3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='æ­å·å¸‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 68, 'total_tokens': 69, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'Qwen/Qwen2.5-7B-Instruct', 'system_fingerprint': '', 'id': '019bf409bae898789574b7e88db76545', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bf409-c784-7fd1-90a7-9919f0684162-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 68, 'output_tokens': 1, 'total_tokens': 69, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "chat_model = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"), temperature=0.4)\n",
    "\n",
    "chat_model.invoke(few_shot_template.invoke({\"input\":\"æ­å·ä¼šä¸‹é›¨å—ï¼Ÿ\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705d6469",
   "metadata": {},
   "source": [
    "ä¸¾ä¾‹3ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade7cb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ æ˜¯ä¸€ä¸ªæ•°å­¦ä¸“å®¶,ç®—å¼: 2*5 å€¼: 10 ä½¿ç”¨ï¼š ä¹˜æ³•è¿ç®— \n",
      "\n",
      "è§£æï¼šè¿™ä¸ªç®—å¼æ˜¯2ä¹˜ä»¥5ï¼Œæ ¹æ®ä¹˜æ³•è¿ç®—çš„è§„åˆ™ï¼Œ2ä¹˜ä»¥5çš„ç»“æœæ˜¯10ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œ2æ˜¯ä¹˜æ•°ï¼Œ5ä¹Ÿæ˜¯ä¹˜æ•°ï¼Œå®ƒä»¬ç›¸ä¹˜çš„ç»“æœå°±æ˜¯10ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# æç¤ºæ¨¡æ¿ï¼Œé…ç½®ä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼Œå°†ä¸€ä¸ªç¤ºä¾‹æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²\n",
    "prompt_template = \"ä½ æ˜¯ä¸€ä¸ªæ•°å­¦ä¸“å®¶,ç®—å¼ï¼š {input} å€¼ï¼š {output} ä½¿ç”¨ï¼š {description} \"\n",
    "\n",
    "# è¿™æ˜¯ä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼Œç”¨äºè®¾ç½®æ¯ä¸ªç¤ºä¾‹çš„æ ¼å¼\n",
    "prompt_sample = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# 2ã€æä¾›ç¤ºä¾‹\n",
    "examples = [\n",
    "    {\"input\": \"2+2\", \"output\": \"4\", \"description\": \"åŠ æ³•è¿ç®—\"},\n",
    "    {\"input\": \"5-2\", \"output\": \"3\", \"description\": \"å‡æ³•è¿ç®—\"},\n",
    "]\n",
    "\n",
    "# 3ã€åˆ›å»ºä¸€ä¸ªFewShotPromptTemplateå¯¹è±¡\n",
    "from langchain_core.prompts import FewShotPromptTemplate\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=prompt_sample,\n",
    "    suffix=\"ä½ æ˜¯ä¸€ä¸ªæ•°å­¦ä¸“å®¶,ç®—å¼: {input}  å€¼: {output}\",\n",
    "    input_variables=[\"input\", \"output\"]\n",
    ")\n",
    "# print(prompt.invoke({\"input\":\"2*5\", \"output\":\"10\"}))\n",
    "\n",
    "# 4ã€åˆå§‹åŒ–å¤§æ¨¡å‹ï¼Œç„¶åè°ƒç”¨\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "chat_model = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "result = chat_model.invoke(prompt.invoke({\"input\":\"2*5\", \"output\":\"\"}))\n",
    "print(result.content)  # ä½¿ç”¨: ä¹˜æ³•è¿ç®—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b674cb4",
   "metadata": {},
   "source": [
    "# 2ã€FewShotChatMessagePromptTemplateçš„ä½¿ç”¨\n",
    "\n",
    "ä¸¾ä¾‹1ï¼šå®ä¾‹åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a508c55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 1+1ç­‰äºå‡ ï¼Ÿ\n",
      "AI: 1+1ç­‰äº2\n",
      "Human: æ³•å›½çš„é¦–éƒ½æ˜¯ï¼Ÿ\n",
      "AI: å·´é»\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    FewShotChatMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "\n",
    "# 1.ç¤ºä¾‹æ¶ˆæ¯æ ¼å¼\n",
    "examples = [\n",
    "    {\"input\": \"1+1ç­‰äºå‡ ï¼Ÿ\", \"output\": \"1+1ç­‰äº2\"},\n",
    "    {\"input\": \"æ³•å›½çš„é¦–éƒ½æ˜¯ï¼Ÿ\", \"output\": \"å·´é»\"}\n",
    "]\n",
    "\n",
    "# 2.å®šä¹‰ç¤ºä¾‹çš„æ¶ˆæ¯æ ¼å¼æç¤ºè¯æ¨¡ç‰ˆ\n",
    "msg_example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\"),\n",
    "])\n",
    "\n",
    "# 3.å®šä¹‰FewShotChatMessagePromptTemplateå¯¹è±¡\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=msg_example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "# 4.è¾“å‡ºæ ¼å¼åŒ–åçš„æ¶ˆæ¯\n",
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d455768e",
   "metadata": {},
   "source": [
    "ä¸¾ä¾‹2ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efdd0cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.å¯¼å…¥ç›¸å…³åŒ…\n",
    "from langchain_core.prompts import (FewShotChatMessagePromptTemplate, ChatPromptTemplate)\n",
    "\n",
    "# 2.å®šä¹‰ç¤ºä¾‹ç»„\n",
    "examples = [\n",
    "    {\"input\": \"2*2\", \"output\": \"4\"},\n",
    "    {\"input\": \"2*3\", \"output\": \"6\"},\n",
    "]\n",
    "\n",
    "# 3.å®šä¹‰ç¤ºä¾‹çš„æ¶ˆæ¯æ ¼å¼æç¤ºè¯æ¨¡ç‰ˆ\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('human', '{input} æ˜¯å¤šå°‘?'),\n",
    "    ('ai', '{output}')\n",
    "])\n",
    "\n",
    "# 4.å®šä¹‰FewShotChatMessagePromptTemplateå¯¹è±¡\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples=examples,  # ç¤ºä¾‹ç»„\n",
    "    example_prompt=example_prompt,  # ç¤ºä¾‹æç¤ºè¯è¯æ¨¡ç‰ˆ\n",
    ")\n",
    "\n",
    "# 5.è¾“å‡ºå®Œæ•´æç¤ºè¯çš„æ¶ˆæ¯æ¨¡ç‰ˆ\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', 'ä½ æ˜¯ä¸€ä¸ªæ•°å­¦å¥‡æ‰'),\n",
    "        few_shot_prompt,\n",
    "        ('human', '{input}'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 6.æä¾›å¤§æ¨¡å‹\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "chat_model = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"),\n",
    "                        temperature=0.5)\n",
    "\n",
    "chat_model.invoke(final_prompt.invoke(input=\"2*4\")).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cab3ef",
   "metadata": {},
   "source": [
    "## 3ã€Example selectors(ç¤ºä¾‹é€‰æ‹©å™¨)\n",
    "\n",
    "ä¸¾ä¾‹1ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ecc523a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸è¾“å…¥æœ€ç›¸ä¼¼çš„ç¤ºä¾‹ï¼š[{'answer': '\\n        æ¥ä¸‹æ¥è¿˜éœ€è¦é—®ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ\\n        è¿½é—®ï¼šè°æ˜¯ä¹”æ²»Â·åç››é¡¿çš„æ¯äº²ï¼Ÿ\\n        ä¸­é—´ç­”æ¡ˆï¼šä¹”æ²»Â·åç››é¡¿çš„æ¯äº²æ˜¯ç›ä¸½Â·é²å°”Â·åç››é¡¿ã€‚\\n        ', 'question': 'è°æ˜¯ä¹”æ²»Â·åç››é¡¿çš„å¤–ç¥–çˆ¶ï¼Ÿ'}]\n"
     ]
    }
   ],
   "source": [
    "# 1.å¯¼å…¥ç›¸å…³åŒ…\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 2.å®šä¹‰åµŒå…¥æ¨¡å‹\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model=os.getenv(\"LLM_EMBEDDING_MODEL_ID\")\n",
    ")\n",
    "\n",
    "# 3.å®šä¹‰ç¤ºä¾‹ç»„\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"è°æ´»å¾—æ›´ä¹…ï¼Œç©†ç½•é»˜å¾·Â·é˜¿é‡Œè¿˜æ˜¯è‰¾ä¼¦Â·å›¾çµ?\",\n",
    "        \"answer\": \"\"\"\n",
    "        æ¥ä¸‹æ¥è¿˜éœ€è¦é—®ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ\n",
    "        è¿½é—®ï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œå»ä¸–æ—¶å¤šå¤§å¹´çºªï¼Ÿ\n",
    "        ä¸­é—´ç­”æ¡ˆï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œå»ä¸–æ—¶äº«å¹´74å²ã€‚\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"craigslistçš„åˆ›å§‹äººæ˜¯ä»€ä¹ˆæ—¶å€™å‡ºç”Ÿçš„ï¼Ÿ\",\n",
    "        \"answer\": \"\"\"\n",
    "        æ¥ä¸‹æ¥è¿˜éœ€è¦é—®ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ\n",
    "        è¿½é—®ï¼šè°æ˜¯craigslistçš„åˆ›å§‹äººï¼Ÿ\n",
    "        ä¸­çº§ç­”æ¡ˆï¼šCraigslistæ˜¯ç”±å…‹é›·æ ¼Â·çº½é©¬å…‹åˆ›ç«‹çš„ã€‚\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"è°æ˜¯ä¹”æ²»Â·åç››é¡¿çš„å¤–ç¥–çˆ¶ï¼Ÿ\",\n",
    "        \"answer\": \"\"\"\n",
    "        æ¥ä¸‹æ¥è¿˜éœ€è¦é—®ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ\n",
    "        è¿½é—®ï¼šè°æ˜¯ä¹”æ²»Â·åç››é¡¿çš„æ¯äº²ï¼Ÿ\n",
    "        ä¸­é—´ç­”æ¡ˆï¼šä¹”æ²»Â·åç››é¡¿çš„æ¯äº²æ˜¯ç›ä¸½Â·é²å°”Â·åç››é¡¿ã€‚\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"ã€Šå¤§ç™½é²¨ã€‹å’Œã€Šçš‡å®¶èµŒåœºã€‹çš„å¯¼æ¼”éƒ½æ¥è‡ªåŒä¸€ä¸ªå›½å®¶å—ï¼Ÿ\",\n",
    "        \"answer\": \"\"\"\n",
    "        æ¥ä¸‹æ¥è¿˜éœ€è¦é—®ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ\n",
    "        è¿½é—®ï¼šã€Šå¤§ç™½é²¨ã€‹çš„å¯¼æ¼”æ˜¯è°ï¼Ÿ\n",
    "        ä¸­çº§ç­”æ¡ˆï¼šã€Šå¤§ç™½é²¨ã€‹çš„å¯¼æ¼”æ˜¯å²è’‚æ–‡Â·æ–¯çš®å°”ä¼¯æ ¼ã€‚\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# 4.å®šä¹‰ç¤ºä¾‹é€‰æ‹©å™¨\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # è¿™æ˜¯å¯ä¾›é€‰æ‹©çš„ç¤ºä¾‹åˆ—è¡¨\n",
    "    examples,\n",
    "    # è¿™æ˜¯ç”¨äºç”ŸæˆåµŒå…¥çš„åµŒå…¥ç±»ï¼Œç”¨äºè¡¡é‡è¯­ä¹‰ç›¸ä¼¼æ€§\n",
    "    embeddings_model,\n",
    "    # è¿™æ˜¯ç”¨äºå­˜å‚¨åµŒå…¥å¹¶è¿›è¡Œç›¸ä¼¼æ€§æœç´¢çš„ VectorStore ç±»\n",
    "    Chroma,\n",
    "    # è¿™æ˜¯è¦ç”Ÿæˆçš„ç¤ºä¾‹æ•°é‡\n",
    "    k=1,\n",
    ")\n",
    "\n",
    "# é€‰æ‹©ä¸è¾“å…¥æœ€ç›¸ä¼¼çš„ç¤ºä¾‹\n",
    "question = \"ç›ä¸½Â·é²å°”Â·åç››é¡¿çš„çˆ¶äº²æ˜¯è°?\"\n",
    "selected_examples = example_selector.select_examples({\"question\": question})\n",
    "print(f\"ä¸è¾“å…¥æœ€ç›¸ä¼¼çš„ç¤ºä¾‹ï¼š{selected_examples}\")\n",
    "\n",
    "# for example in selected_examples:\n",
    "#     print(\"\\n\")\n",
    "#     for k, v in example.items():\n",
    "#         print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75aac6c",
   "metadata": {},
   "source": [
    "ä¸¾ä¾‹2ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd7f258c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç»™å‡ºæ¯ä¸ªè¯ç»„çš„åä¹‰è¯\n",
      "\n",
      "Input: å¹²ç‡¥\n",
      "Output: æ½®æ¹¿\n",
      "\n",
      "Input: å¿§éƒ\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# 1.å¯¼å…¥ç›¸å…³åŒ…\n",
    "import os\n",
    "import dotenv\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 2.å®šä¹‰ç¤ºä¾‹æç¤ºè¯æ¨¡ç‰ˆ\n",
    "example_prompt = PromptTemplate.from_template(\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "\n",
    "# 3.åˆ›å»ºä¸€ä¸ªç¤ºä¾‹æç¤ºè¯æ¨¡ç‰ˆ\n",
    "examples = [\n",
    "    {\"input\": \"é«˜å…´\", \"output\": \"æ‚²ä¼¤\"},\n",
    "    {\"input\": \"é«˜\", \"output\": \"çŸ®\"},\n",
    "    {\"input\": \"é•¿\", \"output\": \"çŸ­\"},\n",
    "    {\"input\": \"ç²¾åŠ›å……æ²›\", \"output\": \"æ— ç²¾æ‰“é‡‡\"},\n",
    "    {\"input\": \"é˜³å…‰\", \"output\": \"é˜´æš—\"},\n",
    "    {\"input\": \"ç²—ç³™\", \"output\": \"å…‰æ»‘\"},\n",
    "    {\"input\": \"å¹²ç‡¥\", \"output\": \"æ½®æ¹¿\"},\n",
    "    {\"input\": \"å¯Œè£•\", \"output\": \"è´«ç©·\"},\n",
    "]\n",
    "\n",
    "# 4.å®šä¹‰åµŒå…¥æ¨¡å‹\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=os.getenv(\"LLM_EMBEDDING_MODEL_ID\")\n",
    ")\n",
    "\n",
    "# 5.åˆ›å»ºè¯­ä¹‰ç›¸ä¼¼æ€§ç¤ºä¾‹é€‰æ‹©å™¨\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples,\n",
    "    embeddings,\n",
    "    Chroma,\n",
    "    k=1,\n",
    "    input_keys=[\"input\"],  # æŒ‡å®šç”¨äºç”ŸæˆåµŒå…¥çš„å­—æ®µ\n",
    ")\n",
    "\n",
    "# æˆ–è€…\n",
    "#example_selector = SemanticSimilarityExampleSelector(\n",
    "#    examples,\n",
    "#    embeddings,\n",
    "#    FAISS,\n",
    "#    k=2\n",
    "#)\n",
    "\n",
    "# 6.å®šä¹‰å°æ ·æœ¬æç¤ºè¯æ¨¡ç‰ˆ\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"ç»™å‡ºæ¯ä¸ªè¯ç»„çš„åä¹‰è¯\",\n",
    "    suffix=\"Input: {input}\\nOutput:\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "response = similar_prompt.invoke({\"input\":\"å¿§éƒ\"})\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
