{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ef6a32",
   "metadata": {},
   "source": [
    "# 1、ChatMessageHistory的使用\n",
    "\n",
    "场景1：记忆存储\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d83c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='你好', additional_kwargs={}, response_metadata={}), AIMessage(content='很高兴认识你', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 1、ChatMessageHistory的实例化\n",
    "history = InMemoryChatMessageHistory()\n",
    "\n",
    "# 2、添加相关的消息进行存储\n",
    "\n",
    "history.add_user_message(\"你好\")\n",
    "\n",
    "history.add_ai_message(\"很高兴认识你\")\n",
    "\n",
    "# 3、打印存储的消息\n",
    "print(history.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633dad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取大模型\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "# 创建大模型实例\n",
    "llm = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02409d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据数学中的运算规则，乘法优先于加法。所以，1 + 2 * 3 应该先计算乘法部分：\n",
      "\n",
      "2 * 3 = 6\n",
      "\n",
      "然后将结果加到1上：\n",
      "\n",
      "1 + 6 = 7\n",
      "\n",
      "因此，1 + 2 * 3 的结果是 7。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "history = InMemoryChatMessageHistory()\n",
    "\n",
    "# 2、添加相关的消息进行存储\n",
    "history.add_user_message(\"你好\")\n",
    "history.add_ai_message(\"很高兴认识你\")\n",
    "history.add_user_message(\"帮我计算1 + 2 * 3 = ？\")\n",
    "\n",
    "response = llm.invoke(history.messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817b790e",
   "metadata": {},
   "source": [
    "# 2、ConversationBufferMemory的使用（老方法被淘汰了）\n",
    "\n",
    "举例1：以字符串的方式返回存储的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47543431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='你好，我叫小明', additional_kwargs={}, response_metadata={}), AIMessage(content='很高兴认识你', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='帮我回答一下1+2*3=?', additional_kwargs={}, response_metadata={}), AIMessage(content='7', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# 1、ConversationBufferMemory的实例化\n",
    "memory = InMemoryChatMessageHistory()\n",
    "\n",
    "# 2、存储相关的消息\n",
    "memory.add_message(HumanMessage(content=\"你好，我叫小明\"))\n",
    "memory.add_message(AIMessage(content=\"很高兴认识你\"))\n",
    "\n",
    "memory.add_message(HumanMessage(content=\"帮我回答一下1+2*3=?\"))\n",
    "memory.add_message(AIMessage(content=\"7\"))\n",
    "\n",
    "# 3、获取存储的信息\n",
    "print(memory.messages)\n",
    "\n",
    "# 说明：返回的字典结构的key叫history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cb7c9d",
   "metadata": {},
   "source": [
    "举例2：以消息列表的方式返回存储的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa16d4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='这是用户说的话：1+1等于几？', additional_kwargs={}, response_metadata={}), AIMessage(content='这是AI说的话：等于2', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "store = {} \n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# 1. 获取历史对象 (传入任意 session_id)\n",
    "history = get_session_history(\"test_user_1\")\n",
    "\n",
    "# 2. 添加消息\n",
    "history.add_user_message(\"这是用户说的话：1+1等于几？\")\n",
    "history.add_ai_message(\"这是AI说的话：等于2\")\n",
    "\n",
    "# 3. 打印结果\n",
    "print(history.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f047d",
   "metadata": {},
   "source": [
    "举例3：结合大模型、提示词模板的使用（PromptTemplate）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f332ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，小明！根据我们之前的对话，你提到你喜欢编程。不过，如果你还有其他特别的兴趣爱好或者喜欢的事物，也随时可以告诉我哦！\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "# 1. 创建模型\n",
    "llm = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "# 2. Prompt (使用 MessagesPlaceholder 替代手动拼接 history)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你可以与人类对话。\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"), # 这是一个占位符，专门放历史记录\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "# 3. 定义 Chain (使用 LCEL 管道符 | 替代 LLMChain)\n",
    "# 逻辑流：Prompt -> 模型 -> 输出转字符串\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 4. 记忆管理 (替代 ConversationBufferMemory)\n",
    "# 用一个简单的字典模拟数据库\n",
    "user_1_history = InMemoryChatMessageHistory()\n",
    "user_1_history.add_message(HumanMessage(content=\"小明喜欢什么？\"))\n",
    "user_1_history.add_message(AIMessage(content=\"小明喜欢编程。\"))\n",
    "store = {\"user_1\": user_1_history}\n",
    "\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# 使用 RunnableWithMessageHistory 包装 chain\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "# 5. 调用\n",
    "response = chain_with_history.invoke(\n",
    "    {\"question\": \"你好，我的名字叫小明，你知道我喜欢什么吗？\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user_1\"}}\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ebef3",
   "metadata": {},
   "source": [
    "举例4：基于举例3，显式的设置meory的key的值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0dbfd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_1': InMemoryChatMessageHistory(messages=[HumanMessage(content='你好，我的名字叫小罗,我喜欢小鹿。', additional_kwargs={}, response_metadata={}), AIMessage(content='你好小罗，很高兴认识你。你对小鹿有这样的喜好，可能是因为它们温顺、可爱，还是因为其他的原因呢？', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]), 'user_2': InMemoryChatMessageHistory(messages=[HumanMessage(content='你好，我的名字叫小谢，你知道我喜欢什么吗，小罗喜欢的我不喜欢？', additional_kwargs={}, response_metadata={}), AIMessage(content='你好小谢！通过这句话，你是否是在说你和小罗在兴趣爱好上有差异呢？不过，我不是你们的专属想象力助手，无法直接得知你的具体喜好是什么。但是，一般人都会有自己独特的喜好，如音乐、电影、书籍、运动等等，而这些可能会和你身边的人有所不同。例如你可能非常喜欢科幻类的电影，而小罗则可能更喜欢爱情电影。如果你愿意的话，可以具体说一下你的喜好，我可以帮助你找到和小罗共享的共同兴趣。', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])])}\n",
      "Human: 你好，我的名字叫小罗,我喜欢小鹿。\n",
      "AI: 你好小罗，很高兴认识你。你对小鹿有这样的喜好，可能是因为它们温顺、可爱，还是因为其他的原因呢？\n",
      "<class 'langchain_core.chat_history.InMemoryChatMessageHistory'>\n",
      "你好小谢！通过这句话，你是否是在说你和小罗在兴趣爱好上有差异呢？不过，我不是你们的专属想象力助手，无法直接得知你的具体喜好是什么。但是，一般人都会有自己独特的喜好，如音乐、电影、书籍、运动等等，而这些可能会和你身边的人有所不同。例如你可能非常喜欢科幻类的电影，而小罗则可能更喜欢爱情电影。如果你愿意的话，可以具体说一下你的喜好，我可以帮助你找到和小罗共享的共同兴趣。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1、创建大模型实例\n",
    "llm = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "# 2、提供提示词模板 (ChatPromptTemplate 替代 PromptTemplate)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你可以与人类对话。\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "# 3、提供Chain (使用管道符 | 构建)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 4、提供memory管理逻辑 (替代 ConversationBufferMemory)\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# 5、包装 Chain\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",      # 对应输入的 key\n",
    "    history_messages_key=\"chat_history\",  # 对应提示词模板中的占位符\n",
    ")\n",
    "\n",
    "# 6、调用\n",
    "response_1 = chain_with_history.invoke(\n",
    "    {\"question\": \"你好，我的名字叫小罗,我喜欢小鹿。\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user_1\"}}\n",
    ")\n",
    "\n",
    "response_2 = chain_with_history.invoke(\n",
    "    {\"question\": \"你好，我的名字叫小谢，你知道我喜欢什么吗，小罗喜欢的我不喜欢？\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user_2\"}}\n",
    ")\n",
    "\n",
    "print(store)\n",
    "print(store[\"user_1\"])\n",
    "print(type(store[\"user_1\"]))\n",
    "print(response_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
