{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec55afc",
   "metadata": {},
   "source": [
    "# 1、关于对话模型中消息（message）的使用\n",
    "\n",
    "标准的对话模型的调用过程：\n",
    "\n",
    "invoke()的输入可以是多种类型，典型的类型有：① 字符串类型 ② 消息列表\n",
    "\n",
    "invoke()的输出类型：BaseMessage的子类 AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36384e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangChain并不是一个广为人知的特定名词，在机器学习和自然语言处理领域里并没有直接对应的概念。不过，您可能是想询问的“LangChain”指的是将语言模型与外部数据源和工具进行链式连接的技术或产品。这里，“LangChain”可以是多种技术和产品的统称或未来发展方向。下面，我将分别介绍两方面的内容，帮助您更好地理解可能的背景信息：\\n\\n1. **链式实施方案（Chain of Implementation）**: 在自然语言处理（NLP）领域，有一个趋势是将语言模型的能力与外部数据和服务进行结合，以构建更加复杂的、上下文感知的解决方案。这通常被称为“链式实施方案”，而不是具体的“LangChain”。每个链环节都有助于实现一个更加具体的任务或流程。例如，模型可以首先从外部知识库查询相关信息来增强其输出，然后再基于语料库的内容生成回答。这种方式可以使模型更灵活、更精确地满足用户的特定需求。\\n\\n2. **LangChain** (假设产品或项目名称): 指的是一个假设中的软件产品或技术框架，它将语言模型与各种外部系统和服务连接起来，以创建更强大的应用或服务。例如，LangChain的技术框架可能会帮助开发者更容易地将自然语言处理模型与数据库、API等外部资源集成，以此来增强模型的功能边界和适用范围。这种框架可能包括一系列工具、库或预构建的模块，旨在简化模型与外部环境交互的过程。\\n\\n然而，现实中并没有一个叫“LangChain”的广泛认可的术语或产品。如果有关具体产品或项目的背景资料，请提供更多的信息，以便更准确地解答您的问题。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 344, 'prompt_tokens': 35, 'total_tokens': 379, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'Qwen/Qwen2.5-7B-Instruct', 'system_fingerprint': '', 'id': '019be9ba5e710b7777bccf73cf6f5eda', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019be9ba-5e94-7673-a775-12c713e1ba74-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 35, 'output_tokens': 344, 'total_tokens': 379, 'input_token_details': {}, 'output_token_details': {}}\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "# 前提：加载配置文件\n",
    "dotenv.load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.getenv(\"LLM_BASE_URL\")\n",
    "# 1、获取对话模型\n",
    "chatModel = ChatOpenAI(\n",
    "    model_name = os.getenv(\"LLM_MODEL_ID\"),\n",
    ")\n",
    "# 2、调用对话模型\n",
    "response = chatModel.invoke(\"请介绍一下LangChain是什么？\")\n",
    "# 3、处理响应数据\n",
    "print(response.content)\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc2900f",
   "metadata": {},
   "source": [
    "关于消息：\n",
    "\n",
    "有典型的三类消息：SystemMessage \\ HumanMessage \\ AIMessage\n",
    "\n",
    "举例1：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7e9db75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是一个水声目标识别领域的专家。', additional_kwargs={}, response_metadata={}), HumanMessage(content='帮我制定一个水声目标识别学习的计划。', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "system_message = SystemMessage(content=\"你是一个水声目标识别领域的专家。\")\n",
    "human_message = HumanMessage(content=\"帮我制定一个水声目标识别学习的计划。\")\n",
    "\n",
    "messages = [system_message, human_message]\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8868693",
   "metadata": {},
   "source": [
    "使用大模型，调用消息列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9dbd82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "当然可以。学习水声目标识别领域需要一定的基础知识和实践探索。下面是一个全面的学习计划，希望对你有所帮助。\n",
      "\n",
      "### 第一部分：基础知识学习（3-4周）\n",
      "\n",
      "#### 1. 数学和物理基础知识\n",
      "- 线性代数、概率论\n",
      "- 声学原理基础（波的特性、多普勒效应等）\n",
      "\n",
      "#### 2. 计算机编程\n",
      "- Python（特别是Numpy、Pandas、Matplotlib）\n",
      "- 数据处理与分析\n",
      "- 如何使用包如scikit-learn进行机器学习\n",
      "\n",
      "#### 3. 了解声学建模和处理\n",
      "- 深入理解声信号处理的基本概念\n",
      "- 如何识别和处理噪声\n",
      "\n",
      "### 第二部分：理论学习（4-6周）\n",
      "\n",
      "#### 1. 水声学基础\n",
      "- 半无限空间中的声传播理论\n",
      "- 海洋声学环境\n",
      "\n",
      "#### 2. 目标识别技术\n",
      "- 时频分析技术\n",
      "- 模式识别\n",
      "- 机器学习方法（例如SVM、深度神经网络等）\n",
      "\n",
      "#### 3. 实际案例研究\n",
      "- 海洋生物识别\n",
      "- 水下无人航行器识别\n",
      "- 目标定位技术\n",
      "\n",
      "### 第三部分：实践操作（3-4周）\n",
      "\n",
      "#### 1. 实验数据收集\n",
      "- 能否获取或者寻找公开的数据集，如果没有则研究现有的模型是否可以应用于该领域\n",
      "\n",
      "#### 2. 算法训练\n",
      "- 基于所学知识，开发目标识别模型（可以从简单的模型开始，逐步复杂化）\n",
      "- 对结果进行评估和优化\n",
      "\n",
      "#### 3. 结果分析与优化\n",
      "- 分析结果，发现不足，进行调整优化\n",
      "- 了解最新的研究动态，借鉴新的方法和技术\n",
      "\n",
      "### 第四部分：项目总结与汇报（2周）\n",
      "\n",
      "#### 1. 编写详细的实验报告与总结\n",
      "- 方法描述\n",
      "- 实验过程\n",
      "- 结果分析\n",
      "- 讨论与展望\n",
      "\n",
      "#### 2. 准备PPT、论文、研究报告等\n",
      "- 为可能的学术交流或成果展示做准备\n",
      "\n",
      "### 第五部分：持续学习与跟踪前沿（持续）\n",
      "- 关注领域相关的国际会议论文\n",
      "- 参与学术讨论和交流\n",
      "- 保持对新技术的敏感度，学习并尝试应用\n",
      "\n",
      "请根据自己的具体情况调整各个部分的时间分配。希望这个计划能帮助你构建坚实的水声目标识别知识基础，并且顺利进入深入学习的状态。\n"
     ]
    }
   ],
   "source": [
    "response = chatModel.invoke(messages)\n",
    "print(type(response))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb7bace",
   "metadata": {},
   "source": [
    "举例2："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62f90c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是一个水声目标识别领域的专家。', additional_kwargs={'tool': 'invoke_func'}, response_metadata={}), HumanMessage(content='帮我制定一个水声目标识别学习的计划。', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "system_message = SystemMessage(\n",
    "    content=\"你是一个水声目标识别领域的专家。\",\n",
    "    additional_kwargs={\"tool\":\"invoke_func\"}\n",
    ")\n",
    "human_message = HumanMessage(content=\"帮我制定一个水声目标识别学习的计划。\")\n",
    "\n",
    "messages = [system_message, human_message]\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74292a26",
   "metadata": {},
   "source": [
    "举例3：ChatMessage平时我们使用的不多，了解一下即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72e3b849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个专业的数据科学家\n",
      "解释一下随机森林算法\n",
      "随机森林是一种集成学习方法...\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ChatMessage\n",
    ")\n",
    "\n",
    "# 创建不同类型的消息\n",
    "system_message = SystemMessage(content=\"你是一个专业的数据科学家\")\n",
    "human_message = HumanMessage(content=\"解释一下随机森林算法\")\n",
    "ai_message = AIMessage(content=\"随机森林是一种集成学习方法...\")\n",
    "custom_message = ChatMessage(role=\"analyst\", content=\"补充一点关于超参数调优的信息\")\n",
    "\n",
    "print(system_message.content)\n",
    "print(human_message.content)\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce84a3da",
   "metadata": {},
   "source": [
    "# 2、关于多轮对话与上下文记忆\n",
    "\n",
    "前提："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1fb9834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "\tmodel=os.getenv(\"LLM_MODEL_ID\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7936c639",
   "metadata": {},
   "source": [
    "测试1：大模型本身是没有上下文记忆能力的\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "504984c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是Qwen，我是由阿里云开发的AI助手。您可以叫我Qwen。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "sys_message = SystemMessage(\n",
    "    content=\"我是一个人工智能的助手\",\n",
    ")\n",
    "human_message = HumanMessage(content=\"猫王是一只猫吗？\")\n",
    "\n",
    "messages = [sys_message, human_message]\n",
    "\n",
    "# 调用大模型，传入messages\n",
    "# response = chat_model.invoke(messages)\n",
    "# print(response.content)\n",
    "\n",
    "response = chat_model.invoke(\"你叫什么名字？\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769837d7",
   "metadata": {},
   "source": [
    "测试2："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efdbd6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是来自阿里云的语言模型，我叫通义千问。关于模型的具体名称和版本信息，我会随着时间不断进行更新迭代，如果您对最新情况感兴趣，可以查看阿里云的官方公告。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "sys_message = SystemMessage(\n",
    "    content=\"我是一个人工智能的助手\",\n",
    ")\n",
    "human_message = HumanMessage(content=\"你的模型具体名称以及你现在的版本是什么？\")\n",
    "human_message1 = HumanMessage(content=\"你叫什么名字？\")\n",
    "\n",
    "messages = [sys_message, human_message, human_message1]\n",
    "\n",
    "# 调用大模型，传入messages\n",
    "response = chat_model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca9ee98",
   "metadata": {},
   "source": [
    "测试3："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2216c4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是来自阿里云的超大规模语言模型，我叫通义千问。您可以叫我千问。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "sys_message1 = SystemMessage(\n",
    "    content=\"我是一个人工智能的助手\",\n",
    ")\n",
    "human_message1 = HumanMessage(content=\"你的模型具体名称以及你现在的版本是什么？\")\n",
    "\n",
    "sys_message2 = SystemMessage(\n",
    "    content=\"我可以做很多事情，有需要就找我吧！\",\n",
    ")\n",
    "human_message2 = HumanMessage(content=\"你叫什么名字？\")\n",
    "\n",
    "messages = [sys_message1, human_message1, sys_message2, human_message2]\n",
    "\n",
    "# 调用大模型，传入messages\n",
    "response = chat_model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ce921f",
   "metadata": {},
   "source": [
    "测试4："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da3d78ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你可以叫我AI助手。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "sys_message1 = SystemMessage(\n",
    "    content=\"我是一个人工智能的助手\",\n",
    ")\n",
    "human_message1 = HumanMessage(content=\"你的模型具体名称以及你现在的版本是什么？\")\n",
    "\n",
    "messages1 = [sys_message1, human_message1]\n",
    "\n",
    "sys_message2 = SystemMessage(\n",
    "    content=\"我可以做很多事情，有需要就找我吧！\",\n",
    ")\n",
    "human_message2 = HumanMessage(content=\"你叫什么名字？\")\n",
    "\n",
    "messages2 = [sys_message2, human_message2]\n",
    "\n",
    "# 调用大模型，传入messages\n",
    "# response = chat_model.invoke(messages1)\n",
    "# print(response.content)\n",
    "\n",
    "response = chat_model.invoke(messages2)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391fe005",
   "metadata": {},
   "source": [
    "测试5："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80d5689d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我是来自阿里云的超大规模语言模型，我叫通义千问。您可以称呼我为通义千问。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 36, 'total_tokens': 62, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'Qwen/Qwen2.5-7B-Instruct', 'system_fingerprint': '', 'id': '019be9cee98ce6f0f089de9724a604d5', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019be9ce-e96e-7341-9ce9-45a9f7a1108a-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 36, 'output_tokens': 26, 'total_tokens': 62, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"我是一个人工智能助手\"),\n",
    "    HumanMessage(content=\"人工智能英文怎么说？\"),\n",
    "    AIMessage(content=\"AI\"),\n",
    "    HumanMessage(content=\"你叫什么名字\"),\n",
    "]\n",
    "\n",
    "messages1 = [\n",
    "    SystemMessage(content=\"我是一个人工智能助手\"),\n",
    "    HumanMessage(content=\"很高兴认识你\"),\n",
    "    AIMessage(content=\"我也很高兴认识你\"),\n",
    "    HumanMessage(content=\"你叫什么名字\"),\n",
    "]\n",
    "\n",
    "messages2 = [\n",
    "    SystemMessage(content=\"我是一个人工智能助手\"),\n",
    "    HumanMessage(content=\"人工智能英文怎么说？\"),\n",
    "    AIMessage(content=\"AI\"),\n",
    "    HumanMessage(content=\"你叫什么名字\"),\n",
    "]\n",
    "\n",
    "chat_model.invoke(messages2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f54ec1f",
   "metadata": {},
   "source": [
    "# 3、关于模型调用的方法的说明\n",
    "\n",
    "invoke() / stream()\n",
    "\n",
    "batch():批量的调用\n",
    "\n",
    "ainvoke() / astream() / abatch():异步方法的调用\n",
    "\n",
    "举例1：体会invoke()阻塞式的调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b05e8bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您好！我叫Qwen，是阿里云推出的一种超大规模语言模型，基于强大的预训练技术训练而成。我能够回答问题、创作文字，还能表达观点、撰写代码，是您进行对话交流和寻求信息的好伙伴。如果您有任何问题或需要帮助，请随时告诉我，我会尽力提供支持！\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "# 前提：加载配置文件\n",
    "dotenv.load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.getenv(\"LLM_BASE_URL\")\n",
    "# 1、获取对话模型\n",
    "chatModel = ChatOpenAI(\n",
    "    model_name = os.getenv(\"LLM_MODEL_ID\"),\n",
    ")\n",
    "# 2、调用对话模型\n",
    "response = chatModel.invoke(\"请介绍一下你自己？\")\n",
    "# 3、处理响应数据\n",
    "print(response.content)\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e155df7c",
   "metadata": {},
   "source": [
    "举例2：流式的演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db8e97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始流式输出：\n",
      "您好！我是Qwen，我由阿里云开发，是一名能与人类进行自然语言交流的AI助手。我被设计用来帮助用户生成各种类型的文本，包括但不限于文章、故事、诗歌、故事梗概甚至是说明书等。同时，我也能够回答问题、提供信息、参与讨论，旨在与用户进行有意义、有帮助的互动。不仅如此，我还能够进行多语言的交流，朝着更加智能和人性化的方向不断进化和学习。如果您有任何问题或需要帮助，欢迎随时向我提问！\n",
      "流式输出结束\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "# 前提：加载配置文件\n",
    "dotenv.load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.getenv(\"LLM_BASE_URL\")\n",
    "# 获取对话模型\n",
    "chatModel = ChatOpenAI(\n",
    "    model_name = os.getenv(\"LLM_MODEL_ID\"),\n",
    "    streaming=True # 启用流式输出\n",
    ")\n",
    "# 创建消息\n",
    "messages = [HumanMessage(content=\"请介绍一下你自己？\")]\n",
    "# 调用对话模型\n",
    "# 流式调用LLM获取响应\n",
    "print(\"开始流式输出：\")\n",
    "for chunk in chatModel.stream(messages):\n",
    "    # 逐个打印内容块\n",
    "    print(chunk.content, end='', flush=True) # 刷新缓冲区 (无换行符，缓冲区未刷新，内容可能不会立即显示)\n",
    "\n",
    "print(\"\\n流式输出结束\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0570e522",
   "metadata": {},
   "source": [
    "举例3：使用batch，测试批量调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3173d35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='当然可以！机器学习是一种人工智能技术，能够使计算机在没有明确编程的情况下从数据中学习并改进。它通过算法和统计模型使计算机能够发现数据中的规律，并基于这些规律进行预测或决策。\\n\\n**机器学习的工作原理**主要分为几个步骤：\\n1. **数据收集**：收集并准备训练数据，这些数据需要根据机器学习任务的需要来选择和处理。\\n2. **模型选择**：选择一个合适的机器学习模型。不同的模型适用于不同的任务，比如线性回归用于预测数值结果，逻辑回归用于分类任务。\\n3. **训练模型**：使用算法让模型学习到数据中的规律，并调整模型的参数以达到最佳性能。\\n4. **模型评估**：使用部分数据集来评估模型的性能，以确保模型不仅有效地学习了数据，还能应用于新数据。\\n5. **部署模型**：将训练好的模型用于新的数据集，在实际应用中做出预测或决策。\\n\\n**机器学习的应用非常广泛**，比如自动驾驶汽车、推荐系统（如购物网站上的商品推荐）、图像识别、自然语言处理等。通过不断优化这些应用，机器学习正逐步改变我们日常生活的方式。', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'Qwen/Qwen2.5-7B-Instruct', 'model_provider': 'openai'}, id='lc_run--019be9de-a04c-7cf3-b7b7-a2456465da39', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 6916, 'output_tokens': 30380, 'total_tokens': 37296, 'input_token_details': {}, 'output_token_details': {}}), AIMessage(content='当然可以！AIGC指的是人工智能生成内容（Artificial Intelligence Generated Content），是一种利用人工智能技术自动生成内容的技术或应用。这种技术可以生成文字、图像、音频、视频等多种类型的创意内容，常用于新闻、娱乐、广告等领域，大大提高了内容生产效率和创作多样性。\\n\\nAIGC的主要特点包括：\\n\\n1. **自主性**：AIGC系统可以基于设计好的算法和模型，自主生成内容，减少人工干预。\\n   \\n2. **高效性**：相比于人工创作，AIGC可以在短时间内生成大量内容，特别适合用于需要大量产出的情境。\\n   \\n3. **可拓展性**：随着技术的进步，AIGC的应用场景越来越广泛，能针对不同的领域和需求进行调整和优化。\\n   \\n4. **多样性和创新性**：利用人工智能进行内容生成，可以带来前所未有的多样性与创新性，甚至创造出独特的艺术作品或内容形式。\\n\\nAIGC的发展引发了一系列讨论，包括版权归属、内容质量和真实性等问题，同时也为内容产业带来了革命性的变化。随着技术的不断进步，未来AIGC将继续扩大其应用范围和影响力。', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'Qwen/Qwen2.5-7B-Instruct', 'model_provider': 'openai'}, id='lc_run--019be9de-a04d-7ed1-bee0-3ddde00eae2d', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 6902, 'output_tokens': 28202, 'total_tokens': 35104, 'input_token_details': {}, 'output_token_details': {}}), AIMessage(content='大模型技术，通常指的是用于机器学习和人工智能领域的一种技术，它涉及到训练和应用大型神经网络模型的过程。这类模型的参数和训练数据量都非常大，能够捕获和理解非常复杂的模式和关系，特别是在处理自然语言理解和生成、图像识别、音频处理等领域时表现出色。\\n\\n大模型技术主要包括以下几个方面：\\n\\n1. **深度学习模型**：大模型的核心是深度学习模型，包括递归神经网络（RNN）、长短期记忆网络（LSTM）、变压器（Transformer）等，这些模型可以处理文本、图像、声音等大规模数据。\\n\\n2. **训练过程**：大模型需要大量的计算资源和时间来训练。常见的训练方式包括使用大规模分布式计算集群、并行处理等技术提高训练效率。而高质量的数据集是训练出性能优良模型的关键。\\n\\n3. **应用领域**：大模型技术广泛应用于自然语言处理（如机器翻译、情感分析、问答系统等）、计算机视觉、音频识别、推荐系统、智能机器人等多个领域，能够解决一些传统方法难以处理的问题。\\n\\n4. **存在的挑战**：包括模型的训练成本高昂、训练数据获取与标注难度、模型的可解释性差等问题。最近几年，研究人员和公司都在努力解决这些挑战，以便更好地利用大模型技术。\\n\\n随着计算能力的提高和数据量的快速增长，大模型技术正变得越来越重要，也在不断地推动着人工智能技术的发展。', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'Qwen/Qwen2.5-7B-Instruct', 'model_provider': 'openai'}, id='lc_run--019be9de-a04e-7a13-b182-a6ca192a39d5', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 8700, 'output_tokens': 44849, 'total_tokens': 53549, 'input_token_details': {}, 'output_token_details': {}})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "# 前提：加载配置文件\n",
    "dotenv.load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.getenv(\"LLM_BASE_URL\")\n",
    "# 获取对话模型\n",
    "chatModel = ChatOpenAI(\n",
    "    model_name = os.getenv(\"LLM_MODEL_ID\"),\n",
    "    streaming=True # 启用流式输出\n",
    ")\n",
    "# 创建多组消息\n",
    "messages1 = [SystemMessage(content=\"你是一位乐于助人的智能小助手\"),\n",
    "             HumanMessage(content=\"请帮我介绍一下什么是机器学习\"), ]\n",
    "\n",
    "messages2 = [SystemMessage(content=\"你是一位乐于助人的智能小助手\"),\n",
    "             HumanMessage(content=\"请帮我介绍一下什么是AIGC\"), ]\n",
    "\n",
    "messages3 = [SystemMessage(content=\"你是一位乐于助人的智能小助手\"),\n",
    "             HumanMessage(content=\"请帮我介绍一下什么是大模型技术\"), ]\n",
    "\n",
    "messages = [messages1, messages2, messages3]\n",
    "# 调用batch\n",
    "response = chatModel.batch(messages)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dabbbfa",
   "metadata": {},
   "source": [
    "举例4：关于同步和异步方法的调用\n",
    "\n",
    "体会1："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f691353c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始调用模型...\n",
      "模型调用完成。\n",
      "执行其他任务 1\n",
      "执行其他任务 2\n",
      "执行其他任务 3\n",
      "执行其他任务 4\n",
      "执行其他任务 5\n",
      "总共耗时：10.033190965652466秒\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def call_model():\n",
    "    # 模拟同步API调用\n",
    "    print(\"开始调用模型...\")\n",
    "    time.sleep(5)  # 模拟调用等待,单位：秒\n",
    "    print(\"模型调用完成。\")\n",
    "\n",
    "def perform_other_tasks():\n",
    "    # 模拟执行其他任务\n",
    "    for i in range(5):\n",
    "        print(f\"执行其他任务 {i + 1}\")\n",
    "        time.sleep(1)  # 单位：秒\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    call_model()\n",
    "    perform_other_tasks()\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    return f\"总共耗时：{total_time}秒\"\n",
    "\n",
    "# 运行同步任务并打印完成时间\n",
    "main_time = main()\n",
    "print(main_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b822f9",
   "metadata": {},
   "source": [
    "体会2："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8ca970f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "异步调用完成\n",
      "其他任务完成\n",
      "总共耗时：5.005593299865723秒\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def async_call(llm):\n",
    "    await asyncio.sleep(5)  # 模拟异步操作\n",
    "    print(\"异步调用完成\")\n",
    "\n",
    "async def perform_other_tasks():\n",
    "    await asyncio.sleep(5)  # 模拟异步操作\n",
    "    print(\"其他任务完成\")\n",
    "\n",
    "async def run_async_tasks():\n",
    "    start_time = time.time()\n",
    "    await asyncio.gather(\n",
    "        async_call(None),  # 示例调用，使用None模拟LLM对象\n",
    "        perform_other_tasks()\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    return f\"总共耗时：{end_time - start_time}秒\"\n",
    "\n",
    "# 正确运行异步任务的方式\n",
    "# if __name__ == \"__main__\":\n",
    "#     # 使用 asyncio.run() 来启动异步程序\n",
    "#     result = asyncio.run(run_async_tasks())\n",
    "#     print(result)\n",
    "\n",
    "\n",
    "# 在 Jupyter 单元格中直接调用\n",
    "result = await run_async_tasks()\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
