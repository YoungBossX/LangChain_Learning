{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c010423",
   "metadata": {},
   "source": [
    "# 关于LCEL语法的使用\n",
    "\n",
    "在使用 | 之前的举例:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8e9b352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```json\\n{\\n  \"joke\": \"为什么电脑总是出问题？因为它老是想‘重启’生活！\"\\n}\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 52, 'total_tokens': 80, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'Qwen/Qwen2.5-7B-Instruct', 'system_fingerprint': '', 'id': '019bfe1835fea2c74128e95f3724b581', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019bfe18-3501-7983-a4cc-5e14df82a6f6-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 52, 'output_tokens': 28, 'total_tokens': 80, 'input_token_details': {}, 'output_token_details': {}}\n",
      "{'joke': '为什么电脑总是出问题？因为它老是想‘重启’生活！'}\n"
     ]
    }
   ],
   "source": [
    "# 引入依赖包\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"LLM_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "# 初始化语言模型\n",
    "chat_model = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "joke_query = \"告诉我一个笑话。\"\n",
    "\n",
    "# 定义Json解析器\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# 以PromptTemplate为例\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"回答用户的查询\\n 满足的格式为{format_instructions}\\n 问题为{question}\\n\",\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke(input={\"question\": joke_query})\n",
    "response = chat_model.invoke(prompt)\n",
    "print(response)\n",
    "\n",
    "json_result = parser.invoke(response)\n",
    "print(json_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea98ca3",
   "metadata": {},
   "source": [
    "使用|符号以后的举例：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1247d5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': '为什么电脑经常生病？因为它窗户（Windwos）太多！'}\n"
     ]
    }
   ],
   "source": [
    "# 引入依赖包\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 初始化语言模型\n",
    "chat_model = ChatOpenAI(model=os.getenv(\"LLM_MODEL_ID\"))\n",
    "\n",
    "joke_query = \"告诉我一个笑话。\"\n",
    "\n",
    "# 定义Json解析器\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# 以PromptTemplate为例\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"回答用户的查询\\n 满足的格式为{format_instructions}\\n 问题为{question}\\n\",\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "# 写法1：\n",
    "# prompt = prompt_template.invoke(input={\"question\":joke_query})\n",
    "# response = chat_model.invoke(prompt)\n",
    "# json_result = parser.invoke(response)\n",
    "\n",
    "# 正确的写法\n",
    "chain = prompt_template | chat_model | parser\n",
    "\n",
    "# 错误的写法\n",
    "# chain =  chat_model |  prompt_template | parser\n",
    "\n",
    "json_result = chain.invoke(input={\"question\": joke_query})\n",
    "print(json_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
